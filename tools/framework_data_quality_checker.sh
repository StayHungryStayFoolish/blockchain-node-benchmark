#!/bin/bash

# =====================================================================
# æ¡†æ¶æ•°æ®éªŒè¯è„šæœ¬ - éªŒè¯å½’æ¡£æ•°æ®å’Œå…±äº«å†…å­˜ç¼“å­˜æ•°æ®è´¨é‡
# =====================================================================

# è„šæœ¬ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# åŠ è½½æ¡†æ¶é…ç½®
if ! source "${SCRIPT_DIR}/../config/config_loader.sh" 2>/dev/null; then
    echo "âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥"
    exit 1
fi

# éªŒè¯ç»“æœç»Ÿè®¡
TOTAL_CHECKS=0
PASSED_CHECKS=0
FAILED_CHECKS=0
VALIDATION_ERRORS=()

# æ—¥å¿—å‡½æ•°
log_info() { echo "â„¹ï¸  $*"; }
log_success() { echo "âœ… $*"; ((PASSED_CHECKS++)); }
log_error() { echo "âŒ $*"; ((FAILED_CHECKS++)); VALIDATION_ERRORS+=("$*"); }
log_warn() { echo "âš ï¸  $*"; }

# å¢åŠ æ£€æŸ¥è®¡æ•°
check_count() { ((TOTAL_CHECKS++)); }

# è·å–æœ€æ–°å½’æ¡£ç¼–å·
get_latest_archive_number() {
    if [[ ! -d "$ARCHIVES_DIR" ]]; then
        echo "000"
        return
    fi
    
    local latest=$(ls -1 "$ARCHIVES_DIR" 2>/dev/null | grep "^run_" | sort -V | tail -1 | sed 's/run_//')
    echo "${latest:-000}"
}

# éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
validate_file_exists() {
    local file_path="$1"
    local file_desc="$2"
    
    check_count
    if [[ -f "$file_path" ]]; then
        log_success "$file_desc å­˜åœ¨: $(basename "$file_path")"
        return 0
    else
        log_error "$file_desc ä¸å­˜åœ¨: $file_path"
        return 1
    fi
}

# éªŒè¯CSVæ–‡ä»¶æ ¼å¼
validate_csv_file() {
    local csv_file="$1"
    local file_desc="$2"
    local expected_header="$3"
    
    if [[ ! -f "$csv_file" ]]; then
        log_error "$file_desc CSVæ–‡ä»¶ä¸å­˜åœ¨: $csv_file"
        return 1
    fi
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
    check_count
    if [[ ! -s "$csv_file" ]]; then
        log_error "$file_desc CSVæ–‡ä»¶ä¸ºç©º"
        return 1
    fi
    log_success "$file_desc CSVæ–‡ä»¶éç©º"
    
    # éªŒè¯è¡¨å¤´
    check_count
    local actual_header=$(head -1 "$csv_file")
    if [[ -n "$expected_header" ]]; then
        if [[ "$actual_header" == "$expected_header" ]]; then
            log_success "$file_desc CSVè¡¨å¤´æ­£ç¡®"
        else
            log_error "$file_desc CSVè¡¨å¤´ä¸åŒ¹é…"
            log_error "  é¢„æœŸ: $(echo "$expected_header" | cut -c1-100)..."
            log_error "  å®é™…: $(echo "$actual_header" | cut -c1-100)..."
            return 1
        fi
    else
        log_success "$file_desc CSVè¡¨å¤´å­˜åœ¨: $(echo "$actual_header" | tr ',' '\n' | wc -l) ä¸ªå­—æ®µ"
    fi
    
    # éªŒè¯æ•°æ®è¡Œæ•°
    check_count
    local line_count=$(wc -l < "$csv_file")
    if [[ $line_count -gt 1 ]]; then
        log_success "$file_desc CSVåŒ…å« $((line_count - 1)) è¡Œæ•°æ®"
    else
        log_error "$file_desc CSVåªæœ‰è¡¨å¤´ï¼Œæ— æ•°æ®è¡Œ"
        return 1
    fi
    
    # éªŒè¯æ—¶é—´æˆ³æ ¼å¼ (æ£€æŸ¥å‰5è¡Œ) - ä¿®å¤ä¸ºç©ºæ ¼åˆ†éš”æ ¼å¼
    check_count
    local invalid_timestamps=$(tail -n +2 "$csv_file" | head -5 | cut -d',' -f1 | grep -v '^[0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\} [0-9]\{2\}:[0-9]\{2\}:[0-9]\{2\}' | wc -l)
    if [[ $invalid_timestamps -eq 0 ]]; then
        log_success "$file_desc æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®"
    else
        log_error "$file_desc å‘ç° $invalid_timestamps ä¸ªæ— æ•ˆæ—¶é—´æˆ³"
    fi
    
    return 0
}

# éªŒè¯JSONæ–‡ä»¶æ ¼å¼
validate_json_file() {
    local json_file="$1"
    local file_desc="$2"
    local required_fields="$3"
    
    if [[ ! -f "$json_file" ]]; then
        log_error "$file_desc JSONæ–‡ä»¶ä¸å­˜åœ¨: $json_file"
        return 1
    fi
    
    # éªŒè¯JSONæ ¼å¼
    check_count
    if jq empty "$json_file" 2>/dev/null; then
        log_success "$file_desc JSONæ ¼å¼æ­£ç¡®"
    else
        log_error "$file_desc JSONæ ¼å¼æ— æ•ˆ"
        return 1
    fi
    
    # éªŒè¯å¿…éœ€å­—æ®µ
    if [[ -n "$required_fields" ]]; then
        check_count
        local missing_fields=()
        for field in $required_fields; do
            if ! jq -e ".$field" "$json_file" >/dev/null 2>&1; then
                missing_fields+=("$field")
            fi
        done
        
        if [[ ${#missing_fields[@]} -eq 0 ]]; then
            log_success "$file_desc JSONå¿…éœ€å­—æ®µå®Œæ•´"
        else
            log_error "$file_desc JSONç¼ºå°‘å­—æ®µ: ${missing_fields[*]}"
        fi
    fi
    
    return 0
}

# éªŒè¯data_loss_stats.jsonçš„é€»è¾‘ä¸€è‡´æ€§
validate_data_loss_stats_logic() {
    local stats_file="$1"
    
    if [[ ! -f "$stats_file" ]]; then
        log_error "ç»Ÿè®¡æ–‡ä»¶ä¸å­˜åœ¨: $stats_file"
        return 1
    fi
    
    check_count
    
    # æå–å…³é”®æ•°å€¼
    local data_loss_count=$(jq -r '.data_loss_count' "$stats_file" 2>/dev/null || echo "null")
    local data_loss_periods=$(jq -r '.data_loss_periods' "$stats_file" 2>/dev/null || echo "null")
    local total_duration=$(jq -r '.total_duration' "$stats_file" 2>/dev/null || echo "null")
    
    # éªŒè¯æ•°å€¼æœ‰æ•ˆæ€§
    local logic_errors=()
    
    # æ£€æŸ¥æ•°å€¼ç±»å‹
    if [[ "$data_loss_count" == "null" ]] || ! [[ "$data_loss_count" =~ ^[0-9]+$ ]]; then
        logic_errors+=("data_loss_countæ— æ•ˆ: $data_loss_count")
    fi
    
    if [[ "$data_loss_periods" == "null" ]] || ! [[ "$data_loss_periods" =~ ^[0-9]+$ ]]; then
        logic_errors+=("data_loss_periodsæ— æ•ˆ: $data_loss_periods")
    fi
    
    if [[ "$total_duration" == "null" ]] || ! [[ "$total_duration" =~ ^[0-9]+$ ]]; then
        logic_errors+=("total_durationæ— æ•ˆ: $total_duration")
    fi
    
    # éªŒè¯é€»è¾‘å…³ç³»
    if [[ "$data_loss_count" =~ ^[0-9]+$ ]] && [[ "$data_loss_periods" =~ ^[0-9]+$ ]]; then
        # data_loss_countåº”è¯¥ >= data_loss_periods (æ¯ä¸ªå‘¨æœŸè‡³å°‘1ä¸ªé‡‡æ ·)
        if [[ $data_loss_count -lt $data_loss_periods ]]; then
            logic_errors+=("é€»è¾‘é”™è¯¯: é‡‡æ ·æ•°($data_loss_count) < å‘¨æœŸæ•°($data_loss_periods)")
        fi
        
        # å¦‚æœæœ‰å‘¨æœŸä½†æ— é‡‡æ ·ï¼Œæˆ–æœ‰é‡‡æ ·ä½†æ— å‘¨æœŸï¼Œéƒ½æ˜¯å¼‚å¸¸
        if [[ $data_loss_periods -gt 0 && $data_loss_count -eq 0 ]]; then
            logic_errors+=("é€»è¾‘é”™è¯¯: æœ‰å‘¨æœŸ($data_loss_periods)ä½†æ— é‡‡æ ·($data_loss_count)")
        fi
        
        if [[ $data_loss_count -gt 0 && $data_loss_periods -eq 0 ]]; then
            logic_errors+=("é€»è¾‘é”™è¯¯: æœ‰é‡‡æ ·($data_loss_count)ä½†æ— å‘¨æœŸ($data_loss_periods)")
        fi
    fi
    
    # éªŒè¯æŒç»­æ—¶é—´é€»è¾‘
    if [[ "$total_duration" =~ ^[0-9]+$ ]] && [[ "$data_loss_periods" =~ ^[0-9]+$ ]]; then
        if [[ $data_loss_periods -gt 0 && $total_duration -eq 0 ]]; then
            logic_errors+=("é€»è¾‘é”™è¯¯: æœ‰å‘¨æœŸ($data_loss_periods)ä½†æ— æŒç»­æ—¶é—´($total_duration)")
        fi
    fi
    
    # è¾“å‡ºéªŒè¯ç»“æœ
    if [[ ${#logic_errors[@]} -eq 0 ]]; then
        log_success "æ•°æ®ä¸¢å¤±ç»Ÿè®¡é€»è¾‘ä¸€è‡´æ€§éªŒè¯é€šè¿‡"
        
        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        if [[ "$data_loss_count" =~ ^[0-9]+$ ]] && [[ "$data_loss_periods" =~ ^[0-9]+$ ]] && [[ "$total_duration" =~ ^[0-9]+$ ]]; then
            local avg_duration=0
            if [[ $data_loss_periods -gt 0 ]]; then
                avg_duration=$((total_duration / data_loss_periods))
            fi
            
            echo "    ğŸ“Š ç»Ÿè®¡æ‘˜è¦: ${data_loss_count}æ¬¡é‡‡æ ·, ${data_loss_periods}ä¸ªå‘¨æœŸ, ${total_duration}ç§’æ€»æ—¶é•¿, å¹³å‡${avg_duration}ç§’/å‘¨æœŸ"
        fi
    else
        log_error "æ•°æ®ä¸¢å¤±ç»Ÿè®¡é€»è¾‘éªŒè¯å¤±è´¥:"
        for error in "${logic_errors[@]}"; do
            echo "    ğŸ”´ $error"
        done
        return 1
    fi
    
    return 0
}

# éªŒè¯Vegetaç»“æœæ–‡ä»¶
validate_vegeta_file() {
    local vegeta_file="$1"
    local file_desc="$2"
    
    if [[ ! -f "$vegeta_file" ]]; then
        log_error "$file_desc Vegetaæ–‡ä»¶ä¸å­˜åœ¨: $vegeta_file"
        return 1
    fi
    
    # éªŒè¯JSONæ ¼å¼
    check_count
    if ! jq empty "$vegeta_file" 2>/dev/null; then
        log_error "$file_desc Vegeta JSONæ ¼å¼æ— æ•ˆ"
        return 1
    fi
    log_success "$file_desc Vegeta JSONæ ¼å¼æ­£ç¡®"
    
    # éªŒè¯æ¡†æ¶å®é™…ä½¿ç”¨çš„å­—æ®µ
    check_count
    local requests=$(jq -r '.requests' "$vegeta_file" 2>/dev/null || echo "null")
    local success_200=$(jq -r '.status_codes."200" // 0' "$vegeta_file" 2>/dev/null || echo "null")
    local avg_latency=$(jq -r '.latencies.mean' "$vegeta_file" 2>/dev/null || echo "null")
    
    # éªŒè¯å­—æ®µå­˜åœ¨æ€§å’Œæ•°å€¼æœ‰æ•ˆæ€§
    local field_errors=()
    
    if [[ "$requests" == "null" ]] || ! [[ "$requests" =~ ^[0-9]+$ ]] || [[ $requests -le 0 ]]; then
        field_errors+=("requestså­—æ®µæ— æ•ˆ: $requests")
    fi
    
    if [[ "$success_200" == "null" ]] || ! [[ "$success_200" =~ ^[0-9]+$ ]]; then
        field_errors+=("status_codes.200å­—æ®µæ— æ•ˆ: $success_200")
    fi
    
    if [[ "$avg_latency" == "null" ]] || ! [[ "$avg_latency" =~ ^[0-9]+$ ]]; then
        field_errors+=("latencies.meanå­—æ®µæ— æ•ˆ: $avg_latency")
    fi
    
    if [[ ${#field_errors[@]} -eq 0 ]]; then
        log_success "$file_desc Vegetaå…³é”®å­—æ®µæœ‰æ•ˆ"
    else
        log_error "$file_desc Vegetaå­—æ®µéªŒè¯å¤±è´¥: ${field_errors[*]}"
        return 1
    fi
    
    # éªŒè¯é€»è¾‘ä¸€è‡´æ€§
    check_count
    if [[ "$requests" =~ ^[0-9]+$ ]] && [[ "$success_200" =~ ^[0-9]+$ ]]; then
        if [[ $success_200 -le $requests ]]; then
            log_success "$file_desc Vegetaæ•°æ®é€»è¾‘ä¸€è‡´"
        else
            log_error "$file_desc Vegetaæ•°æ®é€»è¾‘é”™è¯¯: æˆåŠŸè¯·æ±‚($success_200) > æ€»è¯·æ±‚($requests)"
            return 1
        fi
    fi
    
    return 0
}

# æå–æ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯å’Œè­¦å‘Šä¿¡æ¯
extract_log_warnings_errors() {
    local log_file="$1"
    local file_desc="$2"
    
    if [[ ! -f "$log_file" ]]; then
        log_warn "$file_desc æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: $(basename "$log_file")"
        return 0
    fi
    
    check_count
    
    # æå–ERRORå’ŒWARNæ¶ˆæ¯ (æ”¯æŒå¤šç§æ ¼å¼)
    local errors=$(grep -i "ERROR\|\[ERROR\]\|âŒ" "$log_file" 2>/dev/null | head -10 || true)
    local warnings=$(grep -i "WARN\|\[WARN\]\|âš ï¸" "$log_file" 2>/dev/null | head -10 || true)
    
    # ç»Ÿè®¡æ•°é‡ - ä¿®å¤æ¢è¡Œç¬¦å¯¼è‡´çš„è¯­æ³•é”™è¯¯
    local error_count=$(echo "$errors" | grep -c . 2>/dev/null | tr -d '\n' || echo "0")
    local warn_count=$(echo "$warnings" | grep -c . 2>/dev/null | tr -d '\n' || echo "0")
    
    if [[ $error_count -eq 0 && $warn_count -eq 0 ]]; then
        log_success "$file_desc æ— é”™è¯¯æˆ–è­¦å‘Š"
        return 0
    fi
    
    # è¾“å‡ºé”™è¯¯ä¿¡æ¯
    if [[ -n "$errors" && $error_count -gt 0 ]]; then
        log_error "$file_desc å‘ç° $error_count ä¸ªé”™è¯¯:"
        echo "$errors" | while IFS= read -r line; do
            [[ -n "$line" ]] && echo "    ğŸ”´ $(echo "$line" | cut -c1-120)..."
        done
    fi
    
    # è¾“å‡ºè­¦å‘Šä¿¡æ¯
    if [[ -n "$warnings" && $warn_count -gt 0 ]]; then
        log_warn "$file_desc å‘ç° $warn_count ä¸ªè­¦å‘Š:"
        echo "$warnings" | while IFS= read -r line; do
            [[ -n "$line" ]] && echo "    ğŸŸ¡ $(echo "$line" | cut -c1-120)..."
        done
    fi
    
    # å¦‚æœæœ‰é”™è¯¯ï¼Œæ ‡è®°ä¸ºå¤±è´¥
    if [[ $error_count -gt 0 ]]; then
        log_error "$file_desc åŒ…å«é”™è¯¯ä¿¡æ¯"
        return 1
    else
        log_success "$file_desc ä»…æœ‰è­¦å‘Šï¼Œæ— é”™è¯¯"
        return 0
    fi
}

# ç”Ÿæˆé¢„æœŸçš„CSVè¡¨å¤´
generate_expected_csv_header() {
    local basic_header="timestamp,cpu_usage,cpu_usr,cpu_sys,cpu_iowait,cpu_soft,cpu_idle,mem_used,mem_total,mem_usage"
    
    # è®¾å¤‡è¡¨å¤´ (ä¸æ¡†æ¶å®é™…ç”Ÿæˆé€»è¾‘åŒæ­¥)
    local device_header=""
    if [[ -n "$LEDGER_DEVICE" ]]; then
        device_header="data_${LEDGER_DEVICE}_r_s,data_${LEDGER_DEVICE}_w_s,data_${LEDGER_DEVICE}_rkb_s,data_${LEDGER_DEVICE}_wkb_s,data_${LEDGER_DEVICE}_r_await,data_${LEDGER_DEVICE}_w_await,data_${LEDGER_DEVICE}_avg_await,data_${LEDGER_DEVICE}_aqu_sz,data_${LEDGER_DEVICE}_util,data_${LEDGER_DEVICE}_rrqm_s,data_${LEDGER_DEVICE}_wrqm_s,data_${LEDGER_DEVICE}_rrqm_pct,data_${LEDGER_DEVICE}_wrqm_pct,data_${LEDGER_DEVICE}_rareq_sz,data_${LEDGER_DEVICE}_wareq_sz,data_${LEDGER_DEVICE}_total_iops,data_${LEDGER_DEVICE}_aws_standard_iops,data_${LEDGER_DEVICE}_read_throughput_mibs,data_${LEDGER_DEVICE}_write_throughput_mibs,data_${LEDGER_DEVICE}_total_throughput_mibs,data_${LEDGER_DEVICE}_aws_standard_throughput_mibs"
    fi
    if [[ -n "$ACCOUNTS_DEVICE" && "$ACCOUNTS_DEVICE" != "$LEDGER_DEVICE" ]]; then
        if [[ -n "$device_header" ]]; then
            device_header="$device_header,accounts_${ACCOUNTS_DEVICE}_r_s,accounts_${ACCOUNTS_DEVICE}_w_s,accounts_${ACCOUNTS_DEVICE}_rkb_s,accounts_${ACCOUNTS_DEVICE}_wkb_s,accounts_${ACCOUNTS_DEVICE}_r_await,accounts_${ACCOUNTS_DEVICE}_w_await,accounts_${ACCOUNTS_DEVICE}_avg_await,accounts_${ACCOUNTS_DEVICE}_aqu_sz,accounts_${ACCOUNTS_DEVICE}_util,accounts_${ACCOUNTS_DEVICE}_rrqm_s,accounts_${ACCOUNTS_DEVICE}_wrqm_s,accounts_${ACCOUNTS_DEVICE}_rrqm_pct,accounts_${ACCOUNTS_DEVICE}_wrqm_pct,accounts_${ACCOUNTS_DEVICE}_rareq_sz,accounts_${ACCOUNTS_DEVICE}_wareq_sz,accounts_${ACCOUNTS_DEVICE}_total_iops,accounts_${ACCOUNTS_DEVICE}_aws_standard_iops,accounts_${ACCOUNTS_DEVICE}_read_throughput_mibs,accounts_${ACCOUNTS_DEVICE}_write_throughput_mibs,accounts_${ACCOUNTS_DEVICE}_total_throughput_mibs,accounts_${ACCOUNTS_DEVICE}_aws_standard_throughput_mibs"
        else
            device_header="accounts_${ACCOUNTS_DEVICE}_r_s,accounts_${ACCOUNTS_DEVICE}_w_s,accounts_${ACCOUNTS_DEVICE}_rkb_s,accounts_${ACCOUNTS_DEVICE}_wkb_s,accounts_${ACCOUNTS_DEVICE}_r_await,accounts_${ACCOUNTS_DEVICE}_w_await,accounts_${ACCOUNTS_DEVICE}_avg_await,accounts_${ACCOUNTS_DEVICE}_aqu_sz,accounts_${ACCOUNTS_DEVICE}_util,accounts_${ACCOUNTS_DEVICE}_rrqm_s,accounts_${ACCOUNTS_DEVICE}_wrqm_s,accounts_${ACCOUNTS_DEVICE}_rrqm_pct,accounts_${ACCOUNTS_DEVICE}_wrqm_pct,accounts_${ACCOUNTS_DEVICE}_rareq_sz,accounts_${ACCOUNTS_DEVICE}_wareq_sz,accounts_${ACCOUNTS_DEVICE}_total_iops,accounts_${ACCOUNTS_DEVICE}_aws_standard_iops,accounts_${ACCOUNTS_DEVICE}_read_throughput_mibs,accounts_${ACCOUNTS_DEVICE}_write_throughput_mibs,accounts_${ACCOUNTS_DEVICE}_total_throughput_mibs,accounts_${ACCOUNTS_DEVICE}_aws_standard_throughput_mibs"
        fi
    fi
    
    local network_header="net_interface,net_rx_mbps,net_tx_mbps,net_total_mbps,net_rx_gbps,net_tx_gbps,net_total_gbps,net_rx_pps,net_tx_pps,net_total_pps"
    local overhead_header="monitoring_iops_per_sec,monitoring_throughput_mibs_per_sec"
    local block_height_header="local_block_height,mainnet_block_height,block_height_diff,local_health,mainnet_health,data_loss"
    local qps_header="current_qps,rpc_latency_ms,qps_data_available"
    
    # ç»„è£…å®Œæ•´è¡¨å¤´
    local full_header="$basic_header"
    [[ -n "$device_header" ]] && full_header="$full_header,$device_header"
    full_header="$full_header,$network_header"
    
    # ENAå­—æ®µ (å¦‚æœå¯ç”¨) - åŠ¨æ€ç”Ÿæˆä¸æ¡†æ¶å®Œå…¨åŒæ­¥
    if [[ "$ENA_MONITOR_ENABLED" == "true" ]]; then
        # ä½¿ç”¨æ¡†æ¶ç›¸åŒçš„åŠ¨æ€ç”Ÿæˆé€»è¾‘
        local ena_header=""
        if [[ -n "$ENA_ALLOWANCE_FIELDS_STR" ]]; then
            ena_fields=($ENA_ALLOWANCE_FIELDS_STR)
            for field in "${ena_fields[@]}"; do
                if [[ -n "$ena_header" ]]; then
                    ena_header="$ena_header,$field"
                else
                    ena_header="$field"
                fi
            done
        fi
        [[ -n "$ena_header" ]] && full_header="$full_header,$ena_header"
    fi
    
    full_header="$full_header,$overhead_header,$block_height_header,$qps_header"
    echo "$full_header"
}

# éªŒè¯å½’æ¡£æ–‡ä»¶
validate_archive_files() {
    local run_number="$1"
    local archive_dir="$ARCHIVES_DIR/run_$run_number"
    
    log_info "éªŒè¯å½’æ¡£ run_$run_number çš„æ•°æ®æ–‡ä»¶..."
    
    if [[ ! -d "$archive_dir" ]]; then
        log_error "å½’æ¡£ç›®å½•ä¸å­˜åœ¨: $archive_dir"
        return 1
    fi
    
    # éªŒè¯ä¸»è¦CSVæ–‡ä»¶
    local logs_dir="$archive_dir/logs"
    if [[ -d "$logs_dir" ]]; then
        # æŸ¥æ‰¾æ€§èƒ½æ•°æ®æ–‡ä»¶
        local perf_csv=$(find "$logs_dir" -name "performance_*.csv" | head -1)
        if [[ -n "$perf_csv" ]]; then
            local expected_header=$(generate_expected_csv_header)
            validate_csv_file "$perf_csv" "æ€§èƒ½æ•°æ®" "$expected_header"
        else
            log_error "æœªæ‰¾åˆ°æ€§èƒ½æ•°æ®CSVæ–‡ä»¶"
        fi
        
        # éªŒè¯åŒºå—é«˜åº¦ç›‘æ§æ–‡ä»¶
        local block_csv=$(find "$logs_dir" -name "block_height_monitor_*.csv" | head -1)
        if [[ -n "$block_csv" ]]; then
            local block_header="timestamp,local_block_height,mainnet_block_height,block_height_diff,local_health,mainnet_health,data_loss"
            validate_csv_file "$block_csv" "åŒºå—é«˜åº¦ç›‘æ§" "$block_header"
        else
            log_warn "æœªæ‰¾åˆ°åŒºå—é«˜åº¦ç›‘æ§CSVæ–‡ä»¶"
        fi
        
        # éªŒè¯ç›‘æ§å¼€é”€æ–‡ä»¶
        local overhead_csv=$(find "$logs_dir" -name "monitoring_overhead_*.csv" | head -1)
        if [[ -n "$overhead_csv" ]]; then
            validate_csv_file "$overhead_csv" "ç›‘æ§å¼€é”€" ""
        else
            log_warn "æœªæ‰¾åˆ°ç›‘æ§å¼€é”€CSVæ–‡ä»¶"
        fi
        
        # éªŒè¯æ—¥å¿—æ–‡ä»¶ (æå–é”™è¯¯å’Œè­¦å‘Š)
        log_info "æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯å’Œè­¦å‘Šä¿¡æ¯..."
        
        # æ£€æŸ¥å„ç§æ—¥å¿—æ–‡ä»¶
        for log_pattern in "ebs_bottleneck_detector.log" "ebs_analyzer.log" "master_qps_executor.log" "monitoring_performance_*.log" "monitoring_errors_*.log"; do
            local log_files=$(find "$logs_dir" -name "$log_pattern" 2>/dev/null)
            if [[ -n "$log_files" ]]; then
                while IFS= read -r log_file; do
                    [[ -n "$log_file" ]] && extract_log_warnings_errors "$log_file" "$(basename "$log_file")"
                done <<< "$log_files"
            fi
        done
    else
        log_error "å½’æ¡£æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: $logs_dir"
    fi
    
    # éªŒè¯å½’æ¡£ä¸­çš„ç»Ÿè®¡æ–‡ä»¶
    local stats_dir="$archive_dir/stats"
    if [[ -d "$stats_dir" ]]; then
        log_info "éªŒè¯å½’æ¡£ç»Ÿè®¡æ–‡ä»¶..."
        
        # éªŒè¯data_loss_stats.json
        if [[ -f "$stats_dir/data_loss_stats.json" ]]; then
            local required_stats_fields="data_loss_count data_loss_periods total_duration last_updated"
            validate_json_file "$stats_dir/data_loss_stats.json" "æ•°æ®ä¸¢å¤±ç»Ÿè®¡" "$required_stats_fields"
            
            # éªŒè¯ç»Ÿè®¡æ•°æ®çš„é€»è¾‘ä¸€è‡´æ€§
            validate_data_loss_stats_logic "$stats_dir/data_loss_stats.json"
        else
            log_warn "æœªæ‰¾åˆ°data_loss_stats.jsonæ–‡ä»¶ - å¯èƒ½æµ‹è¯•æœŸé—´æ— æ•°æ®ä¸¢å¤±äº‹ä»¶"
        fi
        
        # éªŒè¯bottleneck_status.json
        if [[ -f "$stats_dir/bottleneck_status.json" ]]; then
            local required_bottleneck_fields="status bottleneck_detected"
            validate_json_file "$stats_dir/bottleneck_status.json" "ç“¶é¢ˆçŠ¶æ€" "$required_bottleneck_fields"
        else
            log_warn "æœªæ‰¾åˆ°bottleneck_status.jsonæ–‡ä»¶"
        fi
    else
        log_warn "æœªæ‰¾åˆ°å½’æ¡£ç»Ÿè®¡ç›®å½•: $stats_dir"
    fi
    
    # éªŒè¯Vegetaç»“æœæ–‡ä»¶
    local vegeta_dir="$archive_dir/vegeta_results"
    if [[ -d "$vegeta_dir" ]]; then
        log_info "éªŒè¯Vegetaæµ‹è¯•ç»“æœæ–‡ä»¶..."
        
        local vegeta_files=$(find "$vegeta_dir" -name "*.json" 2>/dev/null)
        if [[ -n "$vegeta_files" ]]; then
            local vegeta_count=0
            while IFS= read -r vegeta_file; do
                if [[ -n "$vegeta_file" ]]; then
                    validate_vegeta_file "$vegeta_file" "Vegetaç»“æœ[$(basename "$vegeta_file")]"
                    ((vegeta_count++))
                fi
            done <<< "$vegeta_files"
            
            if [[ $vegeta_count -eq 0 ]]; then
                log_warn "Vegetaç»“æœç›®å½•å­˜åœ¨ä½†æ— JSONæ–‡ä»¶"
            fi
        else
            log_warn "æœªæ‰¾åˆ°Vegetaç»“æœJSONæ–‡ä»¶"
        fi
    else
        log_warn "æœªæ‰¾åˆ°Vegetaç»“æœç›®å½•: $vegeta_dir"
    fi
}

# éªŒè¯å…±äº«å†…å­˜æ–‡ä»¶
validate_shared_memory_files() {
    log_info "éªŒè¯å…±äº«å†…å­˜ç¼“å­˜æ–‡ä»¶..."
    
    if [[ ! -d "$MEMORY_SHARE_DIR" ]]; then
        log_warn "å…±äº«å†…å­˜ç›®å½•ä¸å­˜åœ¨: $MEMORY_SHARE_DIR (å¯èƒ½å·²è¢«æ¸…ç†)"
        return 0
    fi
    
    # éªŒè¯æ ¸å¿ƒæŒ‡æ ‡JSON (å¦‚æœå­˜åœ¨)
    if [[ -f "$MEMORY_SHARE_DIR/latest_metrics.json" ]]; then
        validate_json_file "$MEMORY_SHARE_DIR/latest_metrics.json" "æ ¸å¿ƒæŒ‡æ ‡" "timestamp cpu_usage memory_usage"
    else
        log_info "å…±äº«å†…å­˜æ–‡ä»¶å·²è¢«æ¸…ç†ï¼Œè·³è¿‡æ ¸å¿ƒæŒ‡æ ‡éªŒè¯ (æ¡†æ¶æ­£å¸¸è¡Œä¸º)"
    fi
    
    # éªŒè¯è¯¦ç»†æŒ‡æ ‡JSON (å¦‚æœå­˜åœ¨)
    if [[ -f "$MEMORY_SHARE_DIR/unified_metrics.json" ]]; then
        validate_json_file "$MEMORY_SHARE_DIR/unified_metrics.json" "è¯¦ç»†æŒ‡æ ‡" "timestamp cpu_usage memory_usage detailed_data"
    else
        log_info "å…±äº«å†…å­˜æ–‡ä»¶å·²è¢«æ¸…ç†ï¼Œè·³è¿‡è¯¦ç»†æŒ‡æ ‡éªŒè¯ (æ¡†æ¶æ­£å¸¸è¡Œä¸º)"
    fi
    
    # éªŒè¯åŒºå—é«˜åº¦ç¼“å­˜ (å¦‚æœå­˜åœ¨)
    if [[ -f "$MEMORY_SHARE_DIR/block_height_monitor_cache.json" ]]; then
        validate_json_file "$MEMORY_SHARE_DIR/block_height_monitor_cache.json" "åŒºå—é«˜åº¦ç¼“å­˜" "timestamp local_block_height mainnet_block_height"
    else
        log_info "å…±äº«å†…å­˜æ–‡ä»¶å·²è¢«æ¸…ç†ï¼Œè·³è¿‡åŒºå—é«˜åº¦ç¼“å­˜éªŒè¯ (æ¡†æ¶æ­£å¸¸è¡Œä¸º)"
    fi
    
    # éªŒè¯é‡‡æ ·è®¡æ•°æ–‡ä»¶ (å¦‚æœå­˜åœ¨)
    if [[ -f "$MEMORY_SHARE_DIR/sample_count" ]]; then
        validate_file_exists "$MEMORY_SHARE_DIR/sample_count" "é‡‡æ ·è®¡æ•°"
    else
        log_info "å…±äº«å†…å­˜æ–‡ä»¶å·²è¢«æ¸…ç†ï¼Œè·³è¿‡é‡‡æ ·è®¡æ•°éªŒè¯ (æ¡†æ¶æ­£å¸¸è¡Œä¸º)"
    fi
    
    # éªŒè¯å…¶ä»–å¯é€‰æ–‡ä»¶
    [[ -f "$MEMORY_SHARE_DIR/data_loss_stats.json" ]] && validate_json_file "$MEMORY_SHARE_DIR/data_loss_stats.json" "æ•°æ®ä¸¢å¤±ç»Ÿè®¡" ""
    [[ -f "$MEMORY_SHARE_DIR/bottleneck_status.json" ]] && validate_json_file "$MEMORY_SHARE_DIR/bottleneck_status.json" "ç“¶é¢ˆçŠ¶æ€" ""
    [[ -f "$MEMORY_SHARE_DIR/unified_events.json" ]] && validate_json_file "$MEMORY_SHARE_DIR/unified_events.json" "ç»Ÿä¸€äº‹ä»¶" ""
}

# éªŒè¯æ•°æ®ä¸€è‡´æ€§
validate_data_consistency() {
    local run_number="$1"
    
    log_info "éªŒè¯æ•°æ®ä¸€è‡´æ€§..."
    
    # å¦‚æœå…±äº«å†…å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸€è‡´æ€§æ£€æŸ¥
    if [[ ! -d "$MEMORY_SHARE_DIR" ]]; then
        log_warn "å…±äº«å†…å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¸€è‡´æ€§éªŒè¯"
        return 0
    fi
    
    # éªŒè¯é‡‡æ ·è®¡æ•°ä¸€è‡´æ€§
    if [[ -f "$MEMORY_SHARE_DIR/sample_count" ]]; then
        check_count
        local sample_count=$(cat "$MEMORY_SHARE_DIR/sample_count" 2>/dev/null || echo "0")
        if [[ "$sample_count" =~ ^[0-9]+$ ]] && [[ $sample_count -gt 0 ]]; then
            log_success "é‡‡æ ·è®¡æ•°æœ‰æ•ˆ: $sample_count"
        else
            log_error "é‡‡æ ·è®¡æ•°æ— æ•ˆ: $sample_count"
        fi
    fi
    
    # éªŒè¯æ—¶é—´æˆ³ä¸€è‡´æ€§ (JSON vs CSV)
    local archive_dir="$ARCHIVES_DIR/run_$run_number"
    local perf_csv=$(find "$archive_dir/logs" -name "performance_*.csv" 2>/dev/null | head -1)
    
    if [[ -n "$perf_csv" && -f "$MEMORY_SHARE_DIR/latest_metrics.json" ]]; then
        check_count
        local csv_last_timestamp=$(tail -1 "$perf_csv" | cut -d',' -f1)
        local json_timestamp=$(jq -r '.timestamp' "$MEMORY_SHARE_DIR/latest_metrics.json" 2>/dev/null)
        
        if [[ -n "$csv_last_timestamp" && -n "$json_timestamp" && "$json_timestamp" != "null" ]]; then
            # ç®€å•çš„æ—¶é—´æˆ³æ ¼å¼æ£€æŸ¥ - ä¿®å¤ä¸ºç©ºæ ¼åˆ†éš”æ ¼å¼
            if [[ "$csv_last_timestamp" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}\ [0-9]{2}:[0-9]{2}:[0-9]{2} ]] && 
               [[ "$json_timestamp" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}\ [0-9]{2}:[0-9]{2}:[0-9]{2} ]]; then
                log_success "æ—¶é—´æˆ³æ ¼å¼ä¸€è‡´"
            else
                log_error "æ—¶é—´æˆ³æ ¼å¼ä¸ä¸€è‡´: CSV=$csv_last_timestamp, JSON=$json_timestamp"
            fi
        else
            log_warn "æ— æ³•è·å–æœ‰æ•ˆæ—¶é—´æˆ³è¿›è¡Œä¸€è‡´æ€§éªŒè¯"
        fi
    fi
}

# ç”ŸæˆéªŒè¯æŠ¥å‘Š
generate_validation_report() {
    local run_number="$1"
    
    echo ""
    echo "========================================"
    echo "ğŸ” æ¡†æ¶æ•°æ®éªŒè¯æŠ¥å‘Š"
    echo "========================================"
    echo "éªŒè¯æ—¶é—´: $(date)"
    echo "å½’æ¡£ç¼–å·: run_$run_number"
    echo "é…ç½®ç¯å¢ƒ: $DEPLOYMENT_PLATFORM"
    echo "ENAç›‘æ§: $ENA_MONITOR_ENABLED"
    echo ""
    echo "ğŸ“Š éªŒè¯ç»Ÿè®¡:"
    echo "  æ€»æ£€æŸ¥é¡¹: $TOTAL_CHECKS"
    echo "  é€šè¿‡æ£€æŸ¥: $PASSED_CHECKS"
    echo "  å¤±è´¥æ£€æŸ¥: $FAILED_CHECKS"
    
    local success_rate=0
    if [[ $TOTAL_CHECKS -gt 0 ]]; then
        success_rate=$((PASSED_CHECKS * 100 / TOTAL_CHECKS))
    fi
    echo "  æˆåŠŸç‡: $success_rate%"
    
    echo ""
    echo "ğŸ“‹ éªŒè¯è¦†ç›–èŒƒå›´:"
    echo "  âœ… CSVæ•°æ®æ–‡ä»¶ (è¡¨å¤´ã€æ ¼å¼ã€æ—¶é—´æˆ³)"
    echo "  âœ… JSONé…ç½®æ–‡ä»¶ (æ ¼å¼ã€å¿…éœ€å­—æ®µ)"
    echo "  âœ… Vegetaç»“æœæ–‡ä»¶ (å…³é”®å­—æ®µã€é€»è¾‘ä¸€è‡´æ€§)"
    echo "  âœ… å½’æ¡£ç»Ÿè®¡æ–‡ä»¶ (data_loss_stats.jsoné€»è¾‘éªŒè¯)"
    echo "  âœ… å…±äº«å†…å­˜ç¼“å­˜æ–‡ä»¶ (5åˆ†é’ŸTTLå†…)"
    echo "  âœ… æ—¥å¿—æ–‡ä»¶ (é”™è¯¯å’Œè­¦å‘Šæå–)"
    echo "  âœ… æ•°æ®ä¸€è‡´æ€§ (æ—¶é—´æˆ³ã€é‡‡æ ·è®¡æ•°)"
    echo ""
    echo "ğŸ“Š éªŒè¯è¦†ç›–ç‡: ~90% (æ–°å¢å½’æ¡£ç»Ÿè®¡æ–‡ä»¶éªŒè¯)"
    
    if [[ $FAILED_CHECKS -eq 0 ]]; then
        echo ""
        echo "âœ… æ•°æ®éªŒè¯é€šè¿‡ - æ‰€æœ‰æ£€æŸ¥é¡¹ç›®éƒ½æ­£å¸¸"
        echo "ğŸ‰ æ•°æ®è´¨é‡è¯„åˆ†: $success_rate/100"
        echo ""
        echo "ğŸ” éªŒè¯è¯¦æƒ…:"
        echo "  â€¢ æ‰€æœ‰CSVæ–‡ä»¶è¡¨å¤´æ ¼å¼æ­£ç¡®"
        echo "  â€¢ æ‰€æœ‰JSONæ–‡ä»¶ç»“æ„å®Œæ•´"
        echo "  â€¢ Vegetaæµ‹è¯•ç»“æœæ•°æ®æœ‰æ•ˆ"
        echo "  â€¢ å½’æ¡£ç»Ÿè®¡æ–‡ä»¶é€»è¾‘ä¸€è‡´"
        echo "  â€¢ æ—¥å¿—æ–‡ä»¶æ— ä¸¥é‡é”™è¯¯"
        echo "  â€¢ æ•°æ®æ—¶é—´æˆ³ä¸€è‡´æ€§è‰¯å¥½"
    else
        echo ""
        echo "âŒ æ•°æ®éªŒè¯å¤±è´¥ - å‘ç° $FAILED_CHECKS ä¸ªé—®é¢˜"
        echo "ğŸ“‹ é”™è¯¯è¯¦æƒ…:"
        for error in "${VALIDATION_ERRORS[@]}"; do
            echo "  â€¢ $error"
        done
        echo ""
        echo "âš ï¸  æ•°æ®è´¨é‡è¯„åˆ†: $success_rate/100"
        echo ""
        echo "ğŸ”§ å»ºè®®ä¿®å¤:"
        echo "  1. æ£€æŸ¥CSVæ–‡ä»¶è¡¨å¤´æ˜¯å¦ä¸é…ç½®åŒ¹é…"
        echo "  2. éªŒè¯JSONæ–‡ä»¶æ ¼å¼å’Œå¿…éœ€å­—æ®µ"
        echo "  3. ç¡®è®¤Vegetaæµ‹è¯•æ­£å¸¸æ‰§è¡Œ"
        echo "  4. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯ä¿¡æ¯"
        echo "  5. æ£€æŸ¥æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„æ—¶åºé—®é¢˜"
    fi
    
    echo "========================================"
}

# ä¸»å‡½æ•°
main() {
    echo "ğŸ” å¼€å§‹æ¡†æ¶æ•°æ®éªŒè¯..."
    echo ""
    
    # è·å–æœ€æ–°å½’æ¡£ç¼–å·
    local latest_run=$(get_latest_archive_number)
    
    if [[ "$latest_run" == "000" ]]; then
        log_error "æœªæ‰¾åˆ°ä»»ä½•å½’æ¡£æ•°æ®"
        exit 1
    fi
    
    log_info "æ£€æµ‹åˆ°æœ€æ–°å½’æ¡£: run_$latest_run"
    echo ""
    
    # æ‰§è¡ŒéªŒè¯
    validate_archive_files "$latest_run"
    echo ""
    
    validate_shared_memory_files
    echo ""
    
    validate_data_consistency "$latest_run"
    echo ""
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_validation_report "$latest_run"
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    if [[ $FAILED_CHECKS -eq 0 ]]; then
        exit 0
    else
        exit 1
    fi
}

# è„šæœ¬å…¥å£
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
