#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Comprehensive Analyzer - Refactored integrated version with bottleneck mode support
Integrates RPC deep analyzer and QPS analyzer for blockchain node performance testing
Provides unified analysis entry point and complete report generation
Supports bottleneck detection mode and time window analysis
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np
import glob
import os
import sys

# Configure font support for cross-platform compatibility
def setup_font():
    """Configure matplotlib font for cross-platform compatibility"""
    # Use standard fonts that work across all platforms
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    print("âœ… SUCCESS: Comprehensive Analysis using font: DejaVu Sans")
    return True

# Initialize font configuration
setup_font()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.unified_logger import get_logger
import json
import argparse
import random
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Tuple

class DataProcessor:
    """æ•°æ®å¤„ç†å·¥å…·ç±» - è§£å†³æ•°æ®å¤„ç†é‡å¤ä»£ç """
    
    @staticmethod
    def validate_dataframe_column(df: pd.DataFrame, column: str) -> bool:
        """éªŒè¯DataFrameæ˜¯å¦åŒ…å«æŒ‡å®šåˆ—ä¸”æœ‰æ•°æ®"""
        return column in df.columns and len(df) > 0 and not df[column].empty
    
    @staticmethod
    def safe_calculate_mean(df: pd.DataFrame, column: str) -> float:
        """å®‰å…¨è®¡ç®—åˆ—çš„å¹³å‡å€¼ - è§£å†³é‡å¤çš„å‡å€¼è®¡ç®—ä»£ç """
        if DataProcessor.validate_dataframe_column(df, column):
            return df[column].mean()
        return 0.0
    
    @staticmethod
    def safe_calculate_max(df: pd.DataFrame, column: str) -> float:
        """å®‰å…¨è®¡ç®—åˆ—çš„æœ€å¤§å€¼"""
        if DataProcessor.validate_dataframe_column(df, column):
            return df[column].max()
        return 0.0

class FileManager:
    """æ–‡ä»¶ç®¡ç†å·¥å…·ç±» - æ™ºèƒ½æ–‡ä»¶ä¿å­˜ï¼Œæ”¯æŒå¤‡ä»½å’Œå›ºå®šåç§°"""
    
    def __init__(self, output_dir: str, session_timestamp: str):
        self.output_dir = output_dir
        self.session_timestamp = session_timestamp
        self.reports_dir = os.getenv('REPORTS_DIR', os.path.join(output_dir, 'current', 'reports'))
        os.makedirs(self.reports_dir, exist_ok=True)
    
    def save_chart_with_backup(self, chart_name: str, plt_figure) -> str:
        """ä¿å­˜å›¾è¡¨ï¼ŒåŒæ—¶åˆ›å»ºå¤‡ä»½å’Œå½“å‰ç‰ˆæœ¬"""
        # å›ºå®šåç§°æ–‡ä»¶ï¼ˆä¾›å…¶ä»–ç»„ä»¶å¼•ç”¨ï¼‰
        current_path = os.path.join(self.reports_dir, f'{chart_name}.png')
        
        # å¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶
        backup_path = os.path.join(self.reports_dir, f'{chart_name}_{self.session_timestamp}.png')
        
        # ä¿å­˜ä¸¤ä¸ªç‰ˆæœ¬
        plt_figure.savefig(current_path, dpi=300, bbox_inches='tight')
        plt_figure.savefig(backup_path, dpi=300, bbox_inches='tight')
        
        logger.info(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {current_path} (å½“å‰ç‰ˆæœ¬)")
        logger.info(f"ğŸ“Š å¤‡ä»½å·²åˆ›å»º: {backup_path}")
        
        return current_path
    
    def save_report_with_backup(self, report_name: str, content: str) -> str:
        """ä¿å­˜æŠ¥å‘Šï¼ŒåŒæ—¶åˆ›å»ºå¤‡ä»½å’Œå½“å‰ç‰ˆæœ¬"""
        # å›ºå®šåç§°æ–‡ä»¶ï¼ˆä¾›å…¶ä»–ç»„ä»¶å¼•ç”¨ï¼‰
        current_path = os.path.join(self.reports_dir, f'{report_name}.md')
        
        # å¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶
        backup_path = os.path.join(self.reports_dir, f'{report_name}_{self.session_timestamp}.md')
        
        # ä¿å­˜ä¸¤ä¸ªç‰ˆæœ¬
        with open(current_path, 'w', encoding='utf-8') as f:
            f.write(content)
        with open(backup_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {current_path} (å½“å‰ç‰ˆæœ¬)")
        logger.info(f"ğŸ“„ å¤‡ä»½å·²åˆ›å»º: {backup_path}")
        
        return current_path

class OperationLogger:
    """æ“ä½œæ—¥å¿—è£…é¥°å™¨ - ç»Ÿä¸€æ—¥å¿—æ ¼å¼ï¼Œè§£å†³printè¯­å¥é‡å¤é—®é¢˜"""
    
    @staticmethod
    def log_operation(operation_name: str, emoji: str = "ğŸ“Š"):
        """è®°å½•æ“ä½œçš„è£…é¥°å™¨"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                print(f"\n{emoji} {operation_name}...")
                try:
                    result = func(*args, **kwargs)
                    logger.info(f"âœ… {operation_name} completed successfully")
                    return result
                except Exception as e:
                    logger.error(f"âŒ {operation_name} failed: {e}")
                    raise
            return wrapper
        return decorator

# é…ç½®æ—¥å¿—
logger = get_logger(__name__)

# æ·»åŠ è·¯å¾„ä»¥æ”¯æŒé‡ç»„åçš„ç›®å½•ç»“æ„
from pathlib import Path

# ä½¿ç”¨æ›´å¥å£®çš„è·¯å¾„ç®¡ç†
current_dir = Path(__file__).parent
project_root = current_dir.parent
utils_dir = project_root / 'utils'
visualization_dir = project_root / 'visualization'
analysis_dir = current_dir  # æ·»åŠ å½“å‰analysisç›®å½•

# æ·»åŠ è·¯å¾„åˆ°sys.path
for path in [str(utils_dir), str(visualization_dir), str(analysis_dir)]:
    if path not in sys.path:
        sys.path.insert(0, path)

# å¯¼å…¥æ‹†åˆ†åçš„æ¨¡å—
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºæ¨¡å—å¯¼å…¥æ—¶ï¼‰
    from .rpc_deep_analyzer import RpcDeepAnalyzer
    from .qps_analyzer import NodeQPSAnalyzer
    logger.info("âœ… æ‰€æœ‰åˆ†ææ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError:
    try:
        # å°è¯•ç›´æ¥å¯¼å…¥ï¼ˆå½“ç›´æ¥è¿è¡Œè„šæœ¬æ—¶ï¼‰
        from rpc_deep_analyzer import RpcDeepAnalyzer
        from qps_analyzer import NodeQPSAnalyzer
        logger.info("âœ… æ‰€æœ‰åˆ†ææ¨¡å—åŠ è½½æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ åˆ†ææ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

class BottleneckAnalysisMode:
    """ç“¶é¢ˆåˆ†ææ¨¡å¼é…ç½®"""
    
    def __init__(self, bottleneck_info: Optional[Dict] = None):
        # åªæœ‰å½“æä¾›äº†æœ‰æ•ˆçš„ç“¶é¢ˆä¿¡æ¯æ—¶æ‰å¯ç”¨
        self.enabled = bottleneck_info is not None and len(bottleneck_info) > 0
        self.bottleneck_info = bottleneck_info or {}
        self.bottleneck_time = None
        self.analysis_window = None
        self.max_qps = 0
        self.bottleneck_qps = 0
        
        if self.enabled:
            self._parse_bottleneck_info()
    
    def _parse_bottleneck_info(self):
        """è§£æç“¶é¢ˆä¿¡æ¯"""
        try:
            self.bottleneck_time = self.bottleneck_info.get('detection_time')
            self.analysis_window = self.bottleneck_info.get('analysis_window', {})
            self.max_qps = self.bottleneck_info.get('max_successful_qps', 0)
            self.bottleneck_qps = self.bottleneck_info.get('bottleneck_qps', 0)
            
            logger.info(f"ğŸš¨ ç“¶é¢ˆåˆ†ææ¨¡å¼: æœ€å¤§QPS={self.max_qps}, ç“¶é¢ˆQPS={self.bottleneck_qps}")
        except Exception as e:
            logger.error(f"âŒ ç“¶é¢ˆä¿¡æ¯è§£æå¤±è´¥: {e}")
            self.enabled = False

class ComprehensiveAnalyzer:
    """ç»¼åˆåˆ†æå™¨ - æ•´åˆæ‰€æœ‰åˆ†æåŠŸèƒ½çš„ä¸»æ§åˆ¶å™¨ + ç“¶é¢ˆæ¨¡å¼æ”¯æŒ"""

    def __init__(self, output_dir: Optional[str] = None, benchmark_mode: str = "standard", bottleneck_mode: Optional[BottleneckAnalysisMode] = None):
        """
        åˆå§‹åŒ–ç»¼åˆåˆ†æå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneï¼Œå°†ä»ç¯å¢ƒå˜é‡è·å–ï¼‰
            benchmark_mode: åŸºå‡†æµ‹è¯•æ¨¡å¼ (quick/standard/intensive)
            bottleneck_mode: ç“¶é¢ˆåˆ†ææ¨¡å¼é…ç½®
        """
        if output_dir is None:
            output_dir = os.environ.get('DATA_DIR', os.path.join(os.path.expanduser('~'), 'blockchain-node-benchmark-result'))
        
        # åˆ›å»ºä¼šè¯æ—¶é—´æˆ³ï¼Œç”¨äºå¤‡ä»½æ–‡ä»¶å‘½å
        self.session_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        self.output_dir = output_dir
        self.benchmark_mode = benchmark_mode
        self.csv_file = self.get_latest_csv()
        self.bottleneck_mode = bottleneck_mode or BottleneckAnalysisMode()
        
        # åˆå§‹åŒ–å„ä¸ªåˆ†æå™¨
        self.qps_analyzer = NodeQPSAnalyzer(output_dir, benchmark_mode, self.bottleneck_mode.enabled)
        self.rpc_deep_analyzer = RpcDeepAnalyzer(self.csv_file)
        
        # åˆå§‹åŒ–æ–‡ä»¶ç®¡ç†å™¨
        self.file_manager = FileManager(self.output_dir, self.session_timestamp)
        
        # Using English labels system directly
        
        logger.info(f"ğŸ” åˆå§‹åŒ–ç»¼åˆåˆ†æå™¨ï¼Œè¾“å‡ºç›®å½•: {output_dir}")
        if self.bottleneck_mode.enabled:
            logger.info(f"ğŸš¨ ç“¶é¢ˆåˆ†ææ¨¡å¼å·²å¯ç”¨")
    
    def get_latest_csv(self) -> Optional[str]:
        """è·å–æœ€æ–°çš„CSVç›‘æ§æ–‡ä»¶"""
        # ä½¿ç”¨ç¯å¢ƒå˜é‡LOGS_DIRï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨current/logsç»“æ„
        logs_dir = os.getenv('LOGS_DIR', os.path.join(self.output_dir, 'current', 'logs'))
        csv_files = glob.glob(f"{logs_dir}/*.csv")
        if not csv_files:
            # å¤‡ç”¨æŸ¥æ‰¾ï¼šæ£€æŸ¥archivesç›®å½•
            csv_files = glob.glob(f"{self.output_dir}/archives/*/logs/*.csv")
        return max(csv_files, key=os.path.getctime) if csv_files else None

    @staticmethod
    def filter_data_by_time_window(df: pd.DataFrame, start_time: str, end_time: str) -> pd.DataFrame:
        """æ ¹æ®æ—¶é—´çª—å£è¿‡æ»¤æ•°æ® - é™æ€æ–¹æ³•"""
        try:
            if 'timestamp' not in df.columns:
                logger.warning("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰timestampåˆ—ï¼Œæ— æ³•è¿›è¡Œæ—¶é—´çª—å£è¿‡æ»¤")
                return df
            
            # è½¬æ¢æ—¶é—´æˆ³
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            start_dt = pd.to_datetime(start_time)
            end_dt = pd.to_datetime(end_time)
            
            # è¿‡æ»¤æ•°æ®
            filtered_df = df[(df['timestamp'] >= start_dt) & (df['timestamp'] <= end_dt)]
            logger.info(f"ğŸ“Š æ—¶é—´çª—å£è¿‡æ»¤: {len(df)} -> {len(filtered_df)} æ¡è®°å½•")
            
            return filtered_df
        except Exception as e:
            logger.error(f"âŒ æ—¶é—´çª—å£è¿‡æ»¤å¤±è´¥: {e}")
            return df

    def analyze_bottleneck_correlation(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æç“¶é¢ˆç›¸å…³æ€§"""
        if not self.bottleneck_mode.enabled:
            return {}
        
        try:
            analysis_result = {
                'bottleneck_detected': True,
                'max_qps': self.bottleneck_mode.max_qps,
                'bottleneck_qps': self.bottleneck_mode.bottleneck_qps,
                'performance_drop': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'correlations': {},
                'bottleneck_factors': []
            }
            
            # è®¡ç®—æ€§èƒ½ä¸‹é™
            if self.bottleneck_mode.max_qps > 0:
                performance_drop = ((self.bottleneck_mode.bottleneck_qps - self.bottleneck_mode.max_qps) / 
                                  self.bottleneck_mode.max_qps * 100)
                analysis_result['performance_drop'] = performance_drop
            
            # åˆ†æå„æŒ‡æ ‡ä¸QPSçš„ç›¸å…³æ€§
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            qps_column = None
            
            # å¯»æ‰¾QPSåˆ—
            for col in ['current_qps', 'qps', 'requests_per_second']:
                if col in df.columns:
                    qps_column = col
                    break
            
            if qps_column:
                for col in numeric_columns:
                    if col != qps_column and len(df[col].dropna()) > 1:
                        try:
                            correlation = df[qps_column].corr(df[col])
                            if not np.isnan(correlation):
                                analysis_result['correlations'][col] = correlation
                                
                                # è¯†åˆ«ç“¶é¢ˆå› å­
                                if abs(correlation) > 0.7:
                                    analysis_result['bottleneck_factors'].append({
                                        'metric': col,
                                        'correlation': correlation,
                                        'impact': 'high' if abs(correlation) > 0.8 else 'medium'
                                    })
                        except Exception as e:
                            logger.warning(f"âš ï¸ è®¡ç®—{col}ç›¸å…³æ€§å¤±è´¥: {e}")
            
            logger.info(f"ğŸ” ç“¶é¢ˆç›¸å…³æ€§åˆ†æå®Œæˆï¼Œå‘ç°{len(analysis_result['bottleneck_factors'])}ä¸ªå…³é”®å› å­")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ ç“¶é¢ˆç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")
            return {}

    def generate_ultimate_performance_charts(self, df: pd.DataFrame, 
                                           rpc_deep_analysis: Dict[str, Any]) -> Optional[plt.Figure]:
        """ç”Ÿæˆç»ˆææ€§èƒ½å›¾è¡¨ï¼Œæ•´åˆæ‰€æœ‰åˆ†æç»“æœ"""
        print("\nğŸ“ˆ Generating ultimate performance charts...")

        if len(df) == 0:
            print("âŒ No QPS data for chart generation")
            return None

        plt.style.use('default')
        fig, axes = plt.subplots(3, 2, figsize=(16, 18))
        # Using English title directly
        fig.suptitle('Blockchain Node QPS Ultimate Performance Analysis Dashboard', fontsize=16, fontweight='bold')

        # æ£€æŸ¥QPSæ•°æ®å¯ç”¨æ€§
        qps_available = 'qps_data_available' in df.columns and df['qps_data_available'].iloc[0] if len(df) > 0 else False
        
        # 1. CPUä½¿ç”¨ç‡ vs QPS
        if len(df) > 0 and 'cpu_usage' in df.columns and qps_available and 'current_qps' in df.columns:
            axes[0, 0].plot(df['current_qps'], df['cpu_usage'], 'bo-', alpha=0.7, markersize=4)
            axes[0, 0].axhline(y=85, color='red', linestyle='--', alpha=0.8, label='Warning (85%)')
            axes[0, 0].set_title('CPU Usage vs QPS')
            axes[0, 0].set_xlabel('QPS')
            axes[0, 0].set_ylabel('CPU %')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
        else:
            axes[0, 0].text(0.5, 0.5, 'QPS Data Not Available\nfor CPU Analysis', ha='center', va='center',
                           transform=axes[0, 0].transAxes, fontsize=12)
            axes[0, 0].set_title('CPU Usage vs QPS (No Data)')

        # 2. å†…å­˜ä½¿ç”¨ç‡ vs QPS
        if len(df) > 0 and 'mem_usage' in df.columns and qps_available and 'current_qps' in df.columns:
            axes[0, 1].plot(df['current_qps'], df['mem_usage'], 'go-', alpha=0.7, markersize=4)
            axes[0, 1].axhline(y=90, color='red', linestyle='--', alpha=0.8, label='Warning (90%)')
            axes[0, 1].set_title('Memory Usage vs QPS')
            axes[0, 1].set_xlabel('QPS')
            axes[0, 1].set_ylabel('Memory %')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        else:
            axes[0, 1].text(0.5, 0.5, 'QPS Data Not Available\nfor Memory Analysis', ha='center', va='center',
                           transform=axes[0, 1].transAxes, fontsize=12)
            axes[0, 1].set_title('Memory Usage vs QPS (No Data)')

        # 3. RPCå»¶è¿Ÿ vs QPS
        if len(df) > 0 and 'rpc_latency_ms' in df.columns and qps_available and 'current_qps' in df.columns and df['rpc_latency_ms'].notna().any():
            axes[1, 0].plot(df['current_qps'], df['rpc_latency_ms'], 'ro-', alpha=0.7, markersize=4)
            axes[1, 0].axhline(y=1000, color='orange', linestyle='--', alpha=0.8, label='High Latency (1s)')
            axes[1, 0].set_title('RPC Latency vs QPS')
            axes[1, 0].set_xlabel('QPS')
            axes[1, 0].set_ylabel('Latency (ms)')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        else:
            axes[1, 0].text(0.5, 0.5, 'QPS Data Not Available\nfor RPC Latency Analysis', ha='center', va='center',
                           transform=axes[1, 0].transAxes, fontsize=12)
            axes[1, 0].set_title('RPC Latency vs QPS (No Data)')

        # 4. RPCå»¶è¿Ÿåˆ†å¸ƒï¼ˆç§»åŠ¨åˆ°ç¬¬2è¡Œç¬¬0åˆ—ï¼‰
        if len(df) > 0 and 'rpc_latency_ms' in df.columns and df['rpc_latency_ms'].notna().any():
            axes[2, 0].hist(df['rpc_latency_ms'], bins=30, alpha=0.7, color='purple')
            if 'rpc_latency_ms' in df.columns:
                mean_latency = df['rpc_latency_ms'].mean()
                p95_latency = df['rpc_latency_ms'].quantile(0.95)
                axes[2, 0].axvline(mean_latency, color='red', linestyle='--',
                                   label=f'Mean: {mean_latency:.1f}ms')
                axes[2, 0].axvline(p95_latency, color='orange', linestyle='--',
                                   label=f'P95: {p95_latency:.1f}ms')
            axes[2, 0].set_title('RPC Latency Distribution')
            axes[2, 0].set_xlabel('Latency (ms)')
            axes[2, 0].set_ylabel('Frequency')
            axes[2, 0].legend()
            axes[2, 0].grid(True, alpha=0.3)

        # 5. æ€§èƒ½æ‚¬å´–å¯è§†åŒ–
        cliff_analysis = rpc_deep_analysis.get('performance_cliff', {})
        if cliff_analysis and len(df) > 0 and qps_available and 'current_qps' in df.columns and 'rpc_latency_ms' in df.columns and df['rpc_latency_ms'].notna().any():
            try:
                qps_latency = df.groupby('current_qps')['rpc_latency_ms'].mean().reset_index()
                qps_latency = qps_latency.sort_values('current_qps')

                axes[2, 1].plot(qps_latency['current_qps'], qps_latency['rpc_latency_ms'], 'bo-', alpha=0.7)

                # æ ‡è®°æ‚¬å´–ç‚¹
                cliff_points = cliff_analysis.get('performance_degradation_qps', [])
                for cliff_qps in cliff_points:
                    cliff_latency = qps_latency[qps_latency['current_qps'] == cliff_qps]['rpc_latency_ms']
                    if len(cliff_latency) > 0:
                        axes[2, 1].scatter(cliff_qps, cliff_latency.iloc[0], color='red', s=100, marker='x',
                                           label='Performance Cliff')

                axes[2, 1].set_title('Performance Cliff Detection')
                axes[2, 1].set_xlabel('QPS')
                axes[2, 1].set_ylabel('Average Latency (ms)')
                axes[2, 1].grid(True, alpha=0.3)
                if cliff_points:
                    axes[2, 1].legend()
            except Exception as e:
                logger.warning(f"âš ï¸ Performance cliff visualization failed: {e}")
                axes[2, 1].text(0.5, 0.5, 'Performance Cliff Analysis\nData Processing Error', ha='center', va='center',
                               transform=axes[2, 1].transAxes, fontsize=12)
                axes[2, 1].set_title('Performance Cliff Detection (Error)')
        else:
            axes[2, 1].text(0.5, 0.5, 'QPS Data Not Available\nfor Cliff Analysis', ha='center', va='center',
                           transform=axes[2, 1].transAxes, fontsize=12)
            axes[2, 1].set_title('Performance Cliff Detection (No Data)')

        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨ - ä½¿ç”¨æ–‡ä»¶ç®¡ç†å™¨ï¼ŒåŒæ—¶åˆ›å»ºå½“å‰ç‰ˆæœ¬å’Œå¤‡ä»½
        chart_file = self.file_manager.save_chart_with_backup('comprehensive_analysis_charts', plt)
        print(f"âœ… Ultimate performance charts saved: {chart_file}")

        return fig

    def _evaluate_comprehensive_performance(self, benchmark_mode: str, max_qps: int, 
                                          bottlenecks: Dict[str, Any], avg_cpu: float, 
                                          avg_mem: float, avg_rpc: float) -> Dict[str, Any]:
        """
        åŸºäºå®é™…ç›‘æ§æ•°æ®çš„ç§‘å­¦æ€§èƒ½è¯„ä¼°
        æ•´åˆQPSæ€§èƒ½ã€ç³»ç»Ÿèµ„æºä½¿ç”¨ç‡ã€RPCå»¶è¿Ÿç­‰å¤šç»´åº¦ç›‘æ§æ•°æ®
        """
        
        # åªæœ‰æ·±åº¦åŸºå‡†æµ‹è¯•æ¨¡å¼æ‰èƒ½è¿›è¡Œå‡†ç¡®çš„æ€§èƒ½ç­‰çº§è¯„ä¼°
        if benchmark_mode != "intensive":
            return {
                'performance_level': 'Unable to Evaluate',
                'performance_grade': 'N/A',
                'evaluation_reason': f'{benchmark_mode}åŸºå‡†æµ‹è¯•æ¨¡å¼æ— æ³•å‡†ç¡®è¯„ä¼°ç³»ç»Ÿæ€§èƒ½ç­‰çº§ï¼Œéœ€è¦intensiveæ¨¡å¼è¿›è¡Œæ·±åº¦åˆ†æ',
                'evaluation_basis': 'insufficient_benchmark_depth',
                'max_sustainable_qps': max_qps,
                'recommendations': [
                    f'å½“å‰{benchmark_mode}åŸºå‡†æµ‹è¯•ä»…ç”¨äºå¿«é€ŸéªŒè¯',
                    'å¦‚éœ€å‡†ç¡®çš„æ€§èƒ½ç­‰çº§è¯„ä¼°ï¼Œè¯·ä½¿ç”¨intensiveåŸºå‡†æµ‹è¯•æ¨¡å¼',
                    'æ·±åº¦åŸºå‡†æµ‹è¯•å°†è§¦å‘ç³»ç»Ÿç“¶é¢ˆä»¥è·å¾—å‡†ç¡®çš„æ€§èƒ½è¯„ä¼°'
                ]
            }
        
        # ç»¼åˆç“¶é¢ˆåˆ†æ - åŸºäºå®é™…ç›‘æ§æ•°æ®
        bottleneck_types = bottlenecks.get('detected_bottlenecks', [])
        
        # è®¡ç®—ç»¼åˆç“¶é¢ˆè¯„åˆ† - ä¸å†ä¾èµ–åºŸå¼ƒçš„æ—¥å¿—åˆ†ææ•°æ®
        comprehensive_score = ComprehensiveAnalyzer._calculate_comprehensive_bottleneck_score(
            bottleneck_types, avg_cpu, avg_mem, avg_rpc
        )
        
        # åŸºäºç»¼åˆè¯„åˆ†çš„ç§‘å­¦ç­‰çº§è¯„ä¼°
        if comprehensive_score < 0.2:
            level = "Excellent"
            grade = "A (Excellent)"
            reason = f"System performs excellently at {max_qps} QPS, all metrics within normal range"
            
        elif comprehensive_score < 0.4:
            level = "Good"
            grade = "B (Good)"
            reason = f"System performs well at {max_qps} QPS, with minor bottlenecks or issues"
            
        elif comprehensive_score < 0.7:
            level = "Acceptable"
            grade = "C (Acceptable)"
            reason = f"System performs acceptably at {max_qps} QPS, with noticeable bottlenecks requiring attention"
            
        else:
            level = "éœ€è¦ä¼˜åŒ–"
            grade = "D (Needs Improvement)"
            reason = f"ç³»ç»Ÿåœ¨{max_qps} QPSä¸‹å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³ä¼˜åŒ–"
        
        return {
            'performance_level': level,
            'performance_grade': grade,
            'evaluation_reason': reason,
            'evaluation_basis': 'comprehensive_intensive_analysis',
            'max_sustainable_qps': max_qps,
            'comprehensive_score': comprehensive_score,
            'bottleneck_types': bottleneck_types,
            'avg_rpc_latency': avg_rpc,
            'recommendations': ComprehensiveAnalyzer._generate_comprehensive_recommendations(
                bottleneck_types, comprehensive_score, max_qps, avg_rpc
            )
        }
    
    @staticmethod
    def _calculate_comprehensive_bottleneck_score(bottleneck_types: list, 
                                                avg_cpu: float, avg_mem: float, avg_rpc: float) -> float:
        """è®¡ç®—ç»¼åˆç“¶é¢ˆä¸¥é‡ç¨‹åº¦è¯„åˆ† - åŸºäºå®é™…ç›‘æ§æ•°æ®"""
        
        total_score = 0.0
        
        # ç³»ç»Ÿèµ„æºç“¶é¢ˆè¯„åˆ† (æƒé‡: 0.7)
        resource_score = 0.0
        if 'CPU' in bottleneck_types:
            resource_score += 0.3 * (1.5 if avg_cpu > 90 else 1.0)
        if 'Memory' in bottleneck_types:
            resource_score += 0.3 * (1.5 if avg_mem > 95 else 1.0)
        if 'EBS' in bottleneck_types:
            resource_score += 0.1
        
        # RPCæ€§èƒ½è¯„åˆ† (æƒé‡: 0.3) - åŸºäºå®é™…RPCå»¶è¿Ÿç›‘æ§æ•°æ®
        rpc_score = 0.0
        if avg_rpc > 1000:  # é«˜å»¶è¿Ÿ
            rpc_score += 0.15
        if avg_rpc > 2000:  # æé«˜å»¶è¿Ÿ
            rpc_score += 0.15
        
        total_score = resource_score + rpc_score
        
        return min(total_score, 1.0)
    
    @staticmethod
    def _generate_comprehensive_capacity_assessment(performance_evaluation: Dict[str, Any], max_qps: int) -> str:
        """åŸºäºç»¼åˆæ€§èƒ½è¯„ä¼°ç”Ÿæˆå®¹é‡è¯„ä¼° - é™æ€æ–¹æ³•"""
        performance_level = performance_evaluation.get('performance_level', 'æœªçŸ¥')
        comprehensive_score = performance_evaluation.get('comprehensive_score', 0.0)
        
        if performance_level == "Excellent":
            return f"Current configuration can stably handle high load (tested up to {max_qps:,} QPS, comprehensive score: {comprehensive_score:.3f})" if not pd.isna(max_qps) else f"Current configuration can stably handle high load (insufficient test data, comprehensive score: {comprehensive_score:.3f})"
        elif performance_level == "Good":
            return f"Current configuration can handle medium-high load (tested up to {max_qps:,} QPS, with minor issues)" if not pd.isna(max_qps) else "Current configuration can handle medium-high load (insufficient test data, with minor issues)"
        elif performance_level == "Acceptable":
            return f"Current configuration suitable for medium load (tested up to {max_qps:,} QPS, with noticeable issues)" if not pd.isna(max_qps) else "Current configuration suitable for medium load (insufficient test data, with noticeable issues)"
        elif performance_level == "éœ€è¦ä¼˜åŒ–":
            return f"å½“å‰é…ç½®éœ€è¦ä¼˜åŒ–ä»¥å¤„ç†é«˜è´Ÿè½½ (å·²æµ‹è¯•è‡³ {max_qps:,} QPSï¼Œå­˜åœ¨ä¸¥é‡é—®é¢˜)" if not pd.isna(max_qps) else "å½“å‰é…ç½®éœ€è¦ä¼˜åŒ–ä»¥å¤„ç†é«˜è´Ÿè½½ (æµ‹è¯•æ•°æ®ä¸è¶³ï¼Œå­˜åœ¨ä¸¥é‡é—®é¢˜)"
        else:
            return f"éœ€è¦intensiveåŸºå‡†æµ‹è¯•æ¨¡å¼è¿›è¡Œå‡†ç¡®çš„å®¹é‡è¯„ä¼°"

    @staticmethod
    def _generate_comprehensive_recommendations(bottleneck_types: list, 
                                             comprehensive_score: float, max_qps: int, avg_rpc: float) -> list:
        """åŸºäºç»¼åˆåˆ†æç”Ÿæˆä¼˜åŒ–å»ºè®® - åŸºäºå®é™…ç›‘æ§æ•°æ®"""
        recommendations = []
        
        if comprehensive_score < 0.2:
            recommendations.extend([
                f"ğŸ‰ System comprehensive performance is excellent, current configuration can stably support {max_qps} QPS",
                "ğŸ’¡ Consider further increasing QPS targets or optimizing cost efficiency",
                "ï¿½ Recomdmend regular monitoring to maintain current performance level"
            ])
        else:
            # ç³»ç»Ÿèµ„æºä¼˜åŒ–å»ºè®®
            if 'CPU' in bottleneck_types:
                recommendations.append("ğŸ”§ CPUç“¶é¢ˆï¼šè€ƒè™‘å‡çº§CPUæˆ–ä¼˜åŒ–è®¡ç®—å¯†é›†å‹è¿›ç¨‹")
            if 'Memory' in bottleneck_types:
                recommendations.append("ğŸ”§ å†…å­˜ç“¶é¢ˆï¼šè€ƒè™‘å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨")
            if 'EBS' in bottleneck_types:
                recommendations.append("ğŸ”§ å­˜å‚¨ç“¶é¢ˆï¼šè€ƒè™‘å‡çº§EBSç±»å‹æˆ–ä¼˜åŒ–I/Oæ¨¡å¼")
            
            # åŸºäºå®é™…RPCå»¶è¿Ÿçš„ä¼˜åŒ–å»ºè®®
            if avg_rpc > 1000:
                recommendations.append("ğŸ”§ RPCå»¶è¿Ÿè¾ƒé«˜ï¼šè€ƒè™‘ä¼˜åŒ–RPCé…ç½®æˆ–å¢åŠ RPCå¤„ç†èƒ½åŠ›")
            if avg_rpc > 2000:
                recommendations.append("ğŸ”¥ RPCå»¶è¿Ÿè¿‡é«˜ï¼šéœ€è¦ç«‹å³ä¼˜åŒ–RPCæ€§èƒ½æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
        
        return recommendations

    @OperationLogger.log_operation("Generating comprehensive report", "ğŸ“„")
    def generate_comprehensive_report(self, df: pd.DataFrame, max_qps: int, 
                                    bottlenecks: Dict[str, Any], 
                                    rpc_deep_analysis: Dict[str, Any],
                                    benchmark_mode: str = "standard") -> str:
        """ç”ŸæˆåŸºäºç“¶é¢ˆåˆ†æçš„ç»¼åˆæŠ¥å‘Šï¼Œæ•´åˆæ‰€æœ‰åˆ†æç»“æœ"""

        # åŸºæœ¬æ€§èƒ½æŒ‡æ ‡ - ä½¿ç”¨å·¥å…·ç±»é¿å…é‡å¤ä»£ç 
        avg_cpu = DataProcessor.safe_calculate_mean(df, 'cpu_usage')
        avg_mem = DataProcessor.safe_calculate_mean(df, 'mem_usage')
        avg_rpc = DataProcessor.safe_calculate_mean(df, 'rpc_latency_ms') if 'rpc_latency_ms' in df.columns else 0

        # æ³¨æ„ï¼šå½“å‰æ¡†æ¶åªä½¿ç”¨å®æ—¶ç›‘æ§æ•°æ®ï¼Œä¸å†ä¾èµ–åŒºå—é“¾èŠ‚ç‚¹æ—¥å¿—åˆ†æ
        # RPCåˆ†æåŸºäºç›‘æ§æ•°æ®ä¸­çš„å»¶è¿ŸæŒ‡æ ‡ï¼Œä¸æ˜¯æ—¥å¿—è§£æç»“æœ
        
        # åŸºäºåŸºå‡†æµ‹è¯•æ¨¡å¼å’Œç“¶é¢ˆåˆ†æçš„æ€§èƒ½è¯„ä¼°
        # ä¸å†ä½¿ç”¨åºŸå¼ƒçš„æ—¥å¿—åˆ†ææ•°æ®ï¼Œç›´æ¥åŸºäºç›‘æ§æ•°æ®è¿›è¡Œè¯„ä¼°
        performance_evaluation = self._evaluate_comprehensive_performance(
            benchmark_mode, max_qps, bottlenecks, avg_cpu, avg_mem, avg_rpc
        )

        # æ„å»ºæŠ¥å‘Šçš„å„ä¸ªéƒ¨åˆ†
        cpu_bottleneck = 'Detected' if 'CPU' in bottlenecks.get('detected_bottlenecks', []) else 'None detected'
        memory_bottleneck = 'Detected' if 'Memory' in bottlenecks.get('detected_bottlenecks', []) else 'None detected'
        network_bottleneck = 'Detected' if 'Network' in bottlenecks.get('detected_bottlenecks', []) else 'None detected'
        ebs_bottleneck = 'Detected' if 'EBS' in bottlenecks.get('detected_bottlenecks', []) else 'None detected'
        
        max_cpu = DataProcessor.safe_calculate_max(df, 'cpu_usage')
        max_mem = DataProcessor.safe_calculate_max(df, 'mem_usage')
        max_rpc_latency = DataProcessor.safe_calculate_max(df, 'rpc_latency_ms') if 'rpc_latency_ms' in df.columns else 0
        
        latency_trend = 'Stable' if max_rpc_latency < avg_rpc * 2 else 'Variable'

        # å¤„ç†å¯èƒ½çš„NaNå€¼
        max_qps_display = f"{max_qps:,}" if not pd.isna(max_qps) else "N/A"
        
        report = f"""# Blockchain Node QPS Comprehensive Performance Analysis Report
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Executive Summary
- **Maximum QPS Achieved**: {max_qps_display}
- **Performance Grade**: {performance_evaluation['performance_grade']}
- **Performance Level**: {performance_evaluation['performance_level']}
- **Benchmark Mode**: {benchmark_mode}
- **Test Duration**: {len(df)} monitoring points
- **Monitoring Data Points**: {len(df)} records
- **Analysis Coverage**: Complete system performance monitoring

## Performance Evaluation
- **Evaluation Basis**: {performance_evaluation['evaluation_basis']}
- **Evaluation Reason**: {performance_evaluation['evaluation_reason']}
- **Comprehensive Score**: {performance_evaluation.get('comprehensive_score', 0.0):.3f}

## System Performance Metrics
- **Average CPU Usage**: {avg_cpu:.1f}%
- **Average Memory Usage**: {avg_mem:.1f}%
- **Average RPC Latency**: {avg_rpc:.1f}ms
- **CPU Peak**: {max_cpu:.1f}%
- **Memory Peak**: {max_mem:.1f}%
- **RPC Latency Peak**: {max_rpc_latency:.1f}ms

## ğŸ” System Performance Analysis Results

### Monitoring Data Analysis
- **QPS Performance**: Based on real-time system monitoring and CSV data
- **System Resource Usage**: CPU, Memory, Network utilization continuously tracked
- **RPC Performance Monitoring**: Average latency {avg_rpc:.1f}ms from monitoring data
- **Peak RPC Latency**: {max_rpc_latency:.1f}ms during test period

### Resource Bottleneck Detection
- **CPU Bottlenecks**: {cpu_bottleneck}
- **Memory Bottlenecks**: {memory_bottleneck}
- **Network Bottlenecks**: {network_bottleneck}
- **EBS Bottlenecks**: {ebs_bottleneck}

### Performance Trend Analysis
- **QPS Stability**: Analyzed from {len(df)} monitoring data points
- **Latency Trend**: {latency_trend} throughout test period
- **Resource Utilization**: CPU avg {avg_cpu:.1f}%, Memory avg {avg_mem:.1f}%
- **Data Source**: Real-time system monitoring and RPC performance tracking
"""

        # æ·»åŠ RPCæ·±åº¦åˆ†æç»“æœ
        if rpc_deep_analysis:
            rpc_deep_report = self.rpc_deep_analyzer.generate_rpc_deep_analysis_report(rpc_deep_analysis)
            report += rpc_deep_report

        # ä¼˜åŒ–å»ºè®®
        report += """
## ğŸ’¡ Comprehensive Optimization Recommendations

### Immediate Actions
"""

        # åŸºäºç°æœ‰ç›‘æ§æ•°æ®çš„å…·ä½“å»ºè®®
        if avg_rpc > 1000:
            report += "- ğŸ”§ **High Priority**: RPC latency is high, consider optimization\n"
            
        if max_rpc_latency > 2000:
            report += "- ğŸ”¥ **Critical**: Peak RPC latency detected, investigate bottlenecks\n"

        if avg_mem > 90:
            report += "- ğŸ”¥ **Critical**: High memory usage detected, consider increasing memory\n"
            report += "- ğŸ”§ Monitor for potential memory leaks\n"

        # ä½¿ç”¨åŸºäºç»¼åˆåˆ†æçš„å»ºè®®
        for recommendation in performance_evaluation.get('recommendations', []):
            report += f"- {recommendation}\n"

        # åŸºäºRPCæ·±åº¦åˆ†æçš„å»ºè®®
        if rpc_deep_analysis:
            bottleneck_classification = rpc_deep_analysis.get('bottleneck_classification', {})
            recommendations = bottleneck_classification.get('recommendations', [])
            if recommendations:
                report += "\n### RPC Deep Analysis Recommendations\n"
                for rec in recommendations:
                    report += f"- ğŸ”§ {rec}\n"

        # ç”Ÿäº§éƒ¨ç½²å»ºè®®
        capacity_assessment = ComprehensiveAnalyzer._generate_comprehensive_capacity_assessment(performance_evaluation, max_qps)
        csv_file_display = self.csv_file or 'N/A'
        
        # è®¡ç®—æ¨èç”Ÿäº§QPS
        recommended_qps_display = f"{int(max_qps * 0.8):,} (80% of maximum tested)" if not pd.isna(max_qps) else "N/A (insufficient test data)"
        
        report += f"""
### Production Deployment
- **Recommended Production QPS**: {recommended_qps_display}
- **Monitoring Thresholds**: 
  - Alert if RPC latency P99 > 500ms sustained
  - Alert if CPU usage > 85% sustained
  - Alert if Memory usage > 90% sustained
- **Capacity Assessment**: {capacity_assessment}

## Files Generated
- **Comprehensive Charts**: `{self.reports_dir}/comprehensive_analysis_charts.png`
- **Raw Monitoring Data**: `{csv_file_display}`
- **System Performance Analysis**: Included in this report
- **RPC Performance Analysis**: Included in this report
- **Load Test Reports**: `{self.reports_dir}/`

---
*Report generated by Comprehensive Blockchain Node QPS Analyzer v4.0*
"""

        # ä¿å­˜ç»¼åˆæŠ¥å‘Š - ä½¿ç”¨æ–‡ä»¶ç®¡ç†å™¨ï¼ŒåŒæ—¶åˆ›å»ºå½“å‰ç‰ˆæœ¬å’Œå¤‡ä»½
        report_file = self.file_manager.save_report_with_backup('comprehensive_analysis_report', report)

        print(f"âœ… Comprehensive report saved: {report_file}")
        return report

    def run_comprehensive_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„ç»¼åˆåˆ†æ"""
        print("ğŸš€ Starting Comprehensive Blockchain Node QPS Analysis")
        print("=" * 80)

        # 1. è¿è¡ŒQPSåˆ†æ
        print("\nğŸ“Š Phase 1: QPS Performance Analysis")
        qps_results = self.qps_analyzer.run_qps_analysis()
        df = qps_results['dataframe']
        max_qps = qps_results['max_qps']
        bottlenecks = qps_results['bottlenecks']

        # 1.1 Using direct CSV column names for analysis
        logger.info("â„¹ï¸  Using monitoring data for comprehensive analysis")
        print("  â„¹ï¸  Using monitoring data for comprehensive analysis")

        # 2. è¿è¡ŒRPCæ·±åº¦åˆ†æ
        print("\nğŸ” Phase 2: RPC Deep Analysis")
        rpc_deep_analysis = self.rpc_deep_analyzer.analyze_rpc_deep_performance(df)

        # 3. ç”Ÿæˆç»¼åˆå›¾è¡¨å’ŒæŠ¥å‘Š
        print("\nğŸ“ˆ Phase 3: Comprehensive Reporting")
        self.generate_ultimate_performance_charts(df, rpc_deep_analysis)
        
        # 4.1 ç”Ÿæˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨ï¼ˆåŒ…å«é˜ˆå€¼åˆ†æï¼‰
        print("\nğŸ¨ Phase 4.1: Performance Visualization with Threshold Analysis")
        try:
            from performance_visualizer import PerformanceVisualizer
            
            # ä¿å­˜ä¸´æ—¶CSVæ–‡ä»¶ä¾›performance_visualizerä½¿ç”¨ - ä½¿ç”¨è¿›ç¨‹IDå’Œéšæœºæ•°é¿å…å†²çª
            process_id = os.getpid()
            random_id = random.randint(1000, 9999)
            # ä½¿ç”¨TMP_DIRç¯å¢ƒå˜é‡æˆ–current/tmpç›®å½•ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            tmp_dir = os.getenv('TMP_DIR', os.path.join(self.output_dir, 'current', 'tmp'))
            os.makedirs(tmp_dir, exist_ok=True)
            temp_csv_path = os.path.join(tmp_dir, f'temp_performance_data_{process_id}_{random_id}.csv')
            df.to_csv(temp_csv_path, index=False)
            
            # æŸ¥æ‰¾ç›‘æ§å¼€é”€æ–‡ä»¶ - å¢å¼ºæŸ¥æ‰¾é€»è¾‘ä»¥å¤„ç†å½’æ¡£æƒ…å†µ
            overhead_files = glob.glob(f"{self.output_dir}/current/logs/monitoring_overhead_*.csv")
            if not overhead_files:
                # å¦‚æœcurrentç›®å½•æ²¡æœ‰ï¼Œæ£€æŸ¥archivesç›®å½•
                overhead_files = glob.glob(f"{self.output_dir}/archives/*/logs/monitoring_overhead_*.csv")
            if not overhead_files:
                # æœ€åæ£€æŸ¥å½“å‰å·¥ä½œç›®å½•
                overhead_files = glob.glob("monitoring_overhead_*.csv")
            overhead_file = max(overhead_files, key=os.path.getctime) if overhead_files else None
            
            # åˆ›å»ºæ€§èƒ½å¯è§†åŒ–å™¨å¹¶ç”Ÿæˆå›¾è¡¨
            visualizer = PerformanceVisualizer(temp_csv_path, overhead_file)
            chart_results = visualizer.generate_all_charts()
            
            if isinstance(chart_results, tuple) and len(chart_results) == 2:
                chart_files, threshold_analysis = chart_results
                print(f"âœ… ç”Ÿæˆäº† {len(chart_files)} å¼ æ€§èƒ½å›¾è¡¨ï¼ˆåŒ…å«é˜ˆå€¼åˆ†æï¼‰")
                
                # å°†é˜ˆå€¼åˆ†æç»“æœæ·»åŠ åˆ°ç»¼åˆç»“æœä¸­
                if threshold_analysis:
                    print("ğŸ“Š é˜ˆå€¼åˆ†æå·²å®Œæˆå¹¶é›†æˆåˆ°æŠ¥å‘Šä¸­")
            else:
                chart_files = chart_results if isinstance(chart_results, list) else []
                print(f"âœ… ç”Ÿæˆäº† {len(chart_files)} å¼ æ€§èƒ½å›¾è¡¨")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_csv_path):
                os.remove(temp_csv_path)
                
        except ImportError as e:
            print(f"âš ï¸ æ€§èƒ½å¯è§†åŒ–å™¨å¯¼å…¥å¤±è´¥: {e}")
        except Exception as e:
            print(f"âš ï¸ æ€§èƒ½å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        
        comprehensive_report = self.generate_comprehensive_report(
            df, max_qps, bottlenecks, rpc_deep_analysis, self.benchmark_mode
        )

        # 5. æ˜¾ç¤ºRPCæ·±åº¦åˆ†ææŠ¥å‘Š

        if rpc_deep_analysis:
            rpc_report = self.rpc_deep_analyzer.generate_rpc_deep_analysis_report(rpc_deep_analysis)
            print(rpc_report)

        # è¿”å›å®Œæ•´çš„åˆ†æç»“æœ
        comprehensive_results = {
            'qps_analysis': qps_results,
            'rpc_deep_analysis': rpc_deep_analysis,
            'comprehensive_report': comprehensive_report,
            'dataframe': df,
            'max_qps': max_qps,
            'bottlenecks': bottlenecks
        }

        print("\nğŸ‰ Comprehensive Analysis Completed Successfully!")
        print("Generated files:")
        print(f"  ğŸ“Š Charts: {self.reports_dir}/comprehensive_analysis_charts.png")
        print(f"  ğŸ“„ Report: {self.reports_dir}/comprehensive_analysis_report.md")
        print(f"  ğŸ’¾ Backups: Files with timestamp {self.session_timestamp} created for version history")
        print(f"  ğŸ“‹ Individual Analysis Reports: Check {self.reports_dir}/ for detailed reports")

        return comprehensive_results


def main():
    """ä¸»æ‰§è¡Œå‡½æ•° - æ”¯æŒç“¶é¢ˆæ¨¡å¼å’Œæ—¶é—´çª—å£åˆ†æ"""
    parser = argparse.ArgumentParser(description='ç»¼åˆåˆ†æå™¨ - æ”¯æŒç“¶é¢ˆæ¨¡å¼')
    parser.add_argument('csv_file', nargs='?', help='CSVæ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--benchmark-mode', default='standard', choices=['quick', 'standard', 'intensive'], 
                       help='åŸºå‡†æµ‹è¯•æ¨¡å¼ (é»˜è®¤: standard)')
    parser.add_argument('--bottleneck-mode', action='store_true', help='å¯ç”¨ç“¶é¢ˆåˆ†ææ¨¡å¼')
    parser.add_argument('--bottleneck-info', help='ç“¶é¢ˆä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--time-window', action='store_true', help='å¯ç”¨æ—¶é—´çª—å£åˆ†æ')
    parser.add_argument('--start-time', help='æ—¶é—´çª—å£å¼€å§‹æ—¶é—´')
    parser.add_argument('--end-time', help='æ—¶é—´çª—å£ç»“æŸæ—¶é—´')
    parser.add_argument('--bottleneck-time', help='ç“¶é¢ˆæ£€æµ‹æ—¶é—´')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–ç“¶é¢ˆåˆ†ææ¨¡å¼
        bottleneck_mode = None
        if args.bottleneck_mode or args.bottleneck_info:
            bottleneck_info = {}
            
            if args.bottleneck_info and os.path.exists(args.bottleneck_info):
                try:
                    with open(args.bottleneck_info, 'r') as f:
                        bottleneck_info = json.load(f)
                    logger.info(f"ğŸ“Š åŠ è½½ç“¶é¢ˆä¿¡æ¯: {args.bottleneck_info}")
                except Exception as e:
                    logger.error(f"âŒ ç“¶é¢ˆä¿¡æ¯æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            
            bottleneck_mode = BottleneckAnalysisMode(bottleneck_info)
        
        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = ComprehensiveAnalyzer(args.output_dir, args.benchmark_mode, bottleneck_mode)
        
        # ç¡®å®šCSVæ–‡ä»¶
        csv_file = args.csv_file or analyzer.csv_file
        if not csv_file or not os.path.exists(csv_file):
            logger.error("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„CSVæ•°æ®æ–‡ä»¶")
            return 1
        
        logger.info(f"ğŸ“ˆ å¼€å§‹ç»¼åˆåˆ†æ: {csv_file}")
        
        # è¯»å–æ•°æ®
        df = pd.read_csv(csv_file)
        logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ: {len(df)} æ¡è®°å½•")
        
        # æ—¶é—´çª—å£è¿‡æ»¤
        if args.time_window and args.start_time and args.end_time:
            df = ComprehensiveAnalyzer.filter_data_by_time_window(df, args.start_time, args.end_time)
            logger.info(f"ğŸ• æ—¶é—´çª—å£åˆ†æ: {args.start_time} åˆ° {args.end_time}")
        
        # æ‰§è¡Œåˆ†æ
        if bottleneck_mode and bottleneck_mode.enabled:
            logger.info("ğŸš¨ æ‰§è¡Œç“¶é¢ˆæ¨¡å¼åˆ†æ")
            
            # ç“¶é¢ˆç›¸å…³æ€§åˆ†æ
            bottleneck_analysis = analyzer.analyze_bottleneck_correlation(df)

            # ä¿å­˜ç“¶é¢ˆåˆ†æç»“æœ
            reports_dir = os.getenv('REPORTS_DIR', os.path.join(analyzer.output_dir, 'current', 'reports'))
            bottleneck_result_file = os.path.join(reports_dir, 'bottleneck_analysis_result.json')
            os.makedirs(os.path.dirname(bottleneck_result_file), exist_ok=True)
            with open(bottleneck_result_file, 'w') as f:
                json.dump(bottleneck_analysis, f, indent=2, default=str)
            logger.info(f"ğŸ“Š ç“¶é¢ˆåˆ†æç»“æœå·²ä¿å­˜: {bottleneck_result_file}")
        
        # æ‰§è¡Œæ ‡å‡†ç»¼åˆåˆ†æ
        result = analyzer.run_comprehensive_analysis()
        
        if result:
            logger.info("âœ… ç»¼åˆåˆ†æå®Œæˆ")
            return 0
        else:
            logger.error("âŒ ç»¼åˆåˆ†æå¤±è´¥")
            return 1
            
    except Exception as e:
        logger.error(f"âŒ ç»¼åˆåˆ†ææ‰§è¡Œå¤±è´¥: {e}")
        return 1


# æ¼”ç¤ºåŠŸèƒ½ï¼ˆä»…åœ¨ç›´æ¥è¿è¡Œæ—¶ä½¿ç”¨ï¼‰
def demo_comprehensive_analysis():
    """æ¼”ç¤ºç»¼åˆåˆ†æåŠŸèƒ½"""
    try:
        analyzer = ComprehensiveAnalyzer(benchmark_mode="standard")
        results = analyzer.run_comprehensive_analysis()

        print("\nğŸ¯ Analysis Summary:")
        print(f"  Maximum QPS: {results['max_qps']:,}" if not pd.isna(results['max_qps']) else "  Maximum QPS: N/A")
        print(f"  Data Points: {len(results['dataframe'])}")
        print(f"  Bottlenecks: {len(results['bottlenecks'])}")
        
        return results

    except Exception as e:
        logger.error(f"âŒ Comprehensive analysis failed: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    main()
