#!/bin/bash

# =====================================================================
# Solana éªŒè¯èŠ‚ç‚¹æ—¥å¿—åˆ†æè„šæœ¬
# ç”¨äºåˆ†æ Solana éªŒè¯èŠ‚ç‚¹æ—¥å¿—ï¼Œè¯†åˆ«æ€§èƒ½é—®é¢˜å’Œå¼‚å¸¸
# =====================================================================

# åŠ è½½é…ç½®æ–‡ä»¶
source "$(dirname "${BASH_SOURCE[0]}")/../config/config.sh"
source "$(dirname "${BASH_SOURCE[0]}")/../utils/unified_logger.sh"

# åˆå§‹åŒ–ç»Ÿä¸€æ—¥å¿—ç®¡ç†å™¨
init_logger "analyze_validator_logs" $LOG_LEVEL "${LOGS_DIR}/analyze_validator_logs.log"


# åˆå§‹åŒ–å˜é‡
INPUT_LOG=""
OUTPUT_FILE=""
TIMEFRAME=24  # é»˜è®¤åˆ†ææœ€è¿‘ 24 å°æ—¶çš„æ—¥å¿—
VERBOSE=false

# å¸®åŠ©ä¿¡æ¯
show_help() {
    echo "Solana Validator Log Analyzer"
    echo "Usage: $0 [options]"
    echo ""
    echo "Options:"
    echo "  -h, --help                 Show this help message"
    echo "  -i, --input FILE           Input log file (default: ${VALIDATOR_LOG_PATH})"
    echo "  -o, --output FILE          Output analysis file (default: ${LOG_ANALYSIS_OUTPUT})"
    echo "  -t, --timeframe HOURS      Analyze logs from the last N hours (default: ${TIMEFRAME})"
    echo "  -v, --verbose              Enable verbose output"
    echo ""
    echo "Example:"
    echo "  $0 -i \${VALIDATOR_LOG_PATH:-/var/log/solana/validator.log} -o \${REPORTS_DIR}/validator_analysis.txt -t 12"
    echo ""
}

# å‚æ•°è§£æ
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0  # --help åº”è¯¥ç›´æ¥é€€å‡ºæ•´ä¸ªè„šæœ¬
                ;;
            -i|--input)
                INPUT_LOG="$2"
                shift 2
                ;;
            -o|--output)
                OUTPUT_FILE="$2"
                shift 2
                ;;
            -t|--timeframe)
                TIMEFRAME="$2"
                shift 2
                ;;
            --bottleneck-time)
                BOTTLENECK_TIME="$2"
                shift 2
                ;;
            --window-seconds)
                WINDOW_SECONDS="$2"
                shift 2
                ;;
            --bottleneck-types)
                BOTTLENECK_TYPES="$2"
                shift 2
                ;;
            --focus-errors)
                FOCUS_ERRORS=true
                shift
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            *)
                echo "Unknown option: $1"
                show_help
                return 1
                ;;
        esac
    done
    
    # è®¾ç½®é»˜è®¤å€¼
    INPUT_LOG=${INPUT_LOG:-"$VALIDATOR_LOG_PATH"}
    OUTPUT_FILE=${OUTPUT_FILE:-"$LOG_ANALYSIS_OUTPUT"}
    WINDOW_SECONDS=${WINDOW_SECONDS:-30}
    FOCUS_ERRORS=${FOCUS_ERRORS:-false}
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    if ! command -v grep &> /dev/null || ! command -v awk &> /dev/null || ! command -v sort &> /dev/null; then
        echo "Error: Required tools (grep, awk, sort) are not installed"
        return 1
    fi
}

# æ£€æŸ¥è¾“å…¥æ–‡ä»¶
check_input_file() {
    if [[ ! -f "$INPUT_LOG" ]]; then
        echo "Error: Input log file not found: $INPUT_LOG"
        return 1
    fi
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
    if [[ ! -s "$INPUT_LOG" ]]; then
        echo "Error: Input log file is empty: $INPUT_LOG"
        return 1
    fi
}

# è·å–æ—¥å¿—æ—¶é—´èŒƒå›´
get_log_timeframe() {
    local current_time=$(date +%s)
    local timeframe_seconds=$((TIMEFRAME * 3600))
    local start_time=$((current_time - timeframe_seconds))
    
    # è½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼ï¼Œç”¨äºè¿‡æ»¤æ—¥å¿—
    local start_date=$(date -d "@$start_time" "+%Y-%m-%d %H:%M:%S")
    
    echo "$start_date"
}

# è§£æSolanaæ—¶é—´æˆ³æ ¼å¼
parse_solana_timestamp() {
    local log_line="$1"
    # æå–æ—¶é—´æˆ³ï¼š[2025-06-16T18:36:55.458394519Z INFO ...]
    echo "$log_line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g'
}

# è¿‡æ»¤ç“¶é¢ˆæ—¶é—´çª—å£å†…çš„æ—¥å¿—
filter_logs_by_bottleneck_time() {
    local bottleneck_time="$1"
    local window_seconds="$2"
    local input_file="$3"
    local output_file="$4"
    
    if [[ -z "$bottleneck_time" ]]; then
        echo "Error: Bottleneck time not specified"
        return 1
    fi
    
    # è®¡ç®—æ—¶é—´çª—å£
    local bottleneck_epoch=$(date -d "$bottleneck_time" +%s 2>/dev/null)
    if [[ $? -ne 0 ]]; then
        echo "Error: Invalid bottleneck time format: $bottleneck_time"
        return 1
    fi
    
    local start_epoch=$((bottleneck_epoch - window_seconds))
    local end_epoch=$((bottleneck_epoch + window_seconds))
    
    local start_iso=$(date -d "@$start_epoch" -Iseconds | sed 's/+00:00/Z/')
    local end_iso=$(date -d "@$end_epoch" -Iseconds | sed 's/+00:00/Z/')
    
    if [[ "$VERBOSE" == "true" ]]; then
        echo "Filtering logs around bottleneck time: $bottleneck_time"
        echo "Time window: $start_iso to $end_iso (Â±${window_seconds}s)"
    fi
    
    # ä½¿ç”¨awkè¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æ—¥å¿—
    awk -v start_time="$start_iso" -v end_time="$end_iso" '
    {
        # æå–æ—¶é—´æˆ³ [2025-06-23T02:50:26.696435462Z ...]
        if (match($0, /\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z/)) {
            timestamp = substr($0, RSTART+1, RLENGTH-1)
            # ç®€åŒ–æ—¶é—´æˆ³æ¯”è¾ƒ (å»æ‰çº³ç§’éƒ¨åˆ†)
            simple_timestamp = substr(timestamp, 1, 19) "Z"
            if (simple_timestamp >= start_time && simple_timestamp <= end_time) {
                print $0
            }
        }
    }' "$input_file" > "$output_file"
    
    local filtered_count=$(wc -l < "$output_file")
    if [[ "$VERBOSE" == "true" ]]; then
        echo "Filtered $filtered_count log entries in time window"
    fi
    
    return 0
}

# è¿‡æ»¤æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ—¥å¿—
filter_logs_by_time() {
    local start_time=$1
    local input_file="$2"
    local output_file="$3"
    
    # è®¡ç®—å¼€å§‹æ—¶é—´çš„ISOæ ¼å¼
    local start_iso=$(date -d "@$start_time" -Iseconds | sed 's/+00:00/Z/')
    local start_date_only=$(echo "$start_iso" | cut -d'T' -f1)
    
    if [[ "$VERBOSE" == "true" ]]; then
        echo "Filtering logs since: $start_iso"
        echo "Date filter: $start_date_only"
    fi
    
    # ä½¿ç”¨awkæ¥è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æ—¥å¿—
    awk -v start_date="$start_date_only" '
    {
        # æå–æ—¶é—´æˆ³
        if (match($0, /\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z/)) {
            timestamp = substr($0, RSTART+1, RLENGTH-1)
            log_date = substr(timestamp, 1, 10)
            if (log_date >= start_date) {
                print $0
            }
        }
    }' "$input_file" > "$output_file"
}

# åˆ†æSolanaæ•°æ®ç‚¹æŒ‡æ ‡
analyze_datapoints() {
    local filtered_log="$1"
    local tmp_file="${TMP_DIR}/validator_datapoints_$(date +%Y%m%d_%H%M%S).txt"
    
    echo "Analyzing Solana datapoint metrics..."
    
    # æå–æ‰€æœ‰datapointè¡Œ
    grep "datapoint:" "$filtered_log" > "$tmp_file"
    
    # åˆ†æcost_tracker_stats
    local cost_tracker_count=$(grep "cost_tracker_stats" "$tmp_file" | wc -l)
    if [[ $cost_tracker_count -gt 0 ]]; then
        echo ""
        echo "Cost Tracker Analysis ($cost_tracker_count entries):"
        
        # æå–å…³é”®æŒ‡æ ‡çš„å¹³å‡å€¼
        local avg_block_cost=$(grep "cost_tracker_stats" "$tmp_file" | grep -o "block_cost=[0-9]*i" | cut -d'=' -f2 | sed 's/i$//' | awk '{sum+=$1; count++} END {if(count>0) print int(sum/count); else print 0}')
        local avg_tx_count=$(grep "cost_tracker_stats" "$tmp_file" | grep -o " transaction_count=[0-9]*i" | cut -d'=' -f2 | sed 's/i$//' | awk '{sum+=$1; count++} END {if(count>0) print int(sum/count); else print 0}')
        local avg_account_count=$(grep "cost_tracker_stats" "$tmp_file" | grep -o "number_of_accounts=[0-9]*i" | cut -d'=' -f2 | sed 's/i$//' | awk '{sum+=$1; count++} END {if(count>0) print int(sum/count); else print 0}')
        
        echo "- Average block cost: $avg_block_cost"
        echo "- Average transaction count: $avg_tx_count"
        echo "- Average account count: $avg_account_count"
        
        # æ‰¾å‡ºæœ€æ˜‚è´µçš„è´¦æˆ·
        echo "- Most expensive accounts:"
        grep "cost_tracker_stats" "$tmp_file" | grep -o 'costliest_account="[^"]*"' | sort | uniq -c | sort -nr | head -5
    fi
    
    # åˆ†æcompute_bank_stats
    local compute_bank_count=$(grep "compute_bank_stats" "$tmp_file" | wc -l)
    if [[ $compute_bank_count -gt 0 ]]; then
        echo ""
        echo "Compute Bank Analysis ($compute_bank_count entries):"
        
        # æå–è®¡ç®—æ—¶é—´ç»Ÿè®¡
        local avg_elapsed=$(grep "compute_bank_stats" "$tmp_file" | grep -o "elapsed=[0-9]*i" | cut -d'=' -f2 | sed 's/i$//' | awk '{sum+=$1; count++} END {if(count>0) print int(sum/count); else print 0}')
        echo "- Average compute time: ${avg_elapsed}ms"
        
        # åˆ†æslotå¤„ç†
        echo "- Recent slot processing:"
        grep "compute_bank_stats" "$tmp_file" | tail -5 | while read line; do
            local slot=$(echo "$line" | grep -o "computed_slot=[0-9]*i" | cut -d'=' -f2 | sed 's/i$//')
            local elapsed=$(echo "$line" | grep -o "elapsed=[0-9]*i" | cut -d'=' -f2 | sed 's/i$//')
            echo "  Slot $slot: ${elapsed}ms"
        done
    fi
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if [[ "$VERBOSE" != "true" ]]; then
        rm -f "$tmp_file"
    else
        echo "Temporary datapoints file saved to: $tmp_file"
    fi
}

# åˆ†æç“¶é¢ˆæ—¶é—´çª—å£å†…çš„å…³é”®äº‹ä»¶
analyze_bottleneck_events() {
    local filtered_log="$1"
    local bottleneck_types="$2"
    
    echo ""
    echo "========================================="
    echo "ç“¶é¢ˆæ—¶é—´çª—å£å…³é”®äº‹ä»¶åˆ†æ"
    echo "========================================="
    echo "ç“¶é¢ˆç±»å‹: $bottleneck_types"
    echo ""
    
    # 1. åˆ†æERRORå’Œerroräº‹ä»¶
    echo "ğŸš¨ é”™è¯¯äº‹ä»¶åˆ†æ:"
    local error_count=$(grep -i "error" "$filtered_log" | wc -l)
    echo "- é”™è¯¯äº‹ä»¶æ€»æ•°: $error_count"
    
    if [[ $error_count -gt 0 ]]; then
        echo "- é”™è¯¯äº‹ä»¶è¯¦æƒ…:"
        grep -i "error" "$filtered_log" | head -10 | while read line; do
            local timestamp=$(echo "$line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g')
            local error_msg=$(echo "$line" | sed 's/.*ERROR[[:space:]]*//' | cut -c1-100)
            echo "  [$timestamp] $error_msg"
        done
    fi
    
    # 2. åˆ†æsolana_coreäº‹ä»¶
    echo ""
    echo "ğŸ”§ Solana Coreäº‹ä»¶åˆ†æ:"
    local core_count=$(grep "solana_core" "$filtered_log" | wc -l)
    echo "- Coreäº‹ä»¶æ€»æ•°: $core_count"
    
    if [[ $core_count -gt 0 ]]; then
        echo "- å…³é”®Coreäº‹ä»¶:"
        grep "solana_core" "$filtered_log" | grep -E "(replay_stage|banking_stage|poh_recorder)" | head -5 | while read line; do
            local timestamp=$(echo "$line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g')
            local component=$(echo "$line" | grep -o "solana_core::[^]]*" | head -1)
            echo "  [$timestamp] $component"
        done
    fi
    
    # 3. åˆ†æsolana_metricsäº‹ä»¶
    echo ""
    echo "ğŸ“Š Solana Metricsäº‹ä»¶åˆ†æ:"
    local metrics_count=$(grep "solana_metrics" "$filtered_log" | wc -l)
    echo "- Metricsäº‹ä»¶æ€»æ•°: $metrics_count"
    
    if [[ $metrics_count -gt 0 ]]; then
        echo "- æ€§èƒ½æŒ‡æ ‡äº‹ä»¶:"
        grep "solana_metrics" "$filtered_log" | head -5 | while read line; do
            local timestamp=$(echo "$line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g')
            local metric_info=$(echo "$line" | sed 's/.*solana_metrics[[:space:]]*//' | cut -c1-80)
            echo "  [$timestamp] $metric_info"
        done
    fi
    
    # 4. æ ¹æ®ç“¶é¢ˆç±»å‹è¿›è¡Œä¸“é—¨åˆ†æ
    echo ""
    echo "ğŸ¯ ç“¶é¢ˆç±»å‹ä¸“é—¨åˆ†æ:"
    case "$bottleneck_types" in
        *CPU*)
            echo "- CPUç“¶é¢ˆç›¸å…³äº‹ä»¶:"
            grep -E "(compute_bank|cost_tracker|banking_stage)" "$filtered_log" | head -3 | while read line; do
                local timestamp=$(echo "$line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g')
                echo "  [$timestamp] CPUç›¸å…³: $(echo "$line" | cut -c1-100)"
            done
            ;;
        *EBS*)
            echo "- å­˜å‚¨ç“¶é¢ˆç›¸å…³äº‹ä»¶:"
            grep -E "(accounts_db|ledger|snapshot)" "$filtered_log" | head -3 | while read line; do
                local timestamp=$(echo "$line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g')
                echo "  [$timestamp] å­˜å‚¨ç›¸å…³: $(echo "$line" | cut -c1-100)"
            done
            ;;
        *ENA*)
            echo "- ç½‘ç»œç“¶é¢ˆç›¸å…³äº‹ä»¶:"
            grep -E "(streamer|gossip|repair)" "$filtered_log" | head -3 | while read line; do
                local timestamp=$(echo "$line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g')
                echo "  [$timestamp] ç½‘ç»œç›¸å…³: $(echo "$line" | cut -c1-100)"
            done
            ;;
        *)
            echo "- é€šç”¨å…³é”®äº‹ä»¶:"
            grep -E "(WARN|WARNING)" "$filtered_log" | head -3 | while read line; do
                local timestamp=$(echo "$line" | grep -o '\[20[0-9][0-9]-[0-9][0-9]-[0-9][0-9]T[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\.[0-9]*Z' | sed 's/\[//g')
                echo "  [$timestamp] è­¦å‘Š: $(echo "$line" | cut -c1-100)"
            done
            ;;
    esac
    
    echo ""
    echo "========================================="
}

# åˆ†æé”™è¯¯å’Œè­¦å‘Š
analyze_errors_warnings() {
    local start_date=$1
    local tmp_file="${TMP_DIR}/validator_errors_$(date +%Y%m%d_%H%M%S).txt"
    
    echo "Analyzing errors and warnings since $start_date..."
    
    # æ£€æŸ¥è¾“å…¥æ—¥å¿—æ–‡ä»¶å¤§å°ï¼Œå¦‚æœå¤ªå¤§åˆ™é™åˆ¶å¤„ç†
    local log_size=$(stat -f%z "$INPUT_LOG" 2>/dev/null || stat -c%s "$INPUT_LOG" 2>/dev/null || echo "0")
    local max_size=$((1024 * 1024 * 1024))  # 1GB limit
    
    if [ "$log_size" -gt "$max_size" ]; then
        echo "Warning: Log file is very large ($(($log_size / 1024 / 1024))MB). Processing last 100MB only..."
        # åªå¤„ç†æœ€å100MBçš„æ—¥å¿—
        tail -c 100M "$INPUT_LOG" | grep -i -E "error|warn|exception|fail|timeout|panic" > "$tmp_file"
    else
        # æå–é”™è¯¯å’Œè­¦å‘Š
        grep -i -E "error|warn|exception|fail|timeout|panic" "$INPUT_LOG" > "$tmp_file"
    fi
    
    # æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶å¤§å°ï¼Œå¦‚æœå¤ªå¤§åˆ™æˆªæ–­
    local tmp_size=$(stat -f%z "$tmp_file" 2>/dev/null || stat -c%s "$tmp_file" 2>/dev/null || echo "0")
    local max_tmp_size=$((100 * 1024 * 1024))  # 100MB limit for temp file
    
    if [ "$tmp_size" -gt "$max_tmp_size" ]; then
        echo "Warning: Error extraction is very large ($(($tmp_size / 1024 / 1024))MB). Truncating to 100MB..."
        head -c 100M "$tmp_file" > "${tmp_file}.truncated"
        mv "${tmp_file}.truncated" "$tmp_file"
    fi
    
    # ç»Ÿè®¡é”™è¯¯ç±»å‹
    local error_count=$(grep -i "error" "$tmp_file" | wc -l)
    local warning_count=$(grep -i "warn" "$tmp_file" | wc -l)
    local exception_count=$(grep -i "exception" "$tmp_file" | wc -l)
    local failure_count=$(grep -i "fail" "$tmp_file" | wc -l)
    local timeout_count=$(grep -i "timeout" "$tmp_file" | wc -l)
    local panic_count=$(grep -i "panic" "$tmp_file" | wc -l)
    
    echo "Error and Warning Analysis:"
    echo "- Total errors: $error_count"
    echo "- Total warnings: $warning_count"
    echo "- Total exceptions: $exception_count"
    echo "- Total failures: $failure_count"
    echo "- Total timeouts: $timeout_count"
    echo "- Total panics: $panic_count"
    
    # åˆ†ææœ€å¸¸è§çš„é”™è¯¯æ¨¡å¼
    echo ""
    echo "Top 10 most common error patterns:"
    grep -i "error" "$tmp_file" | awk -F': ' '{print $NF}' | sort | uniq -c | sort -nr | head -10
    
    echo ""
    echo "Top 10 most common warning patterns:"
    grep -i "warn" "$tmp_file" | awk -F': ' '{print $NF}' | sort | uniq -c | sort -nr | head -10
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if [[ "$VERBOSE" != "true" ]]; then
        rm -f "$tmp_file"
    else
        echo "Temporary error file saved to: $tmp_file"
    fi
}

# åˆ†ææ€§èƒ½æŒ‡æ ‡
analyze_performance_metrics() {
    local start_date=$1
    local tmp_file="${TMP_DIR}/validator_perf_$(date +%Y%m%d_%H%M%S).txt"
    
    echo "Analyzing performance metrics since $start_date..."
    
    # æå–æ€§èƒ½ç›¸å…³æ—¥å¿—
    grep -i -E "performance|throughput|latency|qps|tps|block|slot|transaction" "$INPUT_LOG" > "$tmp_file"
    
    # åˆ†æ Slot å¤„ç†
    local slot_processed=$(grep -i "slot" "$tmp_file" | grep -i "processed" | wc -l)
    local slot_skipped=$(grep -i "slot" "$tmp_file" | grep -i "skipped" | wc -l)
    local slot_confirmed=$(grep -i "slot" "$tmp_file" | grep -i "confirmed" | wc -l)
    
    echo "Slot Processing Analysis:"
    echo "- Slots processed: $slot_processed"
    echo "- Slots skipped: $slot_skipped"
    echo "- Slots confirmed: $slot_confirmed"
    
    # åˆ†æäº¤æ˜“å¤„ç†
    local tx_processed=$(grep -i "transaction" "$tmp_file" | grep -i "processed" | wc -l)
    local tx_failed=$(grep -i "transaction" "$tmp_file" | grep -i "failed" | wc -l)
    
    echo ""
    echo "Transaction Processing Analysis:"
    echo "- Transactions processed: $tx_processed"
    echo "- Transactions failed: $tx_failed"
    
    # åˆ†ææ€§èƒ½æŒ‡æ ‡
    echo ""
    echo "Performance Metrics:"
    grep -i "performance" "$tmp_file" | tail -10
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if [[ "$VERBOSE" != "true" ]]; then
        rm -f "$tmp_file"
    else
        echo "Temporary performance file saved to: $tmp_file"
    fi
}

# åˆ†æç½‘ç»œè¿æ¥
analyze_network_connections() {
    local start_date=$1
    local tmp_file="${TMP_DIR}/validator_network_$(date +%Y%m%d_%H%M%S).txt"
    
    echo "Analyzing network connections since $start_date..."
    
    # æå–ç½‘ç»œç›¸å…³æ—¥å¿—
    grep -i -E "connection|peer|gossip|network|socket|bind|rpc" "$INPUT_LOG" > "$tmp_file"
    
    # åˆ†æè¿æ¥ç»Ÿè®¡
    local connection_established=$(grep -i "connection" "$tmp_file" | grep -i "established" | wc -l)
    local connection_closed=$(grep -i "connection" "$tmp_file" | grep -i "closed" | wc -l)
    local connection_failed=$(grep -i "connection" "$tmp_file" | grep -i "failed" | wc -l)
    
    echo "Network Connection Analysis:"
    echo "- Connections established: $connection_established"
    echo "- Connections closed: $connection_closed"
    echo "- Connection failures: $connection_failed"
    
    # åˆ†æ RPC è¯·æ±‚
    local rpc_requests=$(grep -i "rpc" "$tmp_file" | grep -i "request" | wc -l)
    local rpc_errors=$(grep -i "rpc" "$tmp_file" | grep -i "error" | wc -l)
    
    echo ""
    echo "RPC Request Analysis:"
    echo "- Total RPC requests: $rpc_requests"
    echo "- RPC errors: $rpc_errors"
    
    # åˆ†æ Gossip ç½‘ç»œ
    echo ""
    echo "Gossip Network Analysis:"
    grep -i "gossip" "$tmp_file" | grep -i -E "error|warn|fail" | tail -10
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if [[ "$VERBOSE" != "true" ]]; then
        rm -f "$tmp_file"
    else
        echo "Temporary network file saved to: $tmp_file"
    fi
}

# åˆ†æèµ„æºä½¿ç”¨
analyze_resource_usage() {
    local start_date=$1
    local tmp_file="${TMP_DIR}/validator_resource_$(date +%Y%m%d_%H%M%S).txt"
    
    echo "Analyzing resource usage since $start_date..."
    
    # æå–èµ„æºç›¸å…³æ—¥å¿—
    grep -i -E "cpu|memory|disk|io|bandwidth|resource|usage|limit" "$INPUT_LOG" > "$tmp_file"
    
    # åˆ†æ CPU ä½¿ç”¨
    echo "CPU Usage Analysis:"
    grep -i "cpu" "$tmp_file" | grep -i "usage" | tail -5
    
    # åˆ†æå†…å­˜ä½¿ç”¨
    echo ""
    echo "Memory Usage Analysis:"
    grep -i "memory" "$tmp_file" | grep -i "usage" | tail -5
    
    # åˆ†æç£ç›˜ä½¿ç”¨
    echo ""
    echo "Disk Usage Analysis:"
    grep -i -E "disk|io" "$tmp_file" | grep -i "usage" | tail -5
    
    # åˆ†æèµ„æºé™åˆ¶
    echo ""
    echo "Resource Limit Analysis:"
    grep -i "limit" "$tmp_file" | grep -i -E "reached|exceeded" | tail -5
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if [[ "$VERBOSE" != "true" ]]; then
        rm -f "$tmp_file"
    else
        echo "Temporary resource file saved to: $tmp_file"
    fi
}

# åˆ†æéªŒè¯èŠ‚ç‚¹æ—¥å¿—
analyze_validator_log() {
    echo "Analyzing Solana validator log: $INPUT_LOG"
    echo "Timeframe: Last $TIMEFRAME hours"
    echo "Output file: $OUTPUT_FILE"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    mkdir -p "$(dirname "$OUTPUT_FILE")"
    
    # è·å–æ—¥å¿—æ—¶é—´èŒƒå›´
    local start_date=$(get_log_timeframe)
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    {
        echo "========================================"
        echo "Solana Validator Log Analysis Report"
        echo "========================================"
        echo "Generated: $(date)"
        echo "Input Log: $INPUT_LOG"
        echo "Timeframe: Last $TIMEFRAME hours (since $start_date)"
        echo "========================================"
        echo ""
        
        echo "========================================"
        echo "Error and Warning Analysis"
        echo "========================================"
        analyze_errors_warnings "$start_date"
        echo ""
        
        echo "========================================"
        echo "Performance Metrics Analysis"
        echo "========================================"
        analyze_performance_metrics "$start_date"
        echo ""
        
        echo "========================================"
        echo "Network Connection Analysis"
        echo "========================================"
        analyze_network_connections "$start_date"
        echo ""
        
        echo "========================================"
        echo "Resource Usage Analysis"
        echo "========================================"
        analyze_resource_usage "$start_date"
        echo ""
        
        echo "========================================"
        echo "Recommendations"
        echo "========================================"
        echo "Based on the log analysis:"
        echo "1. Monitor error patterns and address recurring issues"
        echo "2. Check for resource constraints if performance degradation is observed"
        echo "3. Verify network connectivity if connection failures are frequent"
        echo "4. Consider optimizing RPC configuration if RPC errors are high"
        echo ""
        
        echo "========================================"
        echo "End of Report"
        echo "========================================"
    } > "$OUTPUT_FILE"
    
    echo "Validator log analysis completed: $OUTPUT_FILE"
    
    # å¦‚æœå¯ç”¨äº†è¯¦ç»†è¾“å‡ºï¼Œæ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
    if [[ "$VERBOSE" == "true" ]]; then
        echo ""
        echo "Report content:"
        echo "----------------------------------------"
        cat "$OUTPUT_FILE"
        echo "----------------------------------------"
    fi
}

# ä¸»å‡½æ•°
main() {
    # è§£æå‚æ•°
    parse_args "$@"
    
    # æ£€æŸ¥ä¾èµ–
    if ! check_dependencies; then
        exit 1
    fi
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if ! check_input_file; then
        exit 1
    fi
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºç“¶é¢ˆæ—¶é—´å…³è”åˆ†æ
    if [[ -n "$BOTTLENECK_TIME" ]]; then
        echo "ğŸ” æ‰§è¡Œç“¶é¢ˆæ—¶é—´å…³è”åˆ†ææ¨¡å¼"
        analyze_bottleneck_correlation
    else
        echo "ğŸ“Š æ‰§è¡Œæ ‡å‡†éªŒè¯å™¨æ—¥å¿—åˆ†ææ¨¡å¼"
        # åˆ†æéªŒè¯èŠ‚ç‚¹æ—¥å¿—
        analyze_validator_log
    fi
}

# ç“¶é¢ˆæ—¶é—´å…³è”åˆ†æä¸»å‡½æ•°
analyze_bottleneck_correlation() {
    echo "========================================="
    echo "Solana Validator Log - ç“¶é¢ˆå…³è”åˆ†æ"
    echo "========================================="
    echo "ç”Ÿæˆæ—¶é—´: $(date)"
    echo "è¾“å…¥æ—¥å¿—: $INPUT_LOG"
    echo "ç“¶é¢ˆæ—¶é—´: $BOTTLENECK_TIME"
    echo "åˆ†æçª—å£: Â±${WINDOW_SECONDS}ç§’"
    echo "ç“¶é¢ˆç±»å‹: ${BOTTLENECK_TYPES:-æœªæŒ‡å®š}"
    echo "========================================="
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    mkdir -p "$(dirname "$OUTPUT_FILE")"
    
    # åˆ›å»ºä¸´æ—¶è¿‡æ»¤æ–‡ä»¶
    local filtered_log="${TMP_DIR}/bottleneck_filtered_$(date +%Y%m%d_%H%M%S).log"
    
    # è¿‡æ»¤ç“¶é¢ˆæ—¶é—´çª—å£å†…çš„æ—¥å¿—
    if filter_logs_by_bottleneck_time "$BOTTLENECK_TIME" "$WINDOW_SECONDS" "$INPUT_LOG" "$filtered_log"; then
        echo "âœ… æ—¥å¿—æ—¶é—´çª—å£è¿‡æ»¤å®Œæˆ"
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        {
            echo "========================================="
            echo "Solana Validator Log - ç“¶é¢ˆå…³è”åˆ†ææŠ¥å‘Š"
            echo "========================================="
            echo "ç”Ÿæˆæ—¶é—´: $(date)"
            echo "è¾“å…¥æ—¥å¿—: $INPUT_LOG"
            echo "ç“¶é¢ˆæ—¶é—´: $BOTTLENECK_TIME"
            echo "åˆ†æçª—å£: Â±${WINDOW_SECONDS}ç§’"
            echo "ç“¶é¢ˆç±»å‹: ${BOTTLENECK_TYPES:-æœªæŒ‡å®š}"
            echo "è¿‡æ»¤æ—¥å¿—è¡Œæ•°: $(wc -l < "$filtered_log")"
            echo ""
            
            # æ‰§è¡Œç“¶é¢ˆäº‹ä»¶åˆ†æ
            analyze_bottleneck_events "$filtered_log" "$BOTTLENECK_TYPES"
            
            # å¦‚æœå¯ç”¨äº†é”™è¯¯èšç„¦ï¼Œè¿›è¡Œè¯¦ç»†é”™è¯¯åˆ†æ
            if [[ "$FOCUS_ERRORS" == "true" ]]; then
                echo ""
                echo "========================================="
                echo "è¯¦ç»†é”™è¯¯åˆ†æ (é”™è¯¯èšç„¦æ¨¡å¼)"
                echo "========================================="
                analyze_errors_warnings_filtered "$filtered_log"
            fi
            
            # åˆ†æslotå¤„ç†æƒ…å†µ
            echo ""
            echo "========================================="
            echo "Slotå¤„ç†åˆ†æ"
            echo "========================================="
            analyze_slot_processing "$filtered_log"
            
            # åˆ†æç½‘ç»œè¿æ¥æƒ…å†µ
            echo ""
            echo "========================================="
            echo "ç½‘ç»œè¿æ¥åˆ†æ"
            echo "========================================="
            analyze_network_connections_filtered "$filtered_log"
            
            echo ""
            echo "========================================="
            echo "åˆ†æå®Œæˆæ—¶é—´: $(date)"
            echo "========================================="
            
        } > "$OUTPUT_FILE"
        
        echo "âœ… ç“¶é¢ˆå…³è”åˆ†æå®Œæˆ"
        echo "ğŸ“„ åˆ†ææŠ¥å‘Š: $OUTPUT_FILE"
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if [[ "$VERBOSE" != "true" ]]; then
            rm -f "$filtered_log"
        else
            echo "ğŸ”§ ä¸´æ—¶è¿‡æ»¤æ–‡ä»¶ä¿ç•™: $filtered_log"
        fi
        
    else
        echo "âŒ æ—¥å¿—æ—¶é—´çª—å£è¿‡æ»¤å¤±è´¥"
        return 1
    fi
}

# åˆ†æè¿‡æ»¤åæ—¥å¿—çš„é”™è¯¯å’Œè­¦å‘Š
analyze_errors_warnings_filtered() {
    local filtered_log="$1"
    local tmp_file="${TMP_DIR}/validator_errors_filtered_$(date +%Y%m%d_%H%M%S).txt"
    
    # æå–é”™è¯¯å’Œè­¦å‘Š
    grep -i -E "ERROR|WARN|exception|fail|timeout|panic" "$filtered_log" > "$tmp_file"
    
    # ç»Ÿè®¡é”™è¯¯ç±»å‹
    local error_count=$(grep -i "ERROR" "$tmp_file" | wc -l)
    local warning_count=$(grep -i "WARN" "$tmp_file" | wc -l)
    local exception_count=$(grep -i "exception" "$tmp_file" | wc -l)
    local failure_count=$(grep -i "fail" "$tmp_file" | wc -l)
    local timeout_count=$(grep -i "timeout" "$tmp_file" | wc -l)
    local panic_count=$(grep -i "panic" "$tmp_file" | wc -l)
    
    echo "Error and Warning Summary:"
    echo "- Total errors: $error_count"
    echo "- Total warnings: $warning_count"
    echo "- Total exceptions: $exception_count"
    echo "- Total failures: $failure_count"
    echo "- Total timeouts: $timeout_count"
    echo "- Total panics: $panic_count"
    
    if [[ $error_count -gt 0 ]]; then
        echo ""
        echo "Recent errors (last 5):"
        grep -i "ERROR" "$tmp_file" | tail -5
    fi
    
    if [[ $warning_count -gt 0 ]]; then
        echo ""
        echo "Recent warnings (last 5):"
        grep -i "WARN" "$tmp_file" | tail -5
    fi
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if [[ "$VERBOSE" != "true" ]]; then
        rm -f "$tmp_file"
    fi
}

# åˆ†æè¿‡æ»¤åæ—¥å¿—çš„æ€§èƒ½æŒ‡æ ‡
analyze_performance_metrics_filtered() {
    local filtered_log="$1"
    
    # åˆ†æslotå¤„ç†æ€§èƒ½
    local slot_lines=$(grep -i "slot" "$filtered_log" | wc -l)
    echo "Slot-related log entries: $slot_lines"
    
    # åˆ†æäº¤æ˜“å¤„ç†
    local tx_lines=$(grep -i "transaction" "$filtered_log" | wc -l)
    echo "Transaction-related log entries: $tx_lines"
    
    # åˆ†æRPCæ€§èƒ½
    local rpc_lines=$(grep -i "rpc" "$filtered_log" | wc -l)
    echo "RPC-related log entries: $rpc_lines"
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ€§èƒ½ç›¸å…³æ—¥å¿—
    echo ""
    echo "Recent performance-related entries:"
    grep -i -E "performance|latency|throughput" "$filtered_log" | tail -3
}

# åˆ†æslotå¤„ç†
analyze_slot_processing() {
    local filtered_log="$1"
    
    # åˆ†æfork choiceå’Œvoting
    local voting_lines=$(grep "voting:" "$filtered_log" | wc -l)
    local fork_lines=$(grep "fork" "$filtered_log" | wc -l)
    
    echo "Slot Processing Summary:"
    echo "- Voting entries: $voting_lines"
    echo "- Fork-related entries: $fork_lines"
    
    # æ˜¾ç¤ºæœ€è¿‘çš„slotå¤„ç†ä¿¡æ¯
    echo ""
    echo "Recent slot processing (last 5):"
    grep -E "voting:|fork|slot_weight" "$filtered_log" | tail -5
    
    # åˆ†æslotç¡®è®¤æ—¶é—´
    echo ""
    echo "Recent slot confirmations:"
    grep "confirmed" "$filtered_log" | grep -o "[0-9]*ms" | tail -5 | while read time; do
        echo "- Confirmation time: $time"
    done
}

# åˆ†æè¿‡æ»¤åæ—¥å¿—çš„ç½‘ç»œè¿æ¥
analyze_network_connections_filtered() {
    local filtered_log="$1"
    
    # åˆ†æç½‘ç»œç›¸å…³æ—¥å¿—
    local network_lines=$(grep -i -E "connection|peer|gossip|network" "$filtered_log" | wc -l)
    echo "Network-related log entries: $network_lines"
    
    # åˆ†æRPCè¿æ¥
    local rpc_lines=$(grep -i "rpc" "$filtered_log" | wc -l)
    echo "RPC-related log entries: $rpc_lines"
    
    if [[ $network_lines -gt 0 ]]; then
        echo ""
        echo "Recent network activity (last 3):"
        grep -i -E "connection|peer|gossip" "$filtered_log" | tail -3
    fi
}

# æ‰§è¡Œä¸»å‡½æ•°
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
