#!/usr/bin/env python3
"""
æ€§èƒ½å¯è§†åŒ–å™¨ - ç”Ÿäº§çº§ç‰ˆæœ¬ (å·²ä¿®å¤CSVå­—æ®µä¸€è‡´æ€§é—®é¢˜)
ä½¿ç”¨ç»Ÿä¸€çš„CSVæ•°æ®å¤„ç†å™¨ï¼Œç¡®ä¿å­—æ®µè®¿é—®çš„ä¸€è‡´æ€§å’Œå¯é æ€§
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import numpy as np
from datetime import datetime
import argparse
import os
import sys
from pathlib import Path

# é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
def setup_chinese_font():
    """é…ç½®matplotlibçš„ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    # å°è¯•å¸¸è§çš„ä¸­æ–‡å­—ä½“
    chinese_fonts = [
        'Noto Sans CJK SC',      # Linuxæ¨è
        'SimHei',                # Windows
        'Microsoft YaHei',       # Windows
        'PingFang SC',           # macOS
        'STHeiti',               # macOS
        'WenQuanYi Micro Hei',   # Linux
        'DejaVu Sans'            # åå¤‡å­—ä½“
    ]
    
    # è·å–ç³»ç»Ÿå¯ç”¨å­—ä½“
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
    selected_font = None
    for font in chinese_fonts:
        if font in available_fonts:
            selected_font = font
            break
    
    if selected_font:
        plt.rcParams['font.sans-serif'] = [selected_font]
        plt.rcParams['axes.unicode_minus'] = False
        print(f"âœ… ä½¿ç”¨å­—ä½“: {selected_font}")
        return True
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨è‹±æ–‡æ ‡ç­¾
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾")
        return False

# åˆå§‹åŒ–å­—ä½“é…ç½®
HAS_CHINESE_FONT = setup_chinese_font()

# å¤šè¯­è¨€æ ‡ç­¾é…ç½®
def get_labels():
    """è·å–é€‚åˆå½“å‰å­—ä½“ç¯å¢ƒçš„æ ‡ç­¾"""
    if HAS_CHINESE_FONT:
        return {
            'performance_analysis': 'æ€§èƒ½åˆ†æ',
            'time': 'æ—¶é—´',
            'cpu_usage': 'CPUä½¿ç”¨ç‡ (%)',
            'memory_usage': 'å†…å­˜ä½¿ç”¨ç‡ (%)',
            'disk_usage': 'ç£ç›˜ä½¿ç”¨ç‡ (%)',
            'network_usage': 'ç½‘ç»œä½¿ç”¨ç‡ (%)',
            'qps': 'QPS',
            'latency': 'å»¶è¿Ÿ (ms)',
            'throughput': 'ååé‡',
            'bottleneck_analysis': 'ç“¶é¢ˆåˆ†æ',
            'trend_analysis': 'è¶‹åŠ¿åˆ†æ',
            'correlation_analysis': 'å…³è”åˆ†æ',
            'performance_summary': 'æ€§èƒ½æ‘˜è¦'
        }
    else:
        return {
            'performance_analysis': 'Performance Analysis',
            'time': 'Time',
            'cpu_usage': 'CPU Usage (%)',
            'memory_usage': 'Memory Usage (%)',
            'disk_usage': 'Disk Usage (%)',
            'network_usage': 'Network Usage (%)',
            'qps': 'QPS',
            'latency': 'Latency (ms)',
            'throughput': 'Throughput',
            'bottleneck_analysis': 'Bottleneck Analysis',
            'trend_analysis': 'Trend Analysis',
            'correlation_analysis': 'Correlation Analysis',
            'performance_summary': 'Performance Summary'
        }

# è·å–å½“å‰ç¯å¢ƒçš„æ ‡ç­¾
LABELS = get_labels()

# å¯¼å…¥ç»Ÿä¸€çš„CSVæ•°æ®å¤„ç†å™¨
current_dir = Path(__file__).parent
utils_dir = current_dir.parent / 'utils'
analysis_dir = current_dir.parent / 'analysis'

# æ·»åŠ è·¯å¾„åˆ°sys.path
for path in [str(utils_dir), str(analysis_dir)]:
    if path not in sys.path:
        sys.path.insert(0, path)

try:
    from csv_data_processor import CSVDataProcessor
    from cpu_ebs_correlation_analyzer import CPUEBSCorrelationAnalyzer
    from unit_converter import UnitConverter
    from advanced_chart_generator import AdvancedChartGenerator
    ADVANCED_TOOLS_AVAILABLE = True
    print("âœ… é«˜çº§åˆ†æå·¥å…·å·²åŠ è½½")
except ImportError as e:
    print(f"âš ï¸  é«˜çº§åˆ†æå·¥å…·ä¸å¯ç”¨: {e}")
    print("ğŸ“ å°†ä½¿ç”¨åŸºç¡€åŠŸèƒ½æ¨¡å¼ï¼Œéƒ¨åˆ†é«˜çº§åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    ADVANCED_TOOLS_AVAILABLE = False
    # è®¾ç½®å ä½ç¬¦ç±»ä»¥é¿å…è¿è¡Œæ—¶é”™è¯¯
    class CSVDataProcessor:
        def __init__(self):
            self.df = None
        def load_csv_data(self, file): 
            self.df = pd.read_csv(file)
            return True
        def clean_data(self):
            return True
        def has_field(self, name):
            return name in self.df.columns if self.df is not None else False
        def get_device_columns_safe(self, device_prefix: str, metric_suffix: str) -> list:
            if self.df is None:
                return []
            matching_cols = []
            for col in self.df.columns:
                if col.startswith(f'{device_prefix}_') and metric_suffix in col:
                    matching_cols.append(col)
            return matching_cols

# é«˜çº§å·¥å…·å¯¼å…¥æ£€æŸ¥
try:
    from advanced_chart_generator import AdvancedChartGenerator
    from cpu_ebs_correlation_analyzer import CPUEBSCorrelationAnalyzer  
    from unit_converter import UnitConverter
    ADVANCED_TOOLS_AVAILABLE = True
    print("âœ… é«˜çº§åˆ†æå·¥å…·å·²åŠ è½½")
except ImportError as e:
    print(f"âš ï¸  é«˜çº§åˆ†æå·¥å…·ä¸å¯ç”¨: {e}")
    print("ğŸ“ å°†ä½¿ç”¨åŸºç¡€åŠŸèƒ½æ¨¡å¼ï¼Œéƒ¨åˆ†é«˜çº§åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    ADVANCED_TOOLS_AVAILABLE = False
    
    # å®šä¹‰å ä½ç¬¦ç±»ä»¥é¿å…IDEè­¦å‘Šå’Œè¿è¡Œæ—¶é”™è¯¯
    class DummyTool:
        def __init__(self, *args, **kwargs):
            pass
        def __call__(self, *args, **kwargs):
            return self
    
    # ä½¿ç”¨å¯è°ƒç”¨çš„å ä½ç¬¦ç±»
    CPUEBSCorrelationAnalyzer = DummyTool
    UnitConverter = DummyTool
    AdvancedChartGenerator = DummyTool

class PerformanceVisualizer(CSVDataProcessor):
    """æ€§èƒ½å¯è§†åŒ–å™¨ - åŸºäºç»Ÿä¸€CSVæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, data_file, overhead_file=None):
        super().__init__()  # åˆå§‹åŒ–CSVæ•°æ®å¤„ç†å™¨
        
        self.data_file = data_file
        self.overhead_file = overhead_file
        self.output_dir = os.path.dirname(data_file)
        
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
        # ä½¿ç”¨è‹±æ–‡æ ‡ç­¾ç³»ç»Ÿï¼Œç§»é™¤å¤æ‚çš„å­—ä½“ç®¡ç†
        self.use_english_labels = True
        self.font_manager = None
            
        # é˜ˆå€¼é…ç½® - é›†æˆè‡ªawait_util_analyzer
        self.await_thresholds = {
            'data_avg_await': 5.0,  # é»˜è®¤I/Oç­‰å¾…é˜ˆå€¼ (ms)
            'data_r_await': 5.0,  # é»˜è®¤è¯»Latencyé˜ˆå€¼ (ms)
            'data_w_await': 10.0,  # é»˜è®¤å†™Latencyé˜ˆå€¼ (ms)
            'normal': 10,      # Normal Threshold (ms)
            'warning': 20,     # Warning Threshold (ms)
            'critical': 50     # Critical Threshold (ms)
        }
        
        # ACCOUNTSè®¾å¤‡é˜ˆå€¼å°†åœ¨æ•°æ®åŠ è½½ååŠ¨æ€æ·»åŠ 
        self._accounts_thresholds_added = False
        
        self.util_thresholds = {
            'normal': 70,      # Normal Threshold (%)
            'warning': 85,     # Warning Threshold (%)
            'critical': 95     # Critical Threshold (%)
        }
        
        # åˆå§‹åŒ–æ–°å·¥å…·
        if ADVANCED_TOOLS_AVAILABLE:
            try:
                self.unit_converter = UnitConverter()
                self.correlation_analyzer = CPUEBSCorrelationAnalyzer(data_file)
                self.chart_generator = AdvancedChartGenerator(data_file, self.output_dir)
            except Exception as e:
                print(f"âš ï¸ é«˜çº§å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
                self.unit_converter = None
                self.correlation_analyzer = None
                self.chart_generator = None
        else:
            # å½“é«˜çº§å·¥å…·ä¸å¯ç”¨æ—¶ï¼Œè®¾ç½®ä¸º None
            self.unit_converter = None
            self.correlation_analyzer = None
            self.chart_generator = None
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        try:
            success = self.load_csv_data(self.data_file)
            if success:
                self.clean_data()  # æ¸…æ´—æ•°æ®
                
                # å®‰å…¨çš„Timeæˆ³å¤„ç†
                if 'timestamp' in self.df.columns:
                    try:
                        self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
                        print(f"âœ… Timeæˆ³å­—æ®µ 'self.df['timestamp']' è½¬æ¢æˆåŠŸ")
                    except Exception as e:
                        print(f"âš ï¸  Timeæˆ³è½¬æ¢å¤±è´¥: {e}")
                        # åˆ›å»ºé»˜è®¤Timeæˆ³
                        self.df['timestamp'] = pd.date_range(start='2024-01-01', periods=len(self.df), freq='1min')
                else:
                    print("âš ï¸  æœªæ‰¾åˆ°Timeæˆ³å­—æ®µï¼Œåˆ›å»ºé»˜è®¤Timeæˆ³")
                    self.df['timestamp'] = pd.date_range(start='2024-01-01', periods=len(self.df), freq='1min')
                
                print(f"âœ… åŠ è½½äº† {len(self.df)} æ¡æ€§èƒ½æ•°æ®")
                print(f"ğŸ“Š CSVåˆ—æ•°: {len(self.df.columns)}")
                self.print_field_info()  # æ‰“å°å­—æ®µä¿¡æ¯ç”¨äºè°ƒè¯•
                
                # åŠ¨æ€æ·»åŠ ACCOUNTSè®¾å¤‡é˜ˆå€¼ï¼ˆä»…åœ¨ACCOUNTSè®¾å¤‡é…ç½®æ—¶ï¼‰
                self._add_accounts_thresholds_if_configured()
                
            return success
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def print_field_info(self):
        """æ‰“å°å­—æ®µä¿¡æ¯ç”¨äºè°ƒè¯•"""
        pass
    
    def _add_accounts_thresholds_if_configured(self):
        """åŠ¨æ€æ·»åŠ ACCOUNTSè®¾å¤‡é˜ˆå€¼ï¼ˆä»…åœ¨ACCOUNTSè®¾å¤‡é…ç½®æ—¶ï¼‰"""
        if not self._accounts_thresholds_added and self._is_accounts_configured():
            self.await_thresholds.update({
                'accounts_avg_await': 5.0,  # ACCOUNTS I/Oç­‰å¾…é˜ˆå€¼ (ms)
                'accounts_r_await': 5.0,    # ACCOUNTS è¯»Latencyé˜ˆå€¼ (ms)
                'accounts_w_await': 10.0,   # ACCOUNTS å†™Latencyé˜ˆå€¼ (ms)
            })
            self._accounts_thresholds_added = True
            print("âœ… å·²æ·»åŠ ACCOUNTSè®¾å¤‡é˜ˆå€¼é…ç½®")
    
    def _is_accounts_configured(self):
        """æ£€æŸ¥ ACCOUNTS Deviceæ˜¯å¦é…ç½®å’Œå¯ç”¨
        
        æ ¹æ® config.sh çš„é€»è¾‘ï¼ŒACCOUNTS Deviceæ˜¯å¯é€‰çš„ï¼š
        1. æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
        2. æ£€æŸ¥å®é™…æ•°æ®åˆ—æ˜¯å¦å­˜åœ¨
        3. è¿”å›é…ç½®çŠ¶æ€
        """
        # æ–¹æ³•1: æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
        accounts_device = os.environ.get('ACCOUNTS_DEVICE')
        accounts_vol_type = os.environ.get('ACCOUNTS_VOL_TYPE')
        
        # æ–¹æ³•2: æ£€æŸ¥æ•°æ®åˆ—æ˜¯å¦å­˜åœ¨ï¼ˆæ›´å¯é çš„æ–¹æ³•ï¼‰
        accounts_cols = [col for col in self.df.columns if col.startswith('accounts_')]
        
        # å¦‚æœæœ‰æ•°æ®åˆ—ï¼Œè¯´æ˜ ACCOUNTS Deviceå·²é…ç½®ä¸”æ­£åœ¨ç›‘æ§
        if accounts_cols:
            return True
            
        # å¦‚æœç¯å¢ƒå˜é‡é…ç½®äº†ä½†æ²¡æœ‰æ•°æ®åˆ—ï¼Œè¯´æ˜é…ç½®æœ‰é—®é¢˜
        if accounts_device and accounts_vol_type:
            print(f"âš ï¸  ACCOUNTS Deviceå·²é…ç½® ({accounts_device}) ä½†æœªæ‰¾åˆ°ç›‘æ§æ•°æ®")
            return False
            
        # å®Œå…¨æœªé…ç½®ï¼Œè¿™æ˜¯æ­£å¸¸æƒ…å†µ
        return False
    
    def _analyze_threshold_violations(self, data_series, thresholds, metric_name):
        """âœ… æ”¹è¿›çš„é˜ˆå€¼è¿è§„åˆ†æ - é›†æˆè‡ªawait_util_analyzer"""
        # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
        if data_series.empty:
            return {
                'total_points': 0,
                'warning_violations': 0,
                'critical_violations': 0,
                'warning_percentage': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'critical_percentage': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'max_value': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'avg_value': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'metric_name': metric_name,
                'error': 'æ•°æ®ä¸ºç©º'
            }
        
        # âœ… è¿‡æ»¤NaNå€¼
        valid_data = data_series.dropna()
        if len(valid_data) == 0:
            return {
                'total_points': len(data_series),
                'warning_violations': 0,
                'critical_violations': 0,
                'warning_percentage': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'critical_percentage': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'max_value': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'avg_value': 0.0,  # ä½¿ç”¨floatç±»å‹ä¿æŒä¸€è‡´æ€§
                'metric_name': metric_name,
                'error': 'æ‰€æœ‰æ•°æ®éƒ½æ˜¯NaN'
            }
        
        total_points = len(valid_data)
        violations = {
            'warning': len(valid_data[valid_data > thresholds['warning']]),
            'critical': len(valid_data[valid_data > thresholds['critical']])
        }
        
        return {
            'total_points': total_points,
            'warning_violations': violations['warning'],
            'critical_violations': violations['critical'],
            'warning_percentage': (violations['warning'] / total_points * 100) if total_points > 0 else 0,
            'critical_percentage': (violations['critical'] / total_points * 100) if total_points > 0 else 0,
            'max_value': valid_data.max(),
            'avg_value': valid_data.mean(),
            'metric_name': metric_name,
            'valid_data_ratio': len(valid_data) / len(data_series) * 100
        }
    
    def create_performance_overview_chart(self):
        """âœ… æ”¹è¿›çš„æ€§èƒ½æ€»è§ˆå›¾ç”Ÿæˆ"""
        fig, axes = plt.subplots(2, 2, figsize=(18, 12))
        fig.suptitle('System Performance Overview', fontsize=16, fontweight='bold')
        
        # âœ… å®‰å…¨è·å–å­—æ®µå - ç›´æ¥è®¿é—®
        cpu_usage_col = 'cpu_usage' if 'cpu_usage' in self.df.columns else None
        cpu_iowait_col = 'cpu_iowait' if 'cpu_iowait' in self.df.columns else None
        mem_usage_col = 'memory_usage' if 'memory_usage' in self.df.columns else None
        
        # æŸ¥æ‰¾DATA Deviceåˆ—
        data_iops_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_total_iops')]
        data_util_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_util')]
        
        if not data_iops_cols:
            print("âŒ æœªæ‰¾åˆ°DATA Deviceæ•°æ®")
            return None
        
        data_iops_col = data_iops_cols[0]
        data_util_col = data_util_cols[0] if data_util_cols else None
        
        # âœ… CPUæ€§èƒ½æŒ‡æ ‡ (æ”¹è¿›çš„å­—æ®µå¤„ç†)
        ax1 = axes[0, 0]
        if cpu_usage_col and cpu_iowait_col:
            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            cpu_usage_data = self.df[cpu_usage_col].dropna()
            cpu_iowait_data = self.df[cpu_iowait_col].dropna()
            
            if len(cpu_usage_data) > 0 and len(cpu_iowait_data) > 0:
                # åŸå§‹æ•°æ®
                ax1.plot(self.df['timestamp'], self.df[cpu_usage_col], color='blue', linewidth=1, alpha=0.6, label='CPU Usage(åŸå§‹)')
                ax1.plot(self.df['timestamp'], self.df[cpu_iowait_col], color='red', linewidth=1, alpha=0.6, label='CPU I/O Wait (Raw)')
                
                # âœ… å®‰å…¨çš„ç§»åŠ¨å¹³å‡è®¡ç®—
                if len(cpu_usage_data) >= 10:
                    cpu_smooth = self.df[cpu_usage_col].rolling(window=10, center=True, min_periods=1).mean()
                    ax1.plot(self.df['timestamp'], cpu_smooth, color='blue', linewidth=2, label='CPU Usage(å¹³æ»‘)')
                
                if len(cpu_iowait_data) >= 10:
                    iowait_smooth = self.df[cpu_iowait_col].rolling(window=10, center=True, min_periods=1).mean()
                    ax1.plot(self.df['timestamp'], iowait_smooth, color='red', linewidth=2, label='CPU I/O Wait (Smoothed)')
                
                ax1.set_title(f'{LABELS["cpu_usage"]} (with Moving Average)')
                ax1.set_ylabel('Usage (%)')
                ax1.legend()
                ax1.grid(True, alpha=0.3)
            else:
                ax1.text(0.5, 0.5, 'CPUData Not Available', ha='center', va='center', transform=ax1.transAxes)
                ax1.set_title(f'{LABELS["cpu_usage"]} (Data Not Available)')
        else:
            missing_fields = []
            if not cpu_usage_col:
                missing_fields.append('cpu_usage')
            if not cpu_iowait_col:
                missing_fields.append('cpu_iowait')
            ax1.text(0.5, 0.5, f'Missing Fields: {", ".join(missing_fields)}', ha='center', va='center', transform=ax1.transAxes)
            ax1.set_title(f'{LABELS["cpu_usage"]} (Field Missing)')
        
        # âœ… DATA DeviceIOPS (æ”¹è¿›çš„æ•°æ®æ£€æŸ¥)
        ax2 = axes[0, 1]
        iops_data = self.df[data_iops_col].dropna()
        if len(iops_data) > 0:
            ax2.plot(self.df['timestamp'], self.df[data_iops_col], color='green', linewidth=2, label='DATA IOPS')
            ax2.set_title('DATA DeviceIOPS')
            ax2.set_ylabel('IOPS')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        else:
            ax2.text(0.5, 0.5, 'DATA IOPSData Not Available', ha='center', va='center', transform=ax2.transAxes)
            ax2.set_title('DATA DeviceIOPS (Data Not Available)')
        
        # âœ… Memory Usage (æ”¹è¿›çš„å­—æ®µå¤„ç†)
        ax3 = axes[1, 0]
        if mem_usage_col:
            mem_data = self.df[mem_usage_col].dropna()
            if len(mem_data) > 0:
                ax3.plot(self.df['timestamp'], self.df[mem_usage_col], color='purple', linewidth=2, label='Memory Usage')
                ax3.set_title('Memory Usage')
                ax3.set_ylabel('Usage (%)')
                ax3.legend()
                ax3.grid(True, alpha=0.3)
            else:
                ax3.text(0.5, 0.5, 'å†…å­˜Data Not Available', ha='center', va='center', transform=ax3.transAxes)
                ax3.set_title('Memory Usage (Data Not Available)')
        else:
            ax3.text(0.5, 0.5, 'ç¼ºå°‘Memory Usageå­—æ®µ', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('Memory Usage (Field Missing)')
        
        # âœ… Device Utilization (æ”¹è¿›çš„æ•°æ®æ£€æŸ¥)
        ax4 = axes[1, 1]
        if data_util_col:
            util_data = self.df[data_util_col].dropna()
            if len(util_data) > 0:
                ax4.plot(self.df['timestamp'], self.df[data_util_col], color='orange', linewidth=2, label='DATADevice Utilization')
                ax4.axhline(y=80, color='red', linestyle='--', alpha=0.7, label='80% Warning Line')
                ax4.set_title('Device Utilization')
                ax4.set_ylabel('Utilization (%)')
                ax4.legend()
                ax4.grid(True, alpha=0.3)
            else:
                ax4.text(0.5, 0.5, 'Device UtilizationData Not Available', ha='center', va='center', transform=ax4.transAxes)
                ax4.set_title('Device Utilization (Data Not Available)')
        else:
            ax4.text(0.5, 0.5, 'ç¼ºå°‘Device Utilizationå­—æ®µ', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('Device Utilization (Field Missing)')
        
        plt.tight_layout()
        
        output_file = os.path.join(self.output_dir, 'performance_overview.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š {LABELS['performance_analysis']} overview saved: {output_file}")
        
        return output_file
    
    def create_correlation_visualization_chart(self):
        """âœ… æ”¹è¿›çš„CPU-EBS Performance Correlation Analysis"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('CPU-EBS Performance Correlation Analysis', fontsize=16, fontweight='bold')
        
        # âœ… å®‰å…¨è·å–ç›¸å…³å­—æ®µ
        cpu_iowait_col = 'cpu_iowait' if 'cpu_iowait' in self.df.columns else None
        data_util_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_util')]
        data_await_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_avg_await')]
        data_aqu_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_aqu_sz')]
        
        # âœ… æ”¹è¿›çš„å­—æ®µå­˜åœ¨æ€§æ£€æŸ¥
        missing_fields = []
        if not cpu_iowait_col:
            missing_fields.append('cpu_iowait')
        if not data_util_cols:
            missing_fields.append('data_util')
        if not data_await_cols:
            missing_fields.append('data_avg_await')
        if not data_aqu_cols:
            missing_fields.append('data_aqu_sz')
        
        if missing_fields:
            print(f"âš ï¸  Missing fields for correlation analysis: {', '.join(missing_fields)}")
            # åœ¨å›¾è¡¨ä¸­æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            for i, ax in enumerate(axes.flat):
                ax.text(0.5, 0.5, f'Missing Fields:\n{chr(10).join(missing_fields)}', 
                       ha='center', va='center', transform=ax.transAxes, fontsize=12)
                ax.set_title(f'{LABELS["correlation_analysis"]} {i+1} (Field Missing)')
            plt.tight_layout()
            output_file = os.path.join(self.output_dir, 'cpu_ebs_correlation_visualization.png')
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            return output_file
        
        data_util_col = data_util_cols[0]
        data_await_col = data_await_cols[0]
        data_aqu_col = data_aqu_cols[0]
        
        from scipy.stats import pearsonr
        
        # âœ… å®‰å…¨çš„ç›¸å…³æ€§åˆ†æå‡½æ•°
        def safe_correlation_analysis(x_data, y_data, ax, xlabel, ylabel, title_prefix):
            """å®‰å…¨çš„ç›¸å…³æ€§åˆ†æå’Œå¯è§†åŒ–"""
            try:
                # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥
                if x_data.empty or y_data.empty:
                    ax.text(0.5, 0.5, 'æ•°æ®ä¸ºç©º', ha='center', va='center', transform=ax.transAxes)
                    ax.set_title(f'{title_prefix}\nData Not Available')
                    return
                
                # ç§»é™¤NaNå€¼å¹¶å¯¹é½æ•°æ®
                combined_data = pd.concat([x_data, y_data], axis=1).dropna()
                if len(combined_data) < 10:
                    ax.text(0.5, 0.5, f'æœ‰æ•ˆæ•°æ®ç‚¹ä¸è¶³\n(ä»…{len(combined_data)}ä¸ªç‚¹)', 
                           ha='center', va='center', transform=ax.transAxes)
                    ax.set_title(f'{title_prefix}\næ•°æ®ä¸è¶³')
                    return
                
                x_clean = combined_data.iloc[:, 0]
                y_clean = combined_data.iloc[:, 1]
                
                # ç»˜åˆ¶æ•£ç‚¹å›¾
                ax.scatter(x_clean, y_clean, alpha=0.6, s=30)
                
                # âœ… å®‰å…¨çš„å›å½’çº¿æ‹Ÿåˆ
                try:
                    z = np.polyfit(x_clean, y_clean, 1)
                    p = np.poly1d(z)
                    ax.plot(x_clean, p(x_clean), "r--", alpha=0.8, linewidth=2)
                except np.linalg.LinAlgError:
                    print(f"âš ï¸  {title_prefix}: å›å½’çº¿æ‹Ÿåˆè­¦å‘Š - æ•°æ®çº¿æ€§ç›¸å…³æ€§ä¸è¶³")
                except Exception as e:
                    print(f"âš ï¸  {title_prefix}: å›å½’çº¿æ‹Ÿåˆå¤±è´¥: {e}")
                
                # âœ… å®‰å…¨çš„ç›¸å…³æ€§è®¡ç®—
                try:
                    corr, p_value = pearsonr(x_clean, y_clean)
                    if np.isnan(corr):
                        corr_text = "ç›¸å…³ç³»æ•°: NaN"
                    else:
                        significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*" if p_value < 0.05 else ""
                        corr_text = f'ç›¸å…³ç³»æ•°: {corr:.3f}{significance}\n(n={len(x_clean)})'
                except Exception as e:
                    corr_text = f"è®¡ç®—å¤±è´¥: {str(e)[:20]}"
                
                ax.set_xlabel(xlabel)
                ax.set_ylabel(ylabel)
                ax.set_title(f'{title_prefix}\n{corr_text}')
                ax.grid(True, alpha=0.3)
                
            except Exception as e:
                ax.text(0.5, 0.5, f'Analysis Failed:\n{str(e)[:50]}', ha='center', va='center', transform=ax.transAxes)
                ax.set_title(f'{title_prefix}\nAnalysis Failed')
        
        # æ‰§è¡Œå„é¡¹ç›¸å…³æ€§åˆ†æ
        safe_correlation_analysis(
            self.df[cpu_iowait_col], self.df[data_util_col], axes[0, 0],
            'CPU I/O Wait (%)', 'Device Utilization (%)', 'CPU I/O Wait vs Device Utilization'
        )
        
        safe_correlation_analysis(
            self.df[cpu_iowait_col], self.df[data_await_col], axes[0, 1],
            'CPU I/O Wait (%)', 'I/O Latency (ms)', 'CPU I/O Wait vs I/O Latency'
        )
        
        safe_correlation_analysis(
            self.df[cpu_iowait_col], self.df[data_aqu_col], axes[1, 0],
            'CPU I/O Wait (%)', 'I/Oé˜Ÿåˆ—é•¿åº¦', 'CPU I/O Wait vs I/Oé˜Ÿåˆ—é•¿åº¦'
        )
        
        # âœ… Timeåºåˆ—å¯¹æ¯” (æ”¹è¿›çš„å¤„ç†)
        ax4 = axes[1, 1]
        try:
            cpu_data = self.df[cpu_iowait_col].dropna()
            util_data = self.df[data_util_col].dropna()
            
            if len(cpu_data) > 0 and len(util_data) > 0:
                ax4_twin = ax4.twinx()
                
                ax4.plot(self.df['timestamp'], self.df[cpu_iowait_col], color='blue', linewidth=2, label='CPU I/O Wait')
                ax4_twin.plot(self.df['timestamp'], self.df[data_util_col], color='red', linewidth=2, linestyle='--', alpha=0.7, label='Device Utilization')
                
                ax4.set_xlabel('Time')
                ax4.set_ylabel('CPU I/O Wait (%)', color='blue')
                ax4_twin.set_ylabel('Device Utilization (%)', color='red')
                ax4.set_title('CPU I/O Wait vs Device UtilizationTimeåºåˆ—')
                ax4.grid(True, alpha=0.3)
            else:
                ax4.text(0.5, 0.5, 'Timeåºåˆ—Data Not Available', ha='center', va='center', transform=ax4.transAxes)
                ax4.set_title('Timeåºåˆ—å¯¹æ¯” (Data Not Available)')
        except Exception as e:
            ax4.text(0.5, 0.5, f'Timeåºåˆ—åˆ†æå¤±è´¥:\n{str(e)[:50]}', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('Timeåºåˆ—å¯¹æ¯” (åˆ†æå¤±è´¥)')
        
        plt.tight_layout()
        
        output_file = os.path.join(self.output_dir, 'cpu_ebs_correlation_visualization.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š CPU-EBSç›¸å…³æ€§å¯è§†åŒ–å›¾å·²ä¿å­˜: {output_file}")
        
        return output_file
    
    def create_device_comparison_chart(self):
        """åˆ›å»ºDeviceå¯¹æ¯”å›¾è¡¨ï¼ˆDATA vs ACCOUNTSï¼‰- ä¼˜åŒ–ç‰ˆæœ¬
        
        æ ¹æ® ACCOUNTS Deviceé…ç½®çŠ¶æ€åŠ¨æ€è°ƒæ•´å›¾è¡¨å†…å®¹ï¼š
        - å¦‚æœ ACCOUNTS æœªé…ç½®ï¼šåªæ˜¾ç¤º DATA Deviceåˆ†æ
        - å¦‚æœ ACCOUNTS å·²é…ç½®ï¼šæ˜¾ç¤º DATA vs ACCOUNTS å¯¹æ¯”
        """
        # æ£€æŸ¥ ACCOUNTS Deviceé…ç½®çŠ¶æ€
        accounts_configured = self._is_accounts_configured()
        
        fig, axes = plt.subplots(2, 1, figsize=(15, 10))
        
        # æ ¹æ®é…ç½®çŠ¶æ€è®¾ç½®æ ‡é¢˜
        if accounts_configured:
            fig.suptitle('Deviceæ€§èƒ½å¯¹æ¯”åˆ†æ (DATA vs ACCOUNTS)', fontsize=16, fontweight='bold')
        else:
            fig.suptitle('Deviceæ€§èƒ½åˆ†æ (DATA)', fontsize=16, fontweight='bold')
        
        # æŸ¥æ‰¾Deviceåˆ—
        data_cols = [col for col in self.df.columns if col.startswith('data_')]
        accounts_cols = [col for col in self.df.columns if col.startswith('accounts_')] if accounts_configured else []
        
        if not data_cols:
            print("âŒ æœªæ‰¾åˆ°DATA Deviceæ•°æ®")
            return None
        
        # ä¸Šå›¾ï¼šIOPSå¯¹æ¯”
        ax1 = axes[0]
        data_iops_col = [col for col in data_cols if col.endswith('_total_iops')]
        if data_iops_col:
            ax1.plot(self.df['timestamp'], self.df[data_iops_col[0]], 
                    label='DATA IOPS', linewidth=2, color='blue')
        
        # åªæœ‰åœ¨ ACCOUNTS é…ç½®æ—¶æ‰å¤„ç† ACCOUNTS æ•°æ®
        if accounts_configured and accounts_cols:
            accounts_iops_col = [col for col in accounts_cols if col.endswith('_total_iops')]
            if accounts_iops_col:
                ax1.plot(self.df['timestamp'], self.df[accounts_iops_col[0]], 
                        label='ACCOUNTS IOPS', linewidth=2, color='green')
        
        ax1.set_title('DeviceIOPSå¯¹æ¯”' if accounts_configured else 'DATA DeviceIOPS')
        ax1.set_ylabel('IOPS')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ä¸‹å›¾ï¼šåˆ©ç”¨ç‡å¯¹æ¯”
        ax2 = axes[1]
        data_util_col = [col for col in data_cols if col.endswith('_util')]
        if data_util_col:
            ax2.plot(self.df['timestamp'], self.df[data_util_col[0]], 
                    label='DATA åˆ©ç”¨ç‡', linewidth=2, color='blue')
        
        # åªæœ‰åœ¨ ACCOUNTS é…ç½®æ—¶æ‰å¤„ç† ACCOUNTS æ•°æ®
        if accounts_configured and accounts_cols:
            accounts_util_col = [col for col in accounts_cols if col.endswith('_util')]
            if accounts_util_col:
                ax2.plot(self.df['timestamp'], self.df[accounts_util_col[0]], 
                        label='ACCOUNTS åˆ©ç”¨ç‡', linewidth=2, color='green')
        
        ax2.axhline(y=80, color='orange', linestyle='--', alpha=0.7, label='80% Warning Line')
        ax2.axhline(y=95, color='red', linestyle='--', alpha=0.7, label='95% Critical Line')
        
        ax2.set_title('Device Utilizationå¯¹æ¯”' if accounts_configured else 'DATADevice Utilization')
        ax2.set_xlabel('Time')
        ax2.set_ylabel('Utilization (%)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        output_file = os.path.join(self.output_dir, 'device_performance_comparison.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š Deviceæ€§èƒ½å¯¹æ¯”å›¾å·²ä¿å­˜: {output_file}")
        
        return output_file

    def create_await_threshold_analysis_chart(self):
        """åˆ›å»ºawaitLatencyé˜ˆå€¼åˆ†æå›¾è¡¨ - ä¼˜åŒ–ç‰ˆæœ¬
        
        æ ¹æ® ACCOUNTS Deviceé…ç½®çŠ¶æ€åŠ¨æ€è°ƒæ•´åˆ†æå†…å®¹ï¼š
        - å¦‚æœ ACCOUNTS æœªé…ç½®ï¼šåªåˆ†æ DATA Device
        - å¦‚æœ ACCOUNTS å·²é…ç½®ï¼šåˆ†æ DATA å’Œ ACCOUNTS Device
        """
        # æ£€æŸ¥ ACCOUNTS Deviceé…ç½®çŠ¶æ€
        accounts_configured = self._is_accounts_configured()
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # æ ¹æ®é…ç½®çŠ¶æ€è®¾ç½®æ ‡é¢˜
        if accounts_configured:
            fig.suptitle('I/O Latency(await)é˜ˆå€¼åˆ†æ - DATA & ACCOUNTS', fontsize=16, fontweight='bold')
        else:
            fig.suptitle('I/O Latency(await)é˜ˆå€¼åˆ†æ - DATA', fontsize=16, fontweight='bold')
        
        # è·å–awaitç›¸å…³åˆ—
        data_await_cols = [col for col in self.df.columns if col.startswith('data_') and 'avg_await' in col]
        accounts_await_cols = [col for col in self.df.columns if col.startswith('accounts_') and 'avg_await' in col] if accounts_configured else []
        
        # å¹³å‡ç­‰å¾…Timeè¶‹åŠ¿
        ax1 = axes[0, 0]
        ax1.set_title('å¹³å‡I/Oç­‰å¾…Timeè¶‹åŠ¿')
        
        threshold_violations = {}
        
        # å¤„ç†dataDevice
        if data_await_cols:
            col = data_await_cols[0]
            ax1.plot(self.df['timestamp'], self.df[col], 
                    label='DATA å¹³å‡ç­‰å¾…Time', linewidth=2)
            
            # åˆ†æé˜ˆå€¼è¿è§„
            violations = self._analyze_threshold_violations(
                self.df[col], self.await_thresholds, 'data_avg_await'
            )
            threshold_violations['data_avg_await'] = violations
        
        # åªæœ‰åœ¨ ACCOUNTS é…ç½®æ—¶æ‰å¤„ç† ACCOUNTS æ•°æ®
        if accounts_configured and accounts_await_cols:
            col = accounts_await_cols[0]
            ax1.plot(self.df['timestamp'], self.df[col], 
                    label='ACCOUNTS å¹³å‡ç­‰å¾…Time', linewidth=2)
            
            # åˆ†æé˜ˆå€¼è¿è§„
            violations = self._analyze_threshold_violations(
                self.df[col], self.await_thresholds, 'accounts_avg_await'
            )
            threshold_violations['accounts_avg_await'] = violations
        elif not accounts_configured:
            # æ·»åŠ è¯´æ˜æ–‡æœ¬
            ax1.text(0.02, 0.98, 'ACCOUNTS Deviceæœªé…ç½®', transform=ax1.transAxes, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        ax1.axhline(y=self.await_thresholds['warning'], color='orange', 
                   linestyle='--', alpha=0.7, label='Warning Threshold (20ms)')
        ax1.axhline(y=self.await_thresholds['critical'], color='red', 
                   linestyle='--', alpha=0.7, label='Critical Threshold (50ms)')
        ax1.set_ylabel('ç­‰å¾…Time (ms)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # è¯»ç­‰å¾…Time
        ax2 = axes[0, 1]
        ax2.set_title('è¯»æ“ä½œç­‰å¾…Time')
        
        # è·å–è¯»ç­‰å¾…Timeåˆ—
        data_r_await_cols = [col for col in self.df.columns if col.startswith('data_') and 'r_await' in col]
        accounts_r_await_cols = [col for col in self.df.columns if col.startswith('accounts_') and 'r_await' in col] if accounts_configured else []
        
        if data_r_await_cols:
            col = data_r_await_cols[0]
            ax2.plot(self.df['timestamp'], self.df[col], 
                    label='DATA è¯»ç­‰å¾…Time', linewidth=2)
        
        if accounts_configured and accounts_r_await_cols:
            col = accounts_r_await_cols[0]
            ax2.plot(self.df['timestamp'], self.df[col], 
                    label='ACCOUNTS è¯»ç­‰å¾…Time', linewidth=2)
        elif not accounts_configured:
            ax2.text(0.02, 0.98, 'ACCOUNTS Deviceæœªé…ç½®', transform=ax2.transAxes, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        ax2.axhline(y=self.await_thresholds['warning'], color='orange', 
                   linestyle='--', alpha=0.7)
        ax2.axhline(y=self.await_thresholds['critical'], color='red', 
                   linestyle='--', alpha=0.7)
        ax2.set_ylabel('è¯»ç­‰å¾…Time (ms)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # å†™ç­‰å¾…Time
        ax3 = axes[1, 0]
        ax3.set_title('å†™æ“ä½œç­‰å¾…Time')
        
        # è·å–å†™ç­‰å¾…Timeåˆ—
        data_w_await_cols = [col for col in self.df.columns if col.startswith('data_') and 'w_await' in col]
        accounts_w_await_cols = [col for col in self.df.columns if col.startswith('accounts_') and 'w_await' in col] if accounts_configured else []
        
        if data_w_await_cols:
            col = data_w_await_cols[0]
            ax3.plot(self.df['timestamp'], self.df[col], 
                    label='DATA å†™ç­‰å¾…Time', linewidth=2)
        
        if accounts_configured and accounts_w_await_cols:
            col = accounts_w_await_cols[0]
            ax3.plot(self.df['timestamp'], self.df[col], 
                    label='ACCOUNTS å†™ç­‰å¾…Time', linewidth=2)
        elif not accounts_configured:
            ax3.text(0.02, 0.98, 'ACCOUNTS Deviceæœªé…ç½®', transform=ax3.transAxes, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        ax3.axhline(y=self.await_thresholds['warning'], color='orange', 
                   linestyle='--', alpha=0.7)
        ax3.axhline(y=self.await_thresholds['critical'], color='red', 
                   linestyle='--', alpha=0.7)
        ax3.set_ylabel('å†™ç­‰å¾…Time (ms)')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # é˜ˆå€¼è¿è§„ç»Ÿè®¡
        ax4 = axes[1, 1]
        ax4.set_title('é˜ˆå€¼è¿è§„ç»Ÿè®¡')
        
        if threshold_violations:
            devices = list(threshold_violations.keys())
            warning_pcts = [threshold_violations[dev]['warning_percentage'] for dev in devices]
            critical_pcts = [threshold_violations[dev]['critical_percentage'] for dev in devices]
            
            x = np.arange(len(devices))
            width = 0.35
            
            ax4.bar(x - width/2, warning_pcts, width, label='è­¦å‘Šè¿è§„%', color='orange', alpha=0.7)
            ax4.bar(x + width/2, critical_pcts, width, label='å±é™©è¿è§„%', color='red', alpha=0.7)
            
            ax4.set_xlabel('Device')
            ax4.set_ylabel('è¿è§„ç™¾åˆ†æ¯” (%)')
            ax4.set_xticks(x)
            ax4.set_xticklabels([dev.replace('_avg_await', '') for dev in devices])
            ax4.legend()
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'æ— é˜ˆå€¼è¿è§„æ•°æ®', ha='center', va='center', transform=ax4.transAxes)
        
        plt.tight_layout()
        
        output_file = os.path.join(self.output_dir, 'await_threshold_analysis.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š I/O Latencyé˜ˆå€¼åˆ†æå›¾å·²ä¿å­˜: {output_file}")
        
        return output_file, threshold_violations

    def create_util_threshold_analysis_chart(self):
        """åˆ›å»ºåˆ©ç”¨ç‡é˜ˆå€¼åˆ†æå›¾è¡¨ - ä¼˜åŒ–ç‰ˆæœ¬
        
        æ ¹æ® ACCOUNTS Deviceé…ç½®çŠ¶æ€åŠ¨æ€è°ƒæ•´åˆ†æå†…å®¹ï¼š
        - å¦‚æœ ACCOUNTS æœªé…ç½®ï¼šåªåˆ†æ DATA Device
        - å¦‚æœ ACCOUNTS å·²é…ç½®ï¼šåˆ†æ DATA å’Œ ACCOUNTS Device
        """
        # æ£€æŸ¥ ACCOUNTS Deviceé…ç½®çŠ¶æ€
        accounts_configured = self._is_accounts_configured()
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # æ ¹æ®é…ç½®çŠ¶æ€è®¾ç½®æ ‡é¢˜
        if accounts_configured:
            fig.suptitle('Device Utilizationé˜ˆå€¼åˆ†æ - DATA & ACCOUNTS', fontsize=16, fontweight='bold')
        else:
            fig.suptitle('Device Utilizationé˜ˆå€¼åˆ†æ - DATA', fontsize=16, fontweight='bold')
        
        # è·å–åˆ©ç”¨ç‡ç›¸å…³åˆ—
        data_util_cols = [col for col in self.df.columns if col.startswith('data_') and '_util' in col]
        accounts_util_cols = [col for col in self.df.columns if col.startswith('accounts_') and '_util' in col] if accounts_configured else []
        
        # åˆ©ç”¨ç‡Timeåºåˆ—
        ax1 = axes[0, 0]
        ax1.set_title('Device UtilizationTimeåºåˆ—')
        
        threshold_violations = {}
        
        # å¤„ç†dataDevice
        if data_util_cols:
            col = data_util_cols[0]
            ax1.plot(self.df['timestamp'], self.df[col], 
                    label='DATA åˆ©ç”¨ç‡', linewidth=2)
            
            # åˆ†æé˜ˆå€¼è¿è§„
            violations = self._analyze_threshold_violations(
                self.df[col], self.util_thresholds, 'data_util'
            )
            threshold_violations['data_util'] = violations
        
        # åªæœ‰åœ¨ ACCOUNTS é…ç½®æ—¶æ‰å¤„ç† ACCOUNTS æ•°æ®
        if accounts_configured and accounts_util_cols:
            col = accounts_util_cols[0]
            ax1.plot(self.df['timestamp'], self.df[col], 
                    label='ACCOUNTS åˆ©ç”¨ç‡', linewidth=2)
            
            # åˆ†æé˜ˆå€¼è¿è§„
            violations = self._analyze_threshold_violations(
                self.df[col], self.util_thresholds, 'accounts_util'
            )
            threshold_violations['accounts_util'] = violations
        elif not accounts_configured:
            # æ·»åŠ è¯´æ˜æ–‡æœ¬
            ax1.text(0.02, 0.98, 'ACCOUNTS Deviceæœªé…ç½®', transform=ax1.transAxes, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        ax1.axhline(y=self.util_thresholds['warning'], color='orange', 
                   linestyle='--', alpha=0.7, label='Warning Threshold (85%)')
        ax1.axhline(y=self.util_thresholds['critical'], color='red', 
                   linestyle='--', alpha=0.7, label='Critical Threshold (95%)')
        ax1.set_ylabel('Utilization (%)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # åˆ©ç”¨ç‡åˆ†å¸ƒ
        ax2 = axes[0, 1]
        ax2.set_title('åˆ©ç”¨ç‡åˆ†å¸ƒ')
        
        # å¤„ç†dataDeviceåˆ†å¸ƒ
        if data_util_cols:
            col = data_util_cols[0]
            ax2.hist(self.df[col], bins=30, alpha=0.7, 
                    label='DATA åˆ©ç”¨ç‡åˆ†å¸ƒ')
        
        # åªæœ‰åœ¨ ACCOUNTS é…ç½®æ—¶æ‰å¤„ç† ACCOUNTS æ•°æ®
        if accounts_configured and accounts_util_cols:
            col = accounts_util_cols[0]
            ax2.hist(self.df[col], bins=30, alpha=0.7, 
                    label='ACCOUNTS åˆ©ç”¨ç‡åˆ†å¸ƒ')
        elif not accounts_configured:
            ax2.text(0.02, 0.98, 'ACCOUNTS Deviceæœªé…ç½®', transform=ax2.transAxes, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        ax2.axvline(x=self.util_thresholds['warning'], color='orange', 
                   linestyle='--', alpha=0.7)
        ax2.axvline(x=self.util_thresholds['critical'], color='red', 
                   linestyle='--', alpha=0.7)
        ax2.set_xlabel('Utilization (%)')
        ax2.set_ylabel('é¢‘æ¬¡')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # é«˜åˆ©ç”¨ç‡Timeç»Ÿè®¡
        ax3 = axes[1, 0]
        ax3.set_title('é«˜åˆ©ç”¨ç‡Timeç»Ÿè®¡')
        
        if threshold_violations:
            devices = list(threshold_violations.keys())
            warning_times = [threshold_violations[dev]['warning_violations'] for dev in devices]
            critical_times = [threshold_violations[dev]['critical_violations'] for dev in devices]
            
            x = np.arange(len(devices))
            width = 0.35
            
            ax3.bar(x - width/2, warning_times, width, label='è­¦å‘Šæ¬¡æ•°', color='orange', alpha=0.7)
            ax3.bar(x + width/2, critical_times, width, label='å±é™©æ¬¡æ•°', color='red', alpha=0.7)
            
            ax3.set_xlabel('Device')
            ax3.set_ylabel('è¿è§„æ¬¡æ•°')
            ax3.set_xticks(x)
            ax3.set_xticklabels([dev.replace('_util', '') for dev in devices])
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        else:
            ax3.text(0.5, 0.5, 'æ— é«˜åˆ©ç”¨ç‡è¿è§„', ha='center', va='center', transform=ax3.transAxes)
        
        # é˜ˆå€¼è¿è§„ç™¾åˆ†æ¯”
        ax4 = axes[1, 1]
        ax4.set_title('é˜ˆå€¼è¿è§„ç™¾åˆ†æ¯”')
        
        if threshold_violations:
            devices = list(threshold_violations.keys())
            warning_pcts = [threshold_violations[dev]['warning_percentage'] for dev in devices]
            critical_pcts = [threshold_violations[dev]['critical_percentage'] for dev in devices]
            
            x = np.arange(len(devices))
            width = 0.35
            
            ax4.bar(x - width/2, warning_pcts, width, label='è­¦å‘Šè¿è§„%', color='orange', alpha=0.7)
            ax4.bar(x + width/2, critical_pcts, width, label='å±é™©è¿è§„%', color='red', alpha=0.7)
            
            ax4.set_xlabel('Device')
            ax4.set_ylabel('è¿è§„ç™¾åˆ†æ¯” (%)')
            ax4.set_xticks(x)
            ax4.set_xticklabels([dev.replace('_util', '') for dev in devices])
            ax4.legend()
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'æ— é˜ˆå€¼è¿è§„æ•°æ®', ha='center', va='center', transform=ax4.transAxes)
        
        plt.tight_layout()
        
        output_file = os.path.join(self.output_dir, 'util_threshold_analysis.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š Device Utilizationé˜ˆå€¼åˆ†æå›¾å·²ä¿å­˜: {output_file}")
        
        return output_file, threshold_violations
        
        plt.tight_layout()
        
        output_file = os.path.join(self.output_dir, 'util_threshold_analysis.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š Device Utilizationé˜ˆå€¼åˆ†æå›¾å·²ä¿å­˜: {output_file}")
        
        return output_file, threshold_violations

    def create_monitoring_overhead_analysis_chart(self):
        """åˆ›å»ºç›‘æ§å¼€é”€åˆ†æå›¾è¡¨"""
        if not self.overhead_file or not os.path.exists(self.overhead_file):
            print("âš ï¸ ç›‘æ§å¼€é”€æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¼€é”€åˆ†æå›¾è¡¨")
            return None, {}
        
        try:
            overhead_df = pd.read_csv(self.overhead_file)
            if 'timestamp' in overhead_df.columns:
                overhead_df['timestamp'] = pd.to_datetime(overhead_df['timestamp'])
        except Exception as e:
            print(f"âŒ ç›‘æ§å¼€é”€æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None, {}
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('ç›‘æ§å¼€é”€åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. èµ„æºæ¶ˆè€—å¯¹æ¯” (æ€»èµ„æº vs èŠ‚ç‚¹èµ„æº vs ç›‘æ§å¼€é”€)
        ax1 = axes[0, 0]
        ax1.set_title('ç³»ç»Ÿèµ„æºæ¶ˆè€—å¯¹æ¯”')
        
        if all(col in self.df.columns for col in ['cpu_usage', 'mem_usage']):
            # è®¡ç®—å¹³å‡èµ„æºä½¿ç”¨
            total_cpu = self.df['cpu_usage'].mean()
            total_mem = self.df['mem_usage'].mean()
            
            if all(col in overhead_df.columns for col in ['monitoring_cpu_percent', 'monitoring_mem_percent']):
                monitor_cpu = overhead_df['monitoring_cpu_percent'].mean()
                monitor_mem = overhead_df['monitoring_mem_percent'].mean()
                
                node_cpu = max(0, total_cpu - monitor_cpu)
                node_mem = max(0, total_mem - monitor_mem)
                
                categories = ['CPU Usage (%)', 'Memory Usage (%)']
                total_values = [total_cpu, total_mem]
                node_values = [node_cpu, node_mem]
                monitor_values = [monitor_cpu, monitor_mem]
                
                x = np.arange(len(categories))
                width = 0.25
                
                ax1.bar(x - width, total_values, width, label='æ€»ç³»ç»Ÿèµ„æº', alpha=0.8)
                ax1.bar(x, node_values, width, label='åŒºå—é“¾èŠ‚ç‚¹', alpha=0.8)
                ax1.bar(x + width, monitor_values, width, label='ç›‘æ§å¼€é”€', alpha=0.8)
                
                ax1.set_xticks(x)
                ax1.set_xticklabels(categories)
                ax1.legend()
                ax1.grid(True, alpha=0.3)
        
        # 2. ç›‘æ§å¼€é”€è¶‹åŠ¿
        ax2 = axes[0, 1]
        ax2.set_title('ç›‘æ§å¼€é”€Timeè¶‹åŠ¿')
        
        if 'timestamp' in overhead_df.columns and 'monitoring_cpu_percent' in overhead_df.columns:
            ax2.plot(overhead_df['timestamp'], overhead_df['monitoring_cpu_percent'], 
                    label='CPUå¼€é”€', linewidth=2)
            if 'monitoring_mem_percent' in overhead_df.columns:
                ax2_mem = ax2.twinx()
                ax2_mem.plot(overhead_df['timestamp'], overhead_df['monitoring_mem_percent'], 
                           'r-', label='å†…å­˜å¼€é”€', linewidth=2)
                ax2_mem.set_ylabel('å†…å­˜å¼€é”€ (%)', color='r')
                ax2_mem.tick_params(axis='y', labelcolor='r')
            
            ax2.set_ylabel('CPUå¼€é”€ (%)')
            ax2.legend(loc='upper left')
            ax2.grid(True, alpha=0.3)
        
        # 3. ç›‘æ§è¿›ç¨‹èµ„æºåˆ†å¸ƒ
        ax3 = axes[1, 0]
        ax3.set_title('ç›‘æ§è¿›ç¨‹èµ„æºåˆ†å¸ƒ')
        
        # å¦‚æœæœ‰è¿›ç¨‹çº§åˆ«çš„æ•°æ®
        process_cols = [col for col in overhead_df.columns if col.startswith('process_')]
        if process_cols:
            process_data = []
            process_names = []
            for col in process_cols[:5]:  # æ˜¾ç¤ºå‰5ä¸ªè¿›ç¨‹
                if overhead_df[col].sum() > 0:
                    process_data.append(overhead_df[col].mean())
                    process_names.append(col.replace('process_', '').replace('_cpu', ''))
            
            if process_data:
                ax3.pie(process_data, labels=process_names, autopct='%1.1f%%')
        
        # 4. ç›‘æ§å¼€é”€ç»Ÿè®¡æ‘˜è¦
        ax4 = axes[1, 1]
        ax4.set_title('ç›‘æ§å¼€é”€ç»Ÿè®¡æ‘˜è¦')
        ax4.axis('off')
        
        if all(col in overhead_df.columns for col in ['monitoring_cpu_percent', 'monitoring_mem_percent']):
            stats_text = f"""
ç›‘æ§å¼€é”€ç»Ÿè®¡:

CPUå¼€é”€:
  å¹³å‡: {overhead_df['monitoring_cpu_percent'].mean():.2f}%
  æœ€å¤§: {overhead_df['monitoring_cpu_percent'].max():.2f}%
  æœ€å°: {overhead_df['monitoring_cpu_percent'].min():.2f}%

å†…å­˜å¼€é”€:
  å¹³å‡: {overhead_df['monitoring_mem_percent'].mean():.2f}%
  æœ€å¤§: {overhead_df['monitoring_mem_percent'].max():.2f}%
  æœ€å°: {overhead_df['monitoring_mem_percent'].min():.2f}%

ç›‘æ§æ•ˆç‡:
  æ•°æ®ç‚¹æ•°: {len(overhead_df)}
  ç›‘æ§æ—¶é•¿: {(overhead_df['timestamp'].max() - overhead_df['timestamp'].min()).total_seconds():.0f}ç§’
            """
            ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=10,
                    verticalalignment='top', fontfamily='monospace')
        
        plt.tight_layout()
        
        output_file = os.path.join(self.output_dir, 'monitoring_overhead_analysis.png')
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š ç›‘æ§å¼€é”€åˆ†æå›¾å·²ä¿å­˜: {output_file}")
        
        # è¿”å›å¼€é”€åˆ†æç»“æœ
        overhead_analysis = {}
        if all(col in overhead_df.columns for col in ['monitoring_cpu_percent', 'monitoring_mem_percent']):
            overhead_analysis = {
                'avg_cpu_overhead': overhead_df['monitoring_cpu_percent'].mean(),
                'max_cpu_overhead': overhead_df['monitoring_cpu_percent'].max(),
                'avg_mem_overhead': overhead_df['monitoring_mem_percent'].mean(),
                'max_mem_overhead': overhead_df['monitoring_mem_percent'].max(),
                'total_data_points': len(overhead_df)
            }
        
        return output_file, overhead_analysis

    def generate_all_charts(self):
        print("ğŸ¨ ç”Ÿæˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨...")
        
        if not self.load_data():
            return []
        
        chart_files = []
        threshold_analysis_results = {}
        
        try:
            # ä½¿ç”¨é«˜çº§å›¾è¡¨ç”Ÿæˆå™¨
            if ADVANCED_TOOLS_AVAILABLE and self.chart_generator is not None:
                print("ğŸ¨ ä½¿ç”¨é«˜çº§å›¾è¡¨ç”Ÿæˆå™¨...")
                advanced_charts = self.chart_generator.generate_all_charts()
                if advanced_charts:
                    chart_files.extend(advanced_charts)
            
            # ç”Ÿæˆä¼ ç»Ÿå›¾è¡¨ä½œä¸ºè¡¥å……
            overview_chart = self.create_performance_overview_chart()
            if overview_chart:
                chart_files.append(overview_chart)
                
            correlation_chart = self.create_correlation_visualization_chart()
            if correlation_chart:
                chart_files.append(correlation_chart)
                
            comparison_chart = self.create_device_comparison_chart()
            if comparison_chart:
                chart_files.append(comparison_chart)
            
            # æ–°å¢: ç§»åŠ¨å¹³å‡è¶‹åŠ¿å›¾è¡¨
            smoothed_chart = self.create_smoothed_trend_chart()
            if smoothed_chart:
                chart_files.append(smoothed_chart)
            
            # ç”Ÿæˆé˜ˆå€¼åˆ†æå›¾è¡¨ - é›†æˆè‡ªawait_util_analyzer
            print("ğŸ“Š ç”Ÿæˆé˜ˆå€¼åˆ†æå›¾è¡¨...")
            
            await_chart, await_violations = self.create_await_threshold_analysis_chart()
            if await_chart:
                chart_files.append(await_chart)
                threshold_analysis_results['await_violations'] = await_violations
            
            # ç”ŸæˆQPSè¶‹åŠ¿åˆ†æå›¾è¡¨
            print("ğŸ“Š ç”ŸæˆQPSè¶‹åŠ¿åˆ†æå›¾è¡¨...")
            qps_trend_chart = self.create_qps_trend_analysis_chart()
            if qps_trend_chart:
                chart_files.append(qps_trend_chart)
            
            # ç”Ÿæˆèµ„æºæ•ˆç‡åˆ†æå›¾è¡¨
            print("ğŸ“Š ç”Ÿæˆèµ„æºæ•ˆç‡åˆ†æå›¾è¡¨...")
            efficiency_chart = self.create_resource_efficiency_analysis_chart()
            if efficiency_chart:
                chart_files.append(efficiency_chart)
            
            # ç”Ÿæˆç“¶é¢ˆè¯†åˆ«åˆ†æå›¾è¡¨
            print("ğŸ“Š ç”Ÿæˆç“¶é¢ˆè¯†åˆ«åˆ†æå›¾è¡¨...")
            bottleneck_chart = self.create_bottleneck_identification_chart()
            if bottleneck_chart:
                chart_files.append(bottleneck_chart)
            
            util_chart, util_violations = self.create_util_threshold_analysis_chart()
            if util_chart:
                chart_files.append(util_chart)
                threshold_analysis_results['util_violations'] = util_violations
            
            # ç”Ÿæˆç›‘æ§å¼€é”€åˆ†æå›¾è¡¨
            print("ğŸ“Š ç”Ÿæˆç›‘æ§å¼€é”€åˆ†æå›¾è¡¨...")
            
            overhead_chart, overhead_analysis = self.create_monitoring_overhead_analysis_chart()
            if overhead_chart:
                chart_files.append(overhead_chart)
                threshold_analysis_results['overhead_analysis'] = overhead_analysis
            
            # æ‰“å°é˜ˆå€¼åˆ†ææ‘˜è¦
            self._print_threshold_analysis_summary(threshold_analysis_results)
            
            print(f"âœ… ç”Ÿæˆäº† {len(chart_files)} ä¸ªå›¾è¡¨")
            return chart_files, threshold_analysis_results
            
        except Exception as e:
            print(f"âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return [], {}
    
    def _print_threshold_analysis_summary(self, results):
        """æ‰“å°é˜ˆå€¼åˆ†ææ‘˜è¦ - é›†æˆè‡ªawait_util_analyzer"""
        print("\nğŸ“Š é˜ˆå€¼åˆ†ææ‘˜è¦:")
        print("=" * 60)
        
        if 'await_violations' in results:
            print("\nğŸ• I/O Latencyé˜ˆå€¼åˆ†æ:")
            for device, violations in results['await_violations'].items():
                print(f"  {device}:")
                print(f"    å¹³å‡å€¼: {violations['avg_value']:.2f}ms")
                print(f"    æœ€å¤§å€¼: {violations['max_value']:.2f}ms")
                print(f"    è­¦å‘Šè¿è§„: {violations['warning_violations']}/{violations['total_points']} ({violations['warning_percentage']:.1f}%)")
                print(f"    å±é™©è¿è§„: {violations['critical_violations']}/{violations['total_points']} ({violations['critical_percentage']:.1f}%)")
        
        if 'util_violations' in results:
            print("\nğŸ“ˆ Device Utilizationé˜ˆå€¼åˆ†æ:")
            for device, violations in results['util_violations'].items():
                print(f"  {device}:")
                print(f"    å¹³å‡å€¼: {violations['avg_value']:.1f}%")
                print(f"    æœ€å¤§å€¼: {violations['max_value']:.1f}%")
                print(f"    è­¦å‘Šè¿è§„: {violations['warning_violations']}/{violations['total_points']} ({violations['warning_percentage']:.1f}%)")
                print(f"    å±é™©è¿è§„: {violations['critical_violations']}/{violations['total_points']} ({violations['critical_percentage']:.1f}%)")
        
        # æ–°å¢ï¼šè¯¦ç»†çš„ç›‘æ§å¼€é”€åˆ†ææ‘˜è¦
        if 'overhead_analysis' in results:
            print("\nğŸ’» ç›‘æ§å¼€é”€è¯¦ç»†åˆ†æ:")
            overhead = results['overhead_analysis']
            print(f"  CPUå¼€é”€:")
            print(f"    å¹³å‡å¼€é”€: {overhead.get('avg_cpu_overhead', 0):.2f}%")
            print(f"    å³°å€¼å¼€é”€: {overhead.get('max_cpu_overhead', 0):.2f}%")
            print(f"  å†…å­˜å¼€é”€:")
            print(f"    å¹³å‡å¼€é”€: {overhead.get('avg_mem_overhead', 0):.2f}%")
            print(f"    å³°å€¼å¼€é”€: {overhead.get('max_mem_overhead', 0):.2f}%")
            print(f"  ç›‘æ§æ•ˆç‡:")
            print(f"    æ•°æ®ç‚¹æ•°: {overhead.get('total_data_points', 0)}")
            
            # è®¡ç®—èµ„æºæ•ˆç‡æ¯”
            if self.df is not None and len(self.df) > 0:
                if 'cpu_usage' in self.df.columns:
                    total_cpu = self.df['cpu_usage'].mean()
                    overhead_cpu = overhead.get('avg_cpu_overhead', 0)
                    if total_cpu > 0:
                        cpu_efficiency = (1 - overhead_cpu / total_cpu) * 100
                        print(f"    CPUæ•ˆç‡: {cpu_efficiency:.1f}% (èŠ‚ç‚¹å®é™…ä½¿ç”¨)")
                
                if 'mem_usage' in self.df.columns:
                    total_mem = self.df['mem_usage'].mean()
                    overhead_mem = overhead.get('avg_mem_overhead', 0)
                    if total_mem > 0:
                        mem_efficiency = (1 - overhead_mem / total_mem) * 100
                        print(f"    å†…å­˜æ•ˆç‡: {mem_efficiency:.1f}% (èŠ‚ç‚¹å®é™…ä½¿ç”¨)")
        
        print("=" * 60)

    def create_smoothed_trend_chart(self):
        """
        ç”Ÿæˆç§»åŠ¨å¹³å‡å¹³æ»‘è¶‹åŠ¿å›¾è¡¨
        æ˜¾ç¤ºåŸå§‹æ•°æ®å’Œå¹³æ»‘åçš„è¶‹åŠ¿çº¿å¯¹æ¯”
        """
        print("ğŸ“ˆ ç”Ÿæˆç§»åŠ¨å¹³å‡è¶‹åŠ¿å›¾è¡¨...")
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(18, 12))
            fig.suptitle('æ€§èƒ½æŒ‡æ ‡ç§»åŠ¨å¹³å‡è¶‹åŠ¿åˆ†æ', fontsize=16, fontweight='bold')
            
            # ç§»åŠ¨å¹³å‡çª—å£å¤§å°
            window_size = min(10, len(self.df) // 10)  # è‡ªé€‚åº”çª—å£å¤§å°
            if window_size < 3:
                window_size = 3
            
            # 1. CPU Usageè¶‹åŠ¿
            ax1 = axes[0, 0]
            ax1.plot(self.df['timestamp'], self.df['cpu_usage'], 
                    color='lightblue', linewidth=1, alpha=0.5, label='CPU Usage(åŸå§‹)')
            
            cpu_smooth = self.df['cpu_usage'].rolling(window=window_size, center=True).mean()
            ax1.plot(self.df['timestamp'], cpu_smooth, 
                    color='blue', linewidth=2, label=f'CPU Usage({window_size}ç‚¹å¹³æ»‘)')
            
            ax1.set_title('CPU Usageè¶‹åŠ¿')
            ax1.set_ylabel('Usage (%)')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # 2. Memory Usageè¶‹åŠ¿
            ax2 = axes[0, 1]
            ax2.plot(self.df['timestamp'], self.df['mem_usage'], 
                    color='lightcoral', linewidth=1, alpha=0.5, label='Memory Usage(åŸå§‹)')
            
            mem_smooth = self.df['mem_usage'].rolling(window=window_size, center=True).mean()
            ax2.plot(self.df['timestamp'], mem_smooth, 
                    color='red', linewidth=2, label=f'Memory Usage({window_size}ç‚¹å¹³æ»‘)')
            
            ax2.set_title('Memory Usageè¶‹åŠ¿')
            ax2.set_ylabel('Usage (%)')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # 3. EBSLatencyè¶‹åŠ¿
            data_await_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_avg_await')]
            if data_await_cols:
                ax3 = axes[1, 0]
                await_col = data_await_cols[0]
                
                ax3.plot(self.df['timestamp'], self.df[await_col], 
                        color='lightgreen', linewidth=1, alpha=0.5, label='EBSLatency(åŸå§‹)')
                
                await_smooth = self.df[await_col].rolling(window=window_size, center=True).mean()
                ax3.plot(self.df['timestamp'], await_smooth, 
                        color='green', linewidth=2, label=f'EBSLatency({window_size}ç‚¹å¹³æ»‘)')
                
                ax3.set_title('EBSLatencyè¶‹åŠ¿')
                ax3.set_ylabel('Latency (ms)')
                ax3.legend()
                ax3.grid(True, alpha=0.3)
            else:
                axes[1, 0].text(0.5, 0.5, 'æœªæ‰¾åˆ°EBSLatencyæ•°æ®', ha='center', va='center', transform=axes[1, 0].transAxes)
                axes[1, 0].set_title('EBSLatencyè¶‹åŠ¿ (æ— æ•°æ®)')
            
            # 4. ç½‘ç»œå¸¦å®½è¶‹åŠ¿
            if 'net_rx_mbps' in self.df.columns:
                ax4 = axes[1, 1]
                ax4.plot(self.df['timestamp'], self.df['net_rx_mbps'], 
                        color='lightcoral', linewidth=1, alpha=0.5, label='ç½‘ç»œæ¥æ”¶(åŸå§‹)')
                
                net_smooth = self.df['net_rx_mbps'].rolling(window=window_size, center=True).mean()
                ax4.plot(self.df['timestamp'], net_smooth, 
                        color='orange', linewidth=2, label=f'ç½‘ç»œæ¥æ”¶({window_size}ç‚¹å¹³æ»‘)')
                
                ax4.set_title('ç½‘ç»œå¸¦å®½è¶‹åŠ¿')
                ax4.set_ylabel('å¸¦å®½ (Mbps)')
                ax4.legend()
                ax4.grid(True, alpha=0.3)
            else:
                axes[1, 1].text(0.5, 0.5, 'æœªæ‰¾åˆ°ç½‘ç»œå¸¦å®½æ•°æ®', ha='center', va='center', transform=axes[1, 1].transAxes)
                axes[1, 1].set_title('ç½‘ç»œå¸¦å®½è¶‹åŠ¿ (æ— æ•°æ®)')
            
            # æ ¼å¼åŒ–Timeè½´
            for ax in axes.flat:
                ax.tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            output_file = os.path.join(self.output_dir, 'smoothed_trend_analysis.png')
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… ç§»åŠ¨å¹³å‡è¶‹åŠ¿å›¾: {os.path.basename(output_file)}")
            return output_file
            
        except Exception as e:
            print(f"âŒ ç§»åŠ¨å¹³å‡è¶‹åŠ¿å›¾ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def create_qps_trend_analysis_chart(self):
        """QPSè¶‹åŠ¿åˆ†æå›¾"""
        print("ğŸ“Š ç”ŸæˆQPSè¶‹åŠ¿åˆ†æå›¾è¡¨...")
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('QPSæ€§èƒ½è¶‹åŠ¿åˆ†æ', fontsize=16, fontweight='bold')
            
            # æŸ¥æ‰¾QPSç›¸å…³å­—æ®µ
            qps_cols = [col for col in self.df.columns if 'qps' in col.lower()]
            if not qps_cols:
                print("âš ï¸  æœªæ‰¾åˆ°QPSç›¸å…³å­—æ®µ")
                plt.close()
                return None
            
            # 1. QPSTimeåºåˆ—
            ax1 = axes[0, 0]
            for qps_col in qps_cols[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªQPSæŒ‡æ ‡
                ax1.plot(self.df['timestamp'], self.df[qps_col], label=qps_col, linewidth=2)
            ax1.set_title('QPSTimeåºåˆ—')
            ax1.set_ylabel('QPS')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # 2. QPSåˆ†å¸ƒç›´æ–¹å›¾
            ax2 = axes[0, 1]
            for qps_col in qps_cols[:2]:
                ax2.hist(self.df[qps_col].dropna(), alpha=0.7, label=qps_col, bins=30)
            ax2.set_title('QPSåˆ†å¸ƒ')
            ax2.set_xlabel('QPS')
            ax2.set_ylabel('é¢‘æ¬¡')
            ax2.legend()
            
            # 3. QPSä¸CPUç›¸å…³æ€§
            ax3 = axes[1, 0]
            if 'cpu_usage' in self.df.columns and qps_cols:
                ax3.scatter(self.df['cpu_usage'], self.df[qps_cols[0]], alpha=0.6)
                ax3.set_title('QPS vs CPU Usage')
                ax3.set_xlabel('CPU Usage (%)')
                ax3.set_ylabel('QPS')
                ax3.grid(True, alpha=0.3)
            
            # 4. QPSç»Ÿè®¡æ‘˜è¦
            ax4 = axes[1, 1]
            ax4.axis('off')
            stats_text = "QPSç»Ÿè®¡æ‘˜è¦:\n\n"
            for qps_col in qps_cols[:3]:
                qps_data = self.df[qps_col].dropna()
                if len(qps_data) > 0:
                    stats_text += f"{qps_col}:\n"
                    stats_text += f"  å¹³å‡: {qps_data.mean():.2f}\n"
                    stats_text += f"  æœ€å¤§: {qps_data.max():.2f}\n"
                    stats_text += f"  æœ€å°: {qps_data.min():.2f}\n\n"
            ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=10, verticalalignment='top')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            output_file = os.path.join(self.output_dir, 'qps_trend_analysis.png')
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… QPSè¶‹åŠ¿åˆ†æå›¾: {os.path.basename(output_file)}")
            return output_file
            
        except Exception as e:
            print(f"âŒ QPSè¶‹åŠ¿åˆ†æå›¾ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def create_resource_efficiency_analysis_chart(self):
        """èµ„æºæ•ˆç‡åˆ†æå›¾"""
        print("ğŸ“Š ç”Ÿæˆèµ„æºæ•ˆç‡åˆ†æå›¾è¡¨...")
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('èµ„æºæ•ˆç‡åˆ†æ', fontsize=16, fontweight='bold')
            
            # 1. CPUæ•ˆç‡åˆ†æ
            ax1 = axes[0, 0]
            if 'cpu_usage' in self.df.columns:
                cpu_data = self.df['cpu_usage'].dropna()
                efficiency_ranges = ['ä½æ•ˆ(<30%)', 'ä¸€èˆ¬(30-60%)', 'é«˜æ•ˆ(60-85%)', 'è¿‡è½½(>85%)']
                efficiency_counts = [
                    len(cpu_data[cpu_data < 30]),
                    len(cpu_data[(cpu_data >= 30) & (cpu_data < 60)]),
                    len(cpu_data[(cpu_data >= 60) & (cpu_data < 85)]),
                    len(cpu_data[cpu_data >= 85])
                ]
                ax1.pie(efficiency_counts, labels=efficiency_ranges, autopct='%1.1f%%')
                ax1.set_title('CPUæ•ˆç‡åˆ†å¸ƒ')
            
            # 2. å†…å­˜æ•ˆç‡åˆ†æ
            ax2 = axes[0, 1]
            if 'mem_usage' in self.df.columns:
                mem_data = self.df['mem_usage'].dropna()
                mem_ranges = ['ä½æ•ˆ(<40%)', 'ä¸€èˆ¬(40-70%)', 'é«˜æ•ˆ(70-90%)', 'è¿‡è½½(>90%)']
                mem_counts = [
                    len(mem_data[mem_data < 40]),
                    len(mem_data[(mem_data >= 40) & (mem_data < 70)]),
                    len(mem_data[(mem_data >= 70) & (mem_data < 90)]),
                    len(mem_data[mem_data >= 90])
                ]
                ax2.pie(mem_counts, labels=mem_ranges, autopct='%1.1f%%')
                ax2.set_title('å†…å­˜æ•ˆç‡åˆ†å¸ƒ')
            
            # 3. I/Oæ•ˆç‡åˆ†æ
            ax3 = axes[1, 0]
            data_util_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_util')]
            if data_util_cols:
                util_col = data_util_cols[0]
                util_data = self.df[util_col].dropna()
                ax3.hist(util_data, bins=20, alpha=0.7, color='green')
                ax3.axvline(util_data.mean(), color='red', linestyle='--', label=f'å¹³å‡: {util_data.mean():.1f}%')
                ax3.set_title('I/Oåˆ©ç”¨ç‡åˆ†å¸ƒ')
                ax3.set_xlabel('Utilization (%)')
                ax3.set_ylabel('é¢‘æ¬¡')
                ax3.legend()
            
            # 4. æ•ˆç‡ç»Ÿè®¡æ‘˜è¦
            ax4 = axes[1, 1]
            ax4.axis('off')
            stats_text = "æ•ˆç‡ç»Ÿè®¡æ‘˜è¦:\n\n"
            if 'cpu_usage' in self.df.columns:
                cpu_avg = self.df['cpu_usage'].mean()
                stats_text += f"CPUå¹³å‡åˆ©ç”¨ç‡: {cpu_avg:.1f}%\n"
            if 'mem_usage' in self.df.columns:
                mem_avg = self.df['mem_usage'].mean()
                stats_text += f"å†…å­˜å¹³å‡åˆ©ç”¨ç‡: {mem_avg:.1f}%\n"
            if data_util_cols:
                io_avg = self.df[data_util_cols[0]].mean()
                stats_text += f"I/Oå¹³å‡åˆ©ç”¨ç‡: {io_avg:.1f}%\n"
            ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=12, verticalalignment='top')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            output_file = os.path.join(self.output_dir, 'resource_efficiency_analysis.png')
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… èµ„æºæ•ˆç‡åˆ†æå›¾: {os.path.basename(output_file)}")
            return output_file
            
        except Exception as e:
            print(f"âŒ èµ„æºæ•ˆç‡åˆ†æå›¾ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def create_bottleneck_identification_chart(self):
        """ç“¶é¢ˆè¯†åˆ«åˆ†æå›¾"""
        print("ğŸ“Š ç”Ÿæˆç“¶é¢ˆè¯†åˆ«åˆ†æå›¾è¡¨...")
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('ç³»ç»Ÿç“¶é¢ˆè¯†åˆ«åˆ†æ', fontsize=16, fontweight='bold')
            
            # 1. ç“¶é¢ˆTimeåºåˆ—
            ax1 = axes[0, 0]
            bottleneck_data = []
            
            if 'cpu_usage' in self.df.columns:
                cpu_bottleneck = (self.df['cpu_usage'] > 85).astype(int)
                ax1.plot(self.df['timestamp'], cpu_bottleneck, label='CPUç“¶é¢ˆ(>85%)', linewidth=2)
                bottleneck_data.append(('CPU', cpu_bottleneck.sum()))
            
            if 'mem_usage' in self.df.columns:
                mem_bottleneck = (self.df['mem_usage'] > 90).astype(int)
                ax1.plot(self.df['timestamp'], mem_bottleneck, label='å†…å­˜ç“¶é¢ˆ(>90%)', linewidth=2)
                bottleneck_data.append(('å†…å­˜', mem_bottleneck.sum()))
            
            data_util_cols = [col for col in self.df.columns if col.startswith('data_') and col.endswith('_util')]
            if data_util_cols:
                io_bottleneck = (self.df[data_util_cols[0]] > 80).astype(int)
                ax1.plot(self.df['timestamp'], io_bottleneck, label='I/Oç“¶é¢ˆ(>80%)', linewidth=2)
                bottleneck_data.append(('I/O', io_bottleneck.sum()))
            
            ax1.set_title('ç“¶é¢ˆTimeåºåˆ—')
            ax1.set_ylabel('ç“¶é¢ˆçŠ¶æ€')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # 2. ç“¶é¢ˆé¢‘æ¬¡ç»Ÿè®¡
            ax2 = axes[0, 1]
            if bottleneck_data:
                resources, counts = zip(*bottleneck_data)
                ax2.bar(resources, counts, color=['red', 'orange', 'yellow'])
                ax2.set_title('ç“¶é¢ˆé¢‘æ¬¡ç»Ÿè®¡')
                ax2.set_ylabel('ç“¶é¢ˆæ¬¡æ•°')
                for i, count in enumerate(counts):
                    ax2.text(i, count + max(counts) * 0.01, str(count), ha='center')
            
            # 3. èµ„æºä½¿ç”¨ç‡çƒ­åŠ›å›¾
            ax3 = axes[1, 0]
            resource_cols = []
            if 'cpu_usage' in self.df.columns:
                resource_cols.append('cpu_usage')
            if 'mem_usage' in self.df.columns:
                resource_cols.append('mem_usage')
            if data_util_cols:
                resource_cols.append(data_util_cols[0])
            
            if resource_cols:
                resource_data = self.df[resource_cols].dropna()
                if len(resource_data) > 0:
                    im = ax3.imshow(resource_data.T, aspect='auto', cmap='RdYlBu_r')
                    ax3.set_title('èµ„æºä½¿ç”¨ç‡çƒ­åŠ›å›¾')
                    ax3.set_yticks(range(len(resource_cols)))
                    ax3.set_yticklabels(resource_cols)
                    plt.colorbar(im, ax=ax3)
            
            # 4. ç“¶é¢ˆåˆ†ææ‘˜è¦
            ax4 = axes[1, 1]
            ax4.axis('off')
            summary_text = "ç“¶é¢ˆåˆ†ææ‘˜è¦:\n\n"
            total_points = len(self.df)
            
            for resource, count in bottleneck_data:
                percentage = (count / total_points) * 100 if total_points > 0 else 0
                summary_text += f"{resource}ç“¶é¢ˆ:\n"
                summary_text += f"  å‘ç”Ÿæ¬¡æ•°: {count}\n"
                summary_text += f"  å æ¯”: {percentage:.1f}%\n\n"
            
            ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=10, verticalalignment='top')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            output_file = os.path.join(self.output_dir, 'bottleneck_identification.png')
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… ç“¶é¢ˆè¯†åˆ«åˆ†æå›¾: {os.path.basename(output_file)}")
            return output_file
            
        except Exception as e:
            print(f"âŒ ç“¶é¢ˆè¯†åˆ«åˆ†æå›¾ç”Ÿæˆå¤±è´¥: {e}")
            return None

def main():
    parser = argparse.ArgumentParser(description='æ€§èƒ½å¯è§†åŒ–å™¨')
    parser.add_argument('data_file', help='ç³»ç»Ÿæ€§èƒ½ç›‘æ§CSVæ–‡ä»¶')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.data_file):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_file}")
        return 1
    
    visualizer = PerformanceVisualizer(args.data_file)
    
    result = visualizer.generate_all_charts()
    
    if result:
        print("ğŸ‰ æ€§èƒ½å¯è§†åŒ–å®Œæˆ!")
        return 0
    else:
        print("âŒ æ€§èƒ½å¯è§†åŒ–å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit(main())
