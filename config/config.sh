#!/bin/bash
# =====================================================================
# Solana QPS æµ‹è¯•æ¡†æ¶ - ç»Ÿä¸€é…ç½®æ–‡ä»¶
# =====================================================================
# ç‰ˆæœ¬: 2.0 - ç”Ÿäº§çº§é…ç½®ç®¡ç†
# =====================================================================

# =====================================================================
# ç”¨æˆ·é…ç½®åŒºåŸŸ - è¯·æ ¹æ®æ‚¨çš„ç¯å¢ƒä¿®æ”¹ä»¥ä¸‹é…ç½®
# =====================================================================

# ----- åŸºç¡€é…ç½® -----
# RPC ç«¯ç‚¹é…ç½®
LOCAL_RPC_URL=${RPC_URL:-"http://localhost:8899"}
# Mainnet RPC (ç”¨äºå¯¹æ¯”æµ‹è¯•)
MAINNET_RPC_URL="https://api.mainnet-beta.solana.com"

# ----- åŒºå—é“¾èŠ‚ç‚¹é…ç½® -----
BLOCKCHAIN_NODE="Solana"

# ----- EBS è®¾å¤‡é…ç½® -----
# DATA è®¾å¤‡ (LEDGER æ•°æ®å­˜å‚¨)
LEDGER_DEVICE="nvme1n1"
# ACCOUNTS è®¾å¤‡ (å¯é€‰ï¼Œç”¨äºè´¦æˆ·æ•°æ®å­˜å‚¨)
ACCOUNTS_DEVICE="nvme2n1"

# Data volume configuration
DATA_VOL_TYPE="io2"                    # Options: "gp3" | "io2" | "instance-store"
DATA_VOL_SIZE="2000"                   # Current required data size to keep both snapshot archive and unarchived version of it
DATA_VOL_MAX_IOPS="20000"              # Max IOPS for EBS volumes (REQUIRED for "instance-store")
DATA_VOL_MAX_THROUGHPUT="700"          # Max throughput in MiB/s (REQUIRED for "instance-store", auto-calculated for "io2")

# Accounts volume configuration (optional)
ACCOUNTS_VOL_TYPE="io2"                # Options: "gp3" | "io2" | "instance-store"
ACCOUNTS_VOL_SIZE="500"                # Current required data size to keep both snapshot archive and unarchived version of it
ACCOUNTS_VOL_MAX_IOPS="20000"          # Max IOPS for EBS volumes (REQUIRED for "instance-store")
ACCOUNTS_VOL_MAX_THROUGHPUT="700"      # Max throughput in MiB/s (REQUIRED for "instance-store", auto-calculated for "io2")

# =====================================================================
# Instance Store é…ç½®è¯´æ˜
# =====================================================================
# å¦‚æœä½¿ç”¨ "instance-store" ç±»å‹ï¼Œå¿…é¡»æ ¹æ®æ‚¨çš„EC2å®ä¾‹ç±»å‹é…ç½®æ€§èƒ½å‚æ•°:
# é…ç½®ç¤ºä¾‹:
# DATA_VOL_TYPE="instance-store"
# DATA_VOL_MAX_IOPS="8000"        # æ ¹æ®å®ä¾‹ç±»å‹è®¾ç½®
# DATA_VOL_MAX_THROUGHPUT="600"   # æ ¹æ®å®ä¾‹ç±»å‹è®¾ç½®
#
# å‚è€ƒæ–‡æ¡£: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-store-policy.html
# =====================================================================

# ----- ç½‘ç»œç›‘æ§é…ç½® -----
# EC2å®ä¾‹ç½‘ç»œå¸¦å®½é…ç½® (å•ä½: Gbps) - ç”¨æˆ·å¿…é¡»æ ¹æ®EC2å®ä¾‹ç±»å‹è®¾ç½®
# ğŸ“– å‚è€ƒ: https://docs.aws.amazon.com/ec2/latest/userguide/ec2-instance-network-bandwidth.html

NETWORK_MAX_BANDWIDTH_GBPS=25       # ç½‘ç»œæœ€å¤§å¸¦å®½ (å•ä½: Gbps) - ç”¨æˆ·å¿…é¡»æ ¹æ®EC2å®ä¾‹ç±»å‹è®¾ç½®

# ç½‘ç»œåˆ©ç”¨ç‡é˜ˆå€¼ (%) - ç”¨äºç“¶é¢ˆæ£€æµ‹
NETWORK_UTILIZATION_THRESHOLD=80    # ç½‘ç»œåˆ©ç”¨ç‡è¶…è¿‡80%è§†ä¸ºç“¶é¢ˆ

# ----- éƒ¨ç½²å¹³å°æ£€æµ‹é…ç½® -----
# éƒ¨ç½²å¹³å°ç±»å‹ (auto: è‡ªåŠ¨æ£€æµ‹, aws: AWSç¯å¢ƒ, other: å…¶ä»–ç¯å¢ƒ)
DEPLOYMENT_PLATFORM=${DEPLOYMENT_PLATFORM:-"auto"}

# ENAç½‘ç»œé™åˆ¶ç›‘æ§é…ç½® - åŸºäºAWS ENAæ–‡æ¡£ (å°†æ ¹æ®éƒ¨ç½²å¹³å°è‡ªåŠ¨è°ƒæ•´)
ENA_MONITOR_ENABLED=true
ENA_ALLOWANCE_FIELDS=(
    "bw_in_allowance_exceeded"
    "bw_out_allowance_exceeded" 
    "pps_allowance_exceeded"
    "conntrack_allowance_exceeded"
    "linklocal_allowance_exceeded"
    "conntrack_allowance_available"
)

# ----- ç»Ÿä¸€æ—¥å¿—ç®¡ç†é…ç½® -----
# æ—¥å¿—çº§åˆ«é…ç½® (0=DEBUG, 1=INFO, 2=WARN, 3=ERROR, 4=FATAL)
LOG_LEVEL=${LOG_LEVEL:-1}  # é»˜è®¤INFOçº§åˆ«

# æ—¥å¿—æ ¼å¼é…ç½®
LOG_FORMAT=${LOG_FORMAT:-"[%timestamp%] [%level%] [%component%] %message%"}

# æ—¥å¿—è½®è½¬é…ç½®
MAX_LOG_SIZE=${MAX_LOG_SIZE:-"10M"}    # æœ€å¤§æ—¥å¿—æ–‡ä»¶å¤§å°
MAX_LOG_FILES=${MAX_LOG_FILES:-5}      # ä¿ç•™çš„æ—¥å¿—æ–‡ä»¶æ•°é‡

# æ—¥å¿—è¾“å‡ºé…ç½®
LOG_CONSOLE=${LOG_CONSOLE:-true}       # æ§åˆ¶å°è¾“å‡º
LOG_FILE=${LOG_FILE:-true}             # æ–‡ä»¶è¾“å‡º
LOG_JSON=${LOG_JSON:-false}            # JSONæ ¼å¼è¾“å‡º

# Pythonæ—¥å¿—é…ç½®
PYTHON_LOG_LEVEL=${PYTHON_LOG_LEVEL:-"INFO"}

# å¯¼å‡ºæ—¥å¿—é…ç½®ç¯å¢ƒå˜é‡
export LOG_LEVEL LOG_FORMAT MAX_LOG_SIZE MAX_LOG_FILES
export LOG_CONSOLE LOG_FILE LOG_JSON PYTHON_LOG_LEVEL

# ----- ç›‘æ§é…ç½® -----
# ç»Ÿä¸€ç›‘æ§é—´éš” (ç§’)
MONITOR_INTERVAL=5
# é»˜è®¤ç›‘æ§æ—¶é•¿ (ç§’) - é€‚åˆQPSæµ‹è¯•
DEFAULT_MONITOR_DURATION=1800  # 30åˆ†é’Ÿ
# é«˜é¢‘ç›‘æ§é—´éš” (ç§’)
HIGH_FREQ_INTERVAL=1
# ç›‘æ§å¼€é”€ç»Ÿè®¡é—´éš” (ç§’)
OVERHEAD_STAT_INTERVAL=60

# æ—¶é—´æ ¼å¼æ ‡å‡†
TIMESTAMP_FORMAT="%Y-%m-%d %H:%M:%S"

# ----- Slot ç›‘æ§é…ç½® -----
# Slot å·®å¼‚é˜ˆå€¼
SLOT_DIFF_THRESHOLD=500
# Slot æ—¶é—´é˜ˆå€¼ (ç§’)
SLOT_TIME_THRESHOLD=600
# Slot ç›‘æ§é—´éš” (ç§’)
SLOT_MONITOR_INTERVAL=10

# ----- æ—¥å¿—æ–‡ä»¶è·¯å¾„é…ç½® -----
# Validator æ—¥å¿—è·¯å¾„ - Solanaç”Ÿäº§ç¯å¢ƒæ—¥å¿— (åªè¯»ï¼Œç”¨äºåˆ†æ)
VALIDATOR_LOG_PATH="/data/data/log/validator.log"

# ----- QPS åŸºå‡†æµ‹è¯•é…ç½® -----
# å¿«é€ŸåŸºå‡†æµ‹è¯•æ¨¡å¼ (éªŒè¯åŸºæœ¬QPSèƒ½åŠ›)
QUICK_INITIAL_QPS=1000
QUICK_MAX_QPS=3000
QUICK_QPS_STEP=500
QUICK_DURATION=300  # æ¯ä¸ªQPSçº§åˆ«æµ‹è¯•5åˆ†é’Ÿ

# æ ‡å‡†åŸºå‡†æµ‹è¯•æ¨¡å¼ (æ ‡å‡†æ€§èƒ½æµ‹è¯•)
STANDARD_INITIAL_QPS=1000
STANDARD_MAX_QPS=5000
STANDARD_QPS_STEP=500
STANDARD_DURATION=600   # æ¯ä¸ªQPSçº§åˆ«æµ‹è¯•10åˆ†é’Ÿ

# æ·±åº¦åŸºå‡†æµ‹è¯•æ¨¡å¼ (è‡ªåŠ¨å¯»æ‰¾ç³»ç»Ÿç“¶é¢ˆ)
INTENSIVE_INITIAL_QPS=1000
INTENSIVE_MAX_QPS=999999      # æ— å®é™…ä¸Šé™ï¼Œç›´åˆ°æ£€æµ‹åˆ°ç“¶é¢ˆ
INTENSIVE_QPS_STEP=250
INTENSIVE_DURATION=600        # æ¯ä¸ªQPSçº§åˆ«æµ‹è¯•10åˆ†é’Ÿ
INTENSIVE_AUTO_STOP=true      # å¯ç”¨è‡ªåŠ¨ç“¶é¢ˆæ£€æµ‹åœæ­¢

# åŸºå‡†æµ‹è¯•é—´éš”é…ç½®
QPS_COOLDOWN=30      # QPSçº§åˆ«é—´çš„å†·å´æ—¶é—´ (ç§’)
QPS_WARMUP_DURATION=60  # é¢„çƒ­æ—¶é—´ (ç§’)

# QPSæµ‹è¯•æˆåŠŸç‡å’Œå»¶è¿Ÿé˜ˆå€¼
SUCCESS_RATE_THRESHOLD=95    # æˆåŠŸç‡é˜ˆå€¼ (%)
MAX_LATENCY_THRESHOLD=1000   # æœ€å¤§å»¶è¿Ÿé˜ˆå€¼ (ms)
MAX_RETRIES=3               # æœ€å¤§é‡è¯•æ¬¡æ•°

# è´¦æˆ·å’Œç›®æ ‡æ–‡ä»¶é…ç½®
ACCOUNT_COUNT=1000                                              # é»˜è®¤è´¦æˆ·æ•°é‡

# ----- è´¦æˆ·è·å–å·¥å…·é…ç½® -----
# è´¦æˆ·è·å–å·¥å…·çš„è¯¦ç»†é…ç½®å‚æ•°
ACCOUNT_OUTPUT_FILE="active_accounts.txt"                       # è¾“å‡ºæ–‡ä»¶å
ACCOUNT_TARGET_ADDRESS="TSLvdd1pWpHVjahSpsvCXUbgwsL3JAcvokwaKt1eokM"  # ç¤ºä¾‹ç›®æ ‡åœ°å€
ACCOUNT_MAX_SIGNATURES=50000                                    # æœ€å¤§ç­¾åæ•°é‡
ACCOUNT_TX_BATCH_SIZE=100                                      # äº¤æ˜“æ‰¹å¤„ç†å¤§å°
ACCOUNT_SEMAPHORE_LIMIT=10                                     # å¹¶å‘é™åˆ¶

# ----- é”™è¯¯å¤„ç†å’Œæ—¥å¿—é…ç½® -----
# åŸºäºç»Ÿä¸€è·¯å¾„ç»“æ„çš„é”™è¯¯å¤„ç†ç›®å½• (å°†åœ¨detect_deployment_pathsä¸­è®¾ç½®å®Œæ•´è·¯å¾„)
ERROR_LOG_SUBDIR="error_logs"                                  # é”™è¯¯æ—¥å¿—å­ç›®å½•å
PYTHON_ERROR_LOG_SUBDIR="python_logs"                         # Pythoné”™è¯¯æ—¥å¿—å­ç›®å½•å
TEMP_FILE_PREFIX="solana-qps"                                 # ä¸´æ—¶æ–‡ä»¶å‰ç¼€

# ----- AWSç›¸å…³é…ç½® -----
# AWS EBSåŸºå‡†é…ç½®
AWS_EBS_BASELINE_IO_SIZE_KIB=16                               # AWS EBSåŸºå‡†IOå¤§å° (KiB)

# AWSå…ƒæ•°æ®æœåŠ¡ç«¯ç‚¹é…ç½®
AWS_METADATA_ENDPOINT="http://169.254.169.254"                # AWSå®ä¾‹å…ƒæ•°æ®ç«¯ç‚¹
AWS_METADATA_TOKEN_TTL=21600                                  # å…ƒæ•°æ®ä»¤ç‰ŒTTL (6å°æ—¶)
AWS_METADATA_API_VERSION="latest"                             # APIç‰ˆæœ¬

# ----- ç“¶é¢ˆæ£€æµ‹é…ç½® -----
# ç“¶é¢ˆæ£€æµ‹é˜ˆå€¼ (æé™æµ‹è¯•ç”¨)
BOTTLENECK_CPU_THRESHOLD=85         # CPUä½¿ç”¨ç‡è¶…è¿‡85%è§†ä¸ºç“¶é¢ˆ
BOTTLENECK_MEMORY_THRESHOLD=90      # å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%è§†ä¸ºç“¶é¢ˆ
BOTTLENECK_EBS_UTIL_THRESHOLD=90    # EBSåˆ©ç”¨ç‡è¶…è¿‡90%è§†ä¸ºç“¶é¢ˆ
BOTTLENECK_EBS_LATENCY_THRESHOLD=50 # EBSå»¶è¿Ÿè¶…è¿‡50msè§†ä¸ºç“¶é¢ˆ
BOTTLENECK_ERROR_RATE_THRESHOLD=5   # é”™è¯¯ç‡è¶…è¿‡5%è§†ä¸ºç“¶é¢ˆ

# ç“¶é¢ˆæ£€æµ‹è¿ç»­æ¬¡æ•° (é¿å…å¶å‘æ€§æ³¢åŠ¨)
BOTTLENECK_CONSECUTIVE_COUNT=3      # è¿ç»­3æ¬¡æ£€æµ‹åˆ°ç“¶é¢ˆæ‰åœæ­¢

# ç“¶é¢ˆåˆ†ææ—¶é—´çª—å£é…ç½®
BOTTLENECK_ANALYSIS_WINDOW=30       # ç“¶é¢ˆæ—¶é—´ç‚¹å‰ååˆ†æçª—å£ (ç§’)
BOTTLENECK_CORRELATION_WINDOW=60    # å…³è”åˆ†ææ—¶é—´çª—å£ (ç§’)
PERFORMANCE_CLIFF_WINDOW=45         # æ€§èƒ½æ‚¬å´–åˆ†æçª—å£ (ç§’)

# ----- RPCæ¨¡å¼é…ç½® -----
RPC_MODE="${RPC_MODE:-single}"      # RPCæ¨¡å¼: single/mixed (é»˜è®¤single)

# =====================================================================
# ç³»ç»Ÿè‡ªåŠ¨é…ç½®åŒºåŸŸ - ä»¥ä¸‹å˜é‡ç”±ç³»ç»Ÿè‡ªåŠ¨è®¾ç½®ï¼Œç”¨æˆ·é€šå¸¸æ— éœ€ä¿®æ”¹
# =====================================================================

# ----- è‡ªåŠ¨è®¡ç®—çš„ç½‘ç»œé…ç½® -----
# è‡ªåŠ¨è½¬æ¢ä¸ºMbps (ç”¨äºå†…éƒ¨è®¡ç®—ï¼Œç”¨æˆ·æ— éœ€ä¿®æ”¹)
NETWORK_MAX_BANDWIDTH_MBPS=$((NETWORK_MAX_BANDWIDTH_GBPS * 1000))
# ç½‘ç»œç“¶é¢ˆæ£€æµ‹é˜ˆå€¼ (è‡ªåŠ¨è®¾ç½®)
BOTTLENECK_NETWORK_THRESHOLD=$NETWORK_UTILIZATION_THRESHOLD

# =====================================================================
# ç³»ç»Ÿå‡½æ•°åŒºåŸŸ - è¯·å‹¿ä¿®æ”¹ä»¥ä¸‹å‡½æ•°å®šä¹‰
# =====================================================================

# ----- éƒ¨ç½²å¹³å°æ£€æµ‹å‡½æ•° -----
# è‡ªåŠ¨æ£€æµ‹éƒ¨ç½²å¹³å°å¹¶è°ƒæ•´ENAç›‘æ§é…ç½®
detect_deployment_platform() {
    if [[ "$DEPLOYMENT_PLATFORM" == "auto" ]]; then
        echo "ğŸ” è‡ªåŠ¨æ£€æµ‹éƒ¨ç½²å¹³å°..." >&2
        
        # æ£€æµ‹æ˜¯å¦åœ¨AWSç¯å¢ƒ (é€šè¿‡AWSå…ƒæ•°æ®æœåŠ¡)
        if curl -s --max-time 3 --connect-timeout 2 "${AWS_METADATA_ENDPOINT}/${AWS_METADATA_API_VERSION}/meta-data/instance-id" >/dev/null 2>&1; then
            DEPLOYMENT_PLATFORM="aws"
            ENA_MONITOR_ENABLED=true
            echo "âœ… æ£€æµ‹åˆ°AWSç¯å¢ƒï¼Œå¯ç”¨ENAç›‘æ§" >&2
        else
            DEPLOYMENT_PLATFORM="other"
            ENA_MONITOR_ENABLED=false
            echo "â„¹ï¸  æ£€æµ‹åˆ°éAWSç¯å¢ƒ (IDC/å…¶ä»–äº‘)ï¼Œç¦ç”¨ENAç›‘æ§" >&2
        fi
    else
        echo "ğŸ”§ ä½¿ç”¨æ‰‹åŠ¨é…ç½®çš„éƒ¨ç½²å¹³å°: $DEPLOYMENT_PLATFORM" >&2
        case "$DEPLOYMENT_PLATFORM" in
            "aws")
                ENA_MONITOR_ENABLED=true
                echo "âœ… AWSç¯å¢ƒï¼Œå¯ç”¨ENAç›‘æ§" >&2
                ;;
            "other"|"idc")
                ENA_MONITOR_ENABLED=false
                echo "â„¹ï¸  éAWSç¯å¢ƒï¼Œç¦ç”¨ENAç›‘æ§" >&2
                ;;
            *)
                echo "âš ï¸  æœªçŸ¥éƒ¨ç½²å¹³å°: $DEPLOYMENT_PLATFORMï¼Œç¦ç”¨ENAç›‘æ§" >&2
                ENA_MONITOR_ENABLED=false
                ;;
        esac
    fi
    
    # è¾“å‡ºæœ€ç»ˆé…ç½®
    echo "ğŸ“Š éƒ¨ç½²å¹³å°é…ç½®:" >&2
    echo "   å¹³å°ç±»å‹: $DEPLOYMENT_PLATFORM" >&2
    echo "   ENAç›‘æ§: $ENA_MONITOR_ENABLED" >&2
}

# ----- è·¯å¾„æ£€æµ‹å’Œé…ç½®å‡½æ•° -----
# æ£€æµ‹éƒ¨ç½²ç¯å¢ƒå¹¶è®¾ç½®è·¯å¾„
detect_deployment_paths() {
    # é˜²æ­¢é‡å¤æ‰§è¡Œ
    if [[ "${DEPLOYMENT_PATHS_DETECTED:-false}" == "true" ]]; then
        return 0
    fi
    
    local script_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    local framework_dir="$(dirname "$script_dir")"
    local deployment_dir="$(dirname "$framework_dir")"
    
    echo "ğŸ” æ£€æµ‹éƒ¨ç½²ç»“æ„..." >&2
    echo "   æ¡†æ¶ç›®å½•: $framework_dir" >&2
    echo "   éƒ¨ç½²ç›®å½•: $deployment_dir" >&2
    
    # è®¾ç½®å†…å­˜å…±äº«ç›®å½• (ç‹¬ç«‹äºæ•°æ®ç›®å½•ï¼Œä¿æŒç³»ç»Ÿçº§è·¯å¾„)
    if [[ "$(uname -s)" == "Darwin" ]]; then
        # macOS å¼€å‘ç¯å¢ƒ
        BASE_MEMORY_DIR="${TMPDIR:-/tmp}/blockchain-node-benchmark"
        DEPLOYMENT_ENV="development"
        echo "ğŸ”§ æ£€æµ‹åˆ°å¼€å‘ç¯å¢ƒ (macOS)" >&2
    else
        # Linux ç”Ÿäº§ç¯å¢ƒ - ä½¿ç”¨ç³»ç»Ÿ tmpfs
        BASE_MEMORY_DIR="/dev/shm/blockchain-node-benchmark"
        DEPLOYMENT_ENV="production"
        echo "ğŸ§ æ£€æµ‹åˆ°Linuxç”Ÿäº§ç¯å¢ƒ" >&2
    fi
    
    # æ ‡å‡†åŒ–è·¯å¾„é…ç½®
    BASE_FRAMEWORK_DIR="$framework_dir"
    BASE_DATA_DIR="${BLOCKCHAIN_BENCHMARK_DATA_DIR:-${deployment_dir}/blockchain-node-benchmark-result}"
    DEPLOYMENT_STRUCTURE="standard"
    
    echo "ğŸš€ ä½¿ç”¨æ ‡å‡†éƒ¨ç½²ç»“æ„" >&2
    echo "   æ•°æ®ç›®å½•: $BASE_DATA_DIR" >&2
    
    # æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
    if [[ -n "${BLOCKCHAIN_BENCHMARK_DATA_DIR:-}" ]]; then
        echo "   (ä½¿ç”¨ç¯å¢ƒå˜é‡: BLOCKCHAIN_BENCHMARK_DATA_DIR)" >&2
    fi
    
    # éªŒè¯éƒ¨ç½²ç»“æ„
    validate_deployment_structure "$framework_dir" "$BASE_DATA_DIR"
    
    # è®¾ç½®ç›®å½•ç»“æ„ - åŸºäºæ–°çš„æ ‡å‡†åŒ–è·¯å¾„
    # ä¸»æ•°æ®ç›®å½• (QPSæµ‹è¯•ä¸“å±)
    DATA_DIR="${BASE_DATA_DIR}"
    # å½“å‰æµ‹è¯•æ•°æ®ç›®å½•
    CURRENT_TEST_DIR="${DATA_DIR}/current"
    # æ—¥å¿—ç›®å½• (æ€§èƒ½ç›‘æ§æ•°æ®)
    LOGS_DIR="${CURRENT_TEST_DIR}/logs"
    # æŠ¥å‘Šç›®å½• (åˆ†ææŠ¥å‘Šå’Œå›¾è¡¨)
    REPORTS_DIR="${CURRENT_TEST_DIR}/reports"
    # Vegeta ç»“æœç›®å½• (å‹æµ‹åŸå§‹æ•°æ®)
    VEGETA_RESULTS_DIR="${CURRENT_TEST_DIR}/vegeta_results"
    # ä¸´æ—¶æ–‡ä»¶ç›®å½• (è¿è¡Œæ—¶ä¸´æ—¶æ•°æ®)
    TMP_DIR="${CURRENT_TEST_DIR}/tmp"
    # å½’æ¡£ç›®å½• (å†å²æµ‹è¯•æ•°æ®)
    ARCHIVES_DIR="${DATA_DIR}/archives"
    # é”™è¯¯å¤„ç†å’Œæ—¥å¿—ç›®å½•
    ERROR_LOG_DIR="${CURRENT_TEST_DIR}/${ERROR_LOG_SUBDIR}"
    PYTHON_ERROR_LOG_DIR="${CURRENT_TEST_DIR}/${PYTHON_ERROR_LOG_SUBDIR}"
    
    # å†…å­˜å…±äº«ç›®å½• (ç‹¬ç«‹äºæ•°æ®ç›®å½•ï¼Œä½¿ç”¨ç³»ç»Ÿçº§è·¯å¾„)
    MEMORY_SHARE_DIR="${BASE_MEMORY_DIR}"
    
    # è®¾ç½®åŠ¨æ€è·¯å¾„å˜é‡
    SLOT_CACHE_FILE="${MEMORY_SHARE_DIR}/slot_monitor_cache.json"
    ACCOUNTS_OUTPUT_FILE="${TMP_DIR}/${ACCOUNT_OUTPUT_FILE}"
    SINGLE_METHOD_TARGETS_FILE="${TMP_DIR}/targets_single.json"
    MIXED_METHOD_TARGETS_FILE="${TMP_DIR}/targets_mixed.json"
    QPS_STATUS_FILE="${MEMORY_SHARE_DIR}/qps_status.json"
    TEST_SESSION_DIR="${TMP_DIR}/session_$(date +%Y%m%d_%H%M%S)"
    
    # ä¸´æ—¶æ–‡ä»¶æ¨¡å¼ (ç”¨äºæ¸…ç†)
    TEMP_FILE_PATTERN="${TMP_DIR}/${TEMP_FILE_PREFIX}-*"
    
    # è¾“å‡ºæœ€ç»ˆé…ç½®
    echo "ğŸ“‹ è·¯å¾„é…ç½®å®Œæˆ:" >&2
    echo "   éƒ¨ç½²ç»“æ„: $DEPLOYMENT_STRUCTURE" >&2
    echo "   æ¡†æ¶ç›®å½•: $BASE_FRAMEWORK_DIR" >&2
    echo "   æ•°æ®ç›®å½•: $BASE_DATA_DIR" >&2
    echo "   å†…å­˜å…±äº«: $MEMORY_SHARE_DIR" >&2
    
    # æ ‡è®°è·¯å¾„æ£€æµ‹å·²å®Œæˆ
    DEPLOYMENT_PATHS_DETECTED=true
}

# ----- éƒ¨ç½²ç»“æ„éªŒè¯å‡½æ•° -----
validate_deployment_structure() {
    local framework_dir="$1"
    local data_dir="$2"
    
    echo "ğŸ” éªŒè¯éƒ¨ç½²ç»“æ„..." >&2
    
    # éªŒè¯æ¡†æ¶ç›®å½•ç»“æ„
    local required_dirs=("analysis" "config" "core" "monitoring" "tools" "utils" "visualization")
    local missing_dirs=()
    
    for dir in "${required_dirs[@]}"; do
        if [[ ! -d "${framework_dir}/${dir}" ]]; then
            missing_dirs+=("$dir")
        fi
    done
    
    if [[ ${#missing_dirs[@]} -gt 0 ]]; then
        echo "âŒ æ¡†æ¶ç›®å½•ç»“æ„ä¸å®Œæ•´ï¼Œç¼ºå°‘ç›®å½•: ${missing_dirs[*]}" >&2
        echo "   æ¡†æ¶è·¯å¾„: $framework_dir" >&2
        return 1
    fi
    
    # éªŒè¯æ•°æ®ç›®å½•çˆ¶è·¯å¾„æƒé™
    local data_parent_dir="$(dirname "$data_dir")"
    if [[ ! -d "$data_parent_dir" ]]; then
        echo "âš ï¸  æ•°æ®ç›®å½•çˆ¶è·¯å¾„ä¸å­˜åœ¨: $data_parent_dir" >&2
        echo "   å°†å°è¯•åˆ›å»º..." >&2
    elif [[ ! -w "$data_parent_dir" ]]; then
        echo "âŒ æ•°æ®ç›®å½•çˆ¶è·¯å¾„ä¸å¯å†™: $data_parent_dir" >&2
        echo "   è¯·æ£€æŸ¥æƒé™è®¾ç½®" >&2
        return 1
    fi
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´ (å¦‚æœdfå‘½ä»¤å¯ç”¨)
    if command -v df >/dev/null 2>&1; then
        local available_space=$(df "$data_parent_dir" 2>/dev/null | awk 'NR==2 {print $4}' || echo "0")
        if [[ "$available_space" -lt 1048576 ]]; then  # 1GB = 1048576 KB
            echo "âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³ (å¯ç”¨: ${available_space}KB): $data_parent_dir" >&2
            echo "   å»ºè®®è‡³å°‘ä¿ç•™1GBç©ºé—´ç”¨äºæµ‹è¯•æ•°æ®" >&2
        fi
    fi
    
    echo "âœ… éƒ¨ç½²ç»“æ„éªŒè¯é€šè¿‡" >&2
    return 0
}

# ----- ç›®å½•åˆ›å»ºå‡½æ•° -----
# å®‰å…¨åˆ›å»ºç›®å½•å‡½æ•° - å¢å¼ºç‰ˆ
create_directories_safely() {
    local dirs=("$@")
    local created_dirs=()
    local failed_dirs=()
    
    echo "ğŸ”§ æ­£åœ¨åˆ›å»ºå¿…è¦çš„ç›®å½•..." >&2
    
    for dir in "${dirs[@]}"; do
        if [[ ! -d "$dir" ]]; then
            # æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”å¯å†™
            local parent_dir=$(dirname "$dir")
            if [[ ! -d "$parent_dir" ]]; then
                echo "âš ï¸  çˆ¶ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»º: $parent_dir" >&2
                if ! mkdir -p "$parent_dir" 2>/dev/null; then
                    echo "âŒ æ— æ³•åˆ›å»ºçˆ¶ç›®å½•: $parent_dir" >&2
                    failed_dirs+=("$dir")
                    continue
                fi
            fi
            
            # æ£€æŸ¥ç£ç›˜ç©ºé—´ (å¦‚æœdfå‘½ä»¤å¯ç”¨)
            local available_space
            if command -v df >/dev/null 2>&1; then
                available_space=$(df "$parent_dir" 2>/dev/null | awk 'NR==2 {print $4}' || echo "0")
                if [[ "$available_space" -lt 1048576 ]]; then  # 1GB = 1048576 KB
                    echo "âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³ (å¯ç”¨: ${available_space}KB): $parent_dir" >&2
                fi
            fi
            
            if mkdir -p "$dir" 2>/dev/null; then
                echo "âœ… åˆ›å»ºç›®å½•: $dir" >&2
                created_dirs+=("$dir")
                
                # è®¾ç½®åˆé€‚çš„æƒé™
                chmod 755 "$dir" 2>/dev/null || true
            else
                echo "âŒ æ— æ³•åˆ›å»ºç›®å½•: $dir" >&2
                failed_dirs+=("$dir")
                
                # ä½¿ç”¨ä¸´æ—¶ç›®å½•ä½œä¸ºåå¤‡
                local temp_dir="${TMPDIR:-/tmp}/solana-qps-test/$(basename "$dir")"
                echo "ğŸ”„ ä½¿ç”¨ä¸´æ—¶ç›®å½•æ›¿ä»£: $temp_dir" >&2
                if mkdir -p "$temp_dir" 2>/dev/null; then
                    # æ›´æ–°å˜é‡æŒ‡å‘ä¸´æ—¶ç›®å½•
                    case "$dir" in
                        *logs*) LOGS_DIR="$temp_dir" ;;
                        *reports*) REPORTS_DIR="$temp_dir" ;;
                        *vegeta*) VEGETA_RESULTS_DIR="$temp_dir" ;;
                        *tmp*) TMP_DIR="$temp_dir" ;;
                        *shm*) MEMORY_SHARE_DIR="$temp_dir" ;;
                    esac
                    created_dirs+=("$temp_dir")
                fi
            fi
        else
            echo "âœ… ç›®å½•å·²å­˜åœ¨: $dir" >&2
        fi
    done
    
    # è¿”å›ç»“æœæ‘˜è¦
    if [[ ${#failed_dirs[@]} -gt 0 ]]; then
        echo "âš ï¸  éƒ¨åˆ†ç›®å½•åˆ›å»ºå¤±è´¥: ${failed_dirs[*]}" >&2
        return 1
    else
        echo "âœ… æ‰€æœ‰ç›®å½•åˆ›å»ºæˆåŠŸ" >&2
        return 0
    fi
}

# ----- ç½‘ç»œæ¥å£æ£€æµ‹å‡½æ•° -----
# è‡ªåŠ¨æ£€æµ‹ENAç½‘ç»œæ¥å£
detect_network_interface() {
    # ä¼˜å…ˆæ£€æµ‹ENAæ¥å£
    local ena_interfaces
    if command -v ip >/dev/null 2>&1; then
        ena_interfaces=($(ip link show 2>/dev/null | grep -E "^[0-9]+: (eth|ens|enp)" | grep "state UP" | cut -d: -f2 | tr -d ' '))
    else
        ena_interfaces=()
    fi
    
    # å¦‚æœæ‰¾åˆ°ENAæ¥å£ï¼Œä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€ä¸ª
    if [[ ${#ena_interfaces[@]} -gt 0 ]]; then
        echo "${ena_interfaces[0]}"
        return 0
    fi
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ENAæ¥å£ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•æ£€æµ‹
    local interface=""
    if command -v ip >/dev/null 2>&1; then
        interface=$(ip route 2>/dev/null | grep default | awk '{print $5}' | head -1)
    elif command -v route >/dev/null 2>&1; then
        interface=$(route get default 2>/dev/null | grep interface | awk '{print $2}')
    elif command -v netstat >/dev/null 2>&1; then
        interface=$(netstat -rn 2>/dev/null | grep default | awk '{print $6}' | head -1)
    fi
    
    # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤
    if [[ -z "$interface" ]]; then
        case "$(uname -s)" in
            "Darwin") interface="en0" ;;  # macOSé»˜è®¤
            "Linux") interface="eth0" ;;   # Linuxé»˜è®¤
            *) interface="eth0" ;;         # å…¶ä»–ç³»ç»Ÿé»˜è®¤
        esac
    fi
    
    echo "$interface"
}

# ----- EBSæ€§èƒ½åŸºå‡†è®¡ç®—å‡½æ•° -----
calculate_ebs_performance_baselines() {
    # æ ¹æ®å·ç±»å‹å’Œé…ç½®è®¡ç®—åŸºå‡†æ€§èƒ½ - åŸºäºAWSå®˜æ–¹æ–‡æ¡£ä¿®æ­£
    case "$DATA_VOL_TYPE" in
        "gp3")
            DATA_BASELINE_IOPS=${DATA_VOL_MAX_IOPS:-3000}
            # GP3æœ€å¤§ååé‡æ˜¯1000 MiB/sï¼ŒåŸºå‡†æ˜¯125 MiB/s
            DATA_BASELINE_THROUGHPUT=${DATA_VOL_MAX_THROUGHPUT:-1000}
            ;;
        "io2")
            DATA_BASELINE_IOPS=${DATA_VOL_MAX_IOPS:-1000}
            # IO2ååé‡ = IOPS Ã— 0.256ï¼Œæœ€å¤§4000 MiB/s
            local calculated_throughput=$(( (${DATA_VOL_MAX_IOPS:-1000} * 256) / 1000 ))
            if [[ $calculated_throughput -gt 4000 ]]; then
                DATA_BASELINE_THROUGHPUT=4000  # ä¸è¶…è¿‡æœ€å¤§å€¼
            else
                DATA_BASELINE_THROUGHPUT=$calculated_throughput
            fi
            ;;
        "instance-store")
            # Instance Storeæ€§èƒ½å¿…é¡»ç”±ç”¨æˆ·é…ç½®ï¼Œä¸ä½¿ç”¨ä¼°ç®—å€¼
            if [[ -z "$DATA_VOL_MAX_IOPS" ]]; then
                echo "âŒ é”™è¯¯: DATA_VOL_MAX_IOPS æœªé…ç½®"
                echo "   Instance Storeæ€§èƒ½å› å®ä¾‹ç±»å‹è€Œå¼‚ï¼Œè¯·æ ¹æ®æ‚¨çš„å®ä¾‹ç±»å‹é…ç½®:"
                echo "   export DATA_VOL_MAX_IOPS=<æ‚¨çš„å®ä¾‹IOPS>"
                echo "   å‚è€ƒ: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-store-policy.html"
                exit 1
            fi
            
            if [[ -z "$DATA_VOL_MAX_THROUGHPUT" ]]; then
                echo "âŒ é”™è¯¯: DATA_VOL_MAX_THROUGHPUT æœªé…ç½®"
                echo "   Instance Storeååé‡å¿…é¡»é…ç½®ï¼Œè¯·æ ¹æ®æ‚¨çš„å®ä¾‹ç±»å‹é…ç½®:"
                echo "   export DATA_VOL_MAX_THROUGHPUT=<æ‚¨çš„å®ä¾‹ååé‡MiB/s>"
                echo "   å‚è€ƒ: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-store-policy.html"
                exit 1
            fi
            
            DATA_BASELINE_IOPS=$DATA_VOL_MAX_IOPS
            DATA_BASELINE_THROUGHPUT=$DATA_VOL_MAX_THROUGHPUT
            ;;
        *)
            echo "âŒ é”™è¯¯: ä¸æ”¯æŒçš„DATAå·ç±»å‹: $DATA_VOL_TYPE"
            echo "   æ”¯æŒçš„ç±»å‹: gp3, io2, instance-store"
            exit 1
            ;;
    esac
    
    # ACCOUNTSè®¾å¤‡é…ç½® - åº”ç”¨ç›¸åŒçš„é€»è¾‘
    if [[ -n "$ACCOUNTS_VOL_TYPE" ]]; then
        case "$ACCOUNTS_VOL_TYPE" in
            "gp3")
                ACCOUNTS_BASELINE_IOPS=${ACCOUNTS_VOL_MAX_IOPS:-3000}
                ACCOUNTS_BASELINE_THROUGHPUT=${ACCOUNTS_VOL_MAX_THROUGHPUT:-1000}
                ;;
            "io2")
                ACCOUNTS_BASELINE_IOPS=${ACCOUNTS_VOL_MAX_IOPS:-1000}
                # IO2ååé‡åŠ¨æ€è®¡ç®—
                local accounts_calculated_throughput=$(( (${ACCOUNTS_VOL_MAX_IOPS:-1000} * 256) / 1000 ))
                if [[ $accounts_calculated_throughput -gt 4000 ]]; then
                    ACCOUNTS_BASELINE_THROUGHPUT=4000
                else
                    ACCOUNTS_BASELINE_THROUGHPUT=$accounts_calculated_throughput
                fi
                ;;
            "instance-store")
                # ACCOUNTS Instance Storeä¹Ÿå¿…é¡»ç”±ç”¨æˆ·é…ç½®
                if [[ -z "$ACCOUNTS_VOL_MAX_IOPS" ]]; then
                    echo "âŒ é”™è¯¯: ACCOUNTS_VOL_MAX_IOPS æœªé…ç½®"
                    echo "   ACCOUNTS Instance Storeæ€§èƒ½å¿…é¡»é…ç½®:"
                    echo "   export ACCOUNTS_VOL_MAX_IOPS=<æ‚¨çš„å®ä¾‹IOPS>"
                    exit 1
                fi
                
                if [[ -z "$ACCOUNTS_VOL_MAX_THROUGHPUT" ]]; then
                    echo "âŒ é”™è¯¯: ACCOUNTS_VOL_MAX_THROUGHPUT æœªé…ç½®"
                    echo "   ACCOUNTS Instance Storeååé‡å¿…é¡»é…ç½®:"
                    echo "   export ACCOUNTS_VOL_MAX_THROUGHPUT=<æ‚¨çš„å®ä¾‹ååé‡MiB/s>"
                    exit 1
                fi
                
                ACCOUNTS_BASELINE_IOPS=$ACCOUNTS_VOL_MAX_IOPS
                ACCOUNTS_BASELINE_THROUGHPUT=$ACCOUNTS_VOL_MAX_THROUGHPUT
                ;;
            *)
                echo "âŒ é”™è¯¯: ä¸æ”¯æŒçš„ACCOUNTSå·ç±»å‹: $ACCOUNTS_VOL_TYPE"
                echo "   æ”¯æŒçš„ç±»å‹: gp3, io2, instance-store"
                exit 1
                ;;
        esac
    fi
    
    # è¾“å‡ºè®¡ç®—ç»“æœç”¨äºè°ƒè¯•
    if [[ "${DEBUG:-false}" == "true" ]]; then
        echo "ğŸ”§ EBSæ€§èƒ½åŸºå‡†è®¡ç®—ç»“æœ:"
        echo "  DATAè®¾å¤‡ ($DATA_VOL_TYPE): ${DATA_BASELINE_IOPS} IOPS, ${DATA_BASELINE_THROUGHPUT} MiB/s"
        if [[ -n "$ACCOUNTS_VOL_TYPE" ]]; then
            echo "  ACCOUNTSè®¾å¤‡ ($ACCOUNTS_VOL_TYPE): ${ACCOUNTS_BASELINE_IOPS} IOPS, ${ACCOUNTS_BASELINE_THROUGHPUT} MiB/s"
        fi
    fi
}

# ----- æ—¶é—´ç®¡ç†å‡½æ•° -----
get_unified_timestamp() {
    date +"$TIMESTAMP_FORMAT"
}

# æ—¶é—´èŒƒå›´ç®¡ç†
record_time_range() {
    local event_type="$1"
    local start_time="$2"
    local end_time="$3"
    
    local time_range_file="${MEMORY_SHARE_DIR}/time_ranges.json"
    
    # åˆ›å»ºæˆ–æ›´æ–°æ—¶é—´èŒƒå›´è®°å½•
    local time_record="{\"event_type\":\"$event_type\",\"start_time\":\"$start_time\",\"end_time\":\"$end_time\",\"start_epoch\":$(date -d "$start_time" +%s 2>/dev/null || echo 0),\"end_epoch\":$(date -d "$end_time" +%s 2>/dev/null || echo 0)}"
    
    if [[ -f "$time_range_file" ]]; then
        # æ·»åŠ åˆ°ç°æœ‰è®°å½•
        jq ". += [$time_record]" "$time_range_file" > "${time_range_file}.tmp" && mv "${time_range_file}.tmp" "$time_range_file"
    else
        # åˆ›å»ºæ–°è®°å½•
        echo "[$time_record]" > "$time_range_file"
    fi
}

get_time_ranges() {
    local time_range_file="${MEMORY_SHARE_DIR}/time_ranges.json"
    if [[ -f "$time_range_file" ]]; then
        cat "$time_range_file"
    else
        echo "[]"
    fi
}

# ----- EBSè®¾å¤‡é…ç½®éªŒè¯å‡½æ•° -----
# éªŒè¯å•ä¸ªEBSè®¾å¤‡é…ç½®
validate_ebs_device_config() {
    local device_type="$1"  # DATA æˆ– ACCOUNTS
    local errors=()
    
    # è·å–é…ç½®å˜é‡
    local vol_type_var="${device_type}_VOL_TYPE"
    local vol_iops_var="${device_type}_VOL_MAX_IOPS"
    local vol_throughput_var="${device_type}_VOL_MAX_THROUGHPUT"
    
    local vol_type="${!vol_type_var}"
    local vol_iops="${!vol_iops_var}"
    local vol_throughput="${!vol_throughput_var}"
    
    if [[ -n "$vol_type" ]]; then
        case "$vol_type" in
            "gp3")
                [[ -z "$vol_iops" ]] && errors+=("${vol_iops_var} is required for gp3 volumes")
                [[ -z "$vol_throughput" ]] && errors+=("${vol_throughput_var} is required for gp3 volumes")
                ;;
            "io2")
                [[ -z "$vol_iops" ]] && errors+=("${vol_iops_var} is required for ${vol_type} volumes")
                # throughputå¯¹io2ä¸é€‚ç”¨ï¼Œå¿½ç•¥è¯¥å‚æ•°
                ;;
            "instance-store")
                [[ -z "$vol_iops" ]] && errors+=("${vol_iops_var} is required for instance-store volumes")
                [[ -z "$vol_throughput" ]] && errors+=("${vol_throughput_var} is required for instance-store volumes")
                ;;
            *)
                errors+=("Unsupported ${vol_type_var}: $vol_type")
                ;;
        esac
    fi
    
    printf '%s\n' "${errors[@]}"
}

# æ£€æŸ¥è®¾å¤‡æ˜¯å¦é…ç½®
is_device_configured() {
    local device_type="$1"
    case "$device_type" in
        "DATA")
            [[ -n "$DATA_VOL_TYPE" ]]
            ;;
        "ACCOUNTS")
            [[ -n "$ACCOUNTS_VOL_TYPE" ]]
            ;;
        *)
            return 1
            ;;
    esac
}

# è·å–é€»è¾‘åæ˜ å°„
get_logical_name() {
    local device_type="$1"
    case "$device_type" in
        "DATA") echo "ledger" ;;
        "ACCOUNTS") echo "accounts" ;;
        *) echo "unknown" ;;
    esac
}

# ----- é…ç½®éªŒè¯å‡½æ•° -----
validate_config() {
    local errors=()
    
    # æ£€æŸ¥å¿…è¦ç›®å½•
    if [[ ! -d "$DATA_DIR" ]]; then
        errors+=("DATA_DIR does not exist: $DATA_DIR")
    fi
    
    # éªŒè¯DATAè®¾å¤‡ï¼ˆå¿…é¡»é…ç½®ï¼‰
    if [[ -z "$LEDGER_DEVICE" ]]; then
        errors+=("LEDGER_DEVICE is not configured")
    elif [[ ! -b "/dev/$LEDGER_DEVICE" ]]; then
        errors+=("LEDGER_DEVICE does not exist: /dev/$LEDGER_DEVICE")
    fi
    
    # éªŒè¯DATAå·é…ç½®
    if is_device_configured "DATA"; then
        local data_errors
        data_errors=($(validate_ebs_device_config "DATA"))
        if [[ ${#data_errors[@]} -gt 0 ]]; then
            errors+=("${data_errors[@]}")
        fi
    fi
    
    # éªŒè¯ACCOUNTSè®¾å¤‡ï¼ˆå¯é€‰ï¼‰
    if [[ -n "$ACCOUNTS_DEVICE" ]]; then
        if [[ ! -b "/dev/$ACCOUNTS_DEVICE" ]]; then
            errors+=("ACCOUNTS_DEVICE does not exist: /dev/$ACCOUNTS_DEVICE")
        fi
        
        # éªŒè¯ACCOUNTSå·é…ç½®
        if is_device_configured "ACCOUNTS"; then
            local accounts_errors
            accounts_errors=($(validate_ebs_device_config "ACCOUNTS"))
            if [[ ${#accounts_errors[@]} -gt 0 ]]; then
                errors+=("${accounts_errors[@]}")
            fi
        fi
    fi
    
    # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
    if [[ -n "$VALIDATOR_LOG_PATH" && ! -f "$VALIDATOR_LOG_PATH" ]]; then
        errors+=("VALIDATOR_LOG_PATH does not exist: $VALIDATOR_LOG_PATH")
    fi
    
    # æ£€æŸ¥ç½‘ç»œæ¥å£
    if [[ -z "$NETWORK_INTERFACE" ]]; then
        errors+=("Cannot detect network interface")
    fi
    
    # è¾“å‡ºé”™è¯¯
    if [[ ${#errors[@]} -gt 0 ]]; then
        echo "âŒ Configuration validation failed:"
        printf '  - %s\n' "${errors[@]}"
        return 1
    else
        echo "âœ… Configuration validation passed"
        return 0
    fi
}

# ----- é…ç½®ä¿¡æ¯æ˜¾ç¤ºå‡½æ•° -----
show_config() {
    echo "ğŸ“‹ Blockchain Node Benchmark Framework Configuration"
    echo "=================================================="
    echo "Deployment Structure: ${DEPLOYMENT_STRUCTURE:-"unknown"}"
    echo "Framework Directory: ${BASE_FRAMEWORK_DIR:-"N/A"}"
    echo "Data Directory: $DATA_DIR"
    echo "Logs Directory: $LOGS_DIR"
    echo "Reports Directory: $REPORTS_DIR"
    echo "Memory Share Directory: $MEMORY_SHARE_DIR"
    echo "Network Interface: $NETWORK_INTERFACE"
    echo "Network Bandwidth: ${NETWORK_MAX_BANDWIDTH_GBPS} Gbps"
    echo "DATA Device: $LEDGER_DEVICE ($DATA_VOL_TYPE)"
    echo "ACCOUNTS Device: ${ACCOUNTS_DEVICE:-"Not configured"} (${ACCOUNTS_VOL_TYPE:-"N/A"})"
    echo "Validator Log: $VALIDATOR_LOG_PATH"
    echo "Deployment Environment: $DEPLOYMENT_ENV"
    echo "=================================================="
}

# =====================================================================
# ç³»ç»Ÿåˆå§‹åŒ–åŒºåŸŸ - è‡ªåŠ¨æ‰§è¡Œçš„åˆå§‹åŒ–ä»£ç 
# =====================================================================

# é˜²æ­¢é‡å¤åˆå§‹åŒ–
if [[ "${CONFIG_INITIALIZED:-false}" != "true" ]]; then
    # æ‰§è¡Œè·¯å¾„æ£€æµ‹å’Œé…ç½®
    detect_deployment_paths

    # æ‰§è¡Œéƒ¨ç½²å¹³å°æ£€æµ‹ (å¿…é¡»åœ¨è·¯å¾„æ£€æµ‹ä¹‹å)
    detect_deployment_platform

    # è®¾ç½®ç½‘ç»œæ¥å£
    NETWORK_INTERFACE=$(detect_network_interface)

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    create_directories_safely "${LOGS_DIR}" "${REPORTS_DIR}" "${VEGETA_RESULTS_DIR}" "${TMP_DIR}" "${ARCHIVES_DIR}" "${MEMORY_SHARE_DIR}" "${ERROR_LOG_DIR}" "${PYTHON_ERROR_LOG_DIR}"

    # æ‰§è¡ŒEBSæ€§èƒ½åŸºå‡†è®¡ç®—
    calculate_ebs_performance_baselines

    # æ ‡è®°é…ç½®å·²åˆå§‹åŒ–
    CONFIG_INITIALIZED=true
fi

# è‡ªåŠ¨éªŒè¯é…ç½® (å¦‚æœç›´æ¥æ‰§è¡Œæ­¤è„šæœ¬)
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    show_config
    validate_config
fi
