#!/usr/bin/env python3
"""
å¼‚å¸¸æ£€æµ‹å·¥å…· - IQRæ–¹æ³•å®ç°
æä¾›æ¯”2Ïƒè§„åˆ™æ›´é²æ£’çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from utils.unified_logger import get_logger

logger = get_logger(__name__)

class AnomalyDetector:
    """
    å¼‚å¸¸æ£€æµ‹å™¨ - åŸºäºIQRæ–¹æ³•
    ç›¸æ¯”2Ïƒè§„åˆ™ï¼ŒIQRæ–¹æ³•å¯¹æå€¼æ›´é²æ£’ï¼Œæ›´é€‚åˆéæ­£æ€åˆ†å¸ƒæ•°æ®
    """
    
    def __init__(self, iqr_multiplier: float = 1.5):
        """
        åˆå§‹åŒ–å¼‚å¸¸æ£€æµ‹å™¨
        
        Args:
            iqr_multiplier: IQRå€æ•°ï¼Œé»˜è®¤1.5 (æ ‡å‡†å€¼)
                          - 1.5: æ ‡å‡†å¼‚å¸¸æ£€æµ‹ (çº¦99.3%æ•°æ®åœ¨èŒƒå›´å†…)
                          - 3.0: æç«¯å¼‚å¸¸æ£€æµ‹ (çº¦99.9%æ•°æ®åœ¨èŒƒå›´å†…)
        """
        self.iqr_multiplier = iqr_multiplier
        
    def detect_outliers_iqr(self, data: Union[pd.Series, np.ndarray], 
                           return_bounds: bool = False) -> Union[pd.Series, Tuple[pd.Series, Dict]]:
        """
        ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
        
        Args:
            data: è¾“å…¥æ•°æ® (pandas Series æˆ– numpy array)
            return_bounds: æ˜¯å¦è¿”å›å¼‚å¸¸æ£€æµ‹è¾¹ç•Œä¿¡æ¯
            
        Returns:
            å¦‚æœreturn_bounds=False: å¸ƒå°”Seriesï¼ŒTrueè¡¨ç¤ºå¼‚å¸¸å€¼
            å¦‚æœreturn_bounds=True: (å¼‚å¸¸å€¼å¸ƒå°”Series, è¾¹ç•Œä¿¡æ¯å­—å…¸)
        """
        if isinstance(data, np.ndarray):
            data = pd.Series(data)
        
        # ç¡®ä¿ data æ˜¯ pd.Series ç±»å‹ï¼ˆç”¨äºIDEç±»å‹æ¨æ–­ï¼‰
        data: pd.Series = data
        
        # âœ… æ·»åŠ æ—¥å¿—è®°å½•
        logger.info(f"ğŸ” å¼€å§‹IQRå¼‚å¸¸æ£€æµ‹ï¼Œæ•°æ®ç‚¹æ•°: {len(data)}")
        logger.debug(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: min={data.min():.2f}, max={data.max():.2f}, mean={data.mean():.2f}")
            
        # è®¡ç®—å››åˆ†ä½æ•°
        Q1 = data.quantile(0.25)
        Q3 = data.quantile(0.75)
        IQR = Q3 - Q1
        
        # è®¡ç®—å¼‚å¸¸æ£€æµ‹è¾¹ç•Œ
        lower_bound = Q1 - self.iqr_multiplier * IQR
        upper_bound = Q3 + self.iqr_multiplier * IQR
        
        # âœ… æ·»åŠ è¾¹ç•Œä¿¡æ¯æ—¥å¿—
        logger.debug(f"ğŸ“ IQRè¾¹ç•Œ: Q1={Q1:.2f}, Q3={Q3:.2f}, IQR={IQR:.2f}")
        logger.debug(f"ğŸ¯ å¼‚å¸¸æ£€æµ‹è¾¹ç•Œ: [{lower_bound:.2f}, {upper_bound:.2f}]")
        
        # æ£€æµ‹å¼‚å¸¸å€¼
        outliers_mask = (data < lower_bound) | (data > upper_bound)
        outliers: pd.Series = pd.Series(outliers_mask, dtype=bool)
        
        # âœ… æ·»åŠ æ£€æµ‹ç»“æœæ—¥å¿—
        outlier_count = outliers.sum()
        outlier_percentage = (outlier_count / len(data)) * 100
        logger.info(f"âœ… IQRå¼‚å¸¸æ£€æµ‹å®Œæˆ: å‘ç° {outlier_count} ä¸ªå¼‚å¸¸ç‚¹ ({outlier_percentage:.1f}%)")
        
        if return_bounds:
            bounds_info = {
                'Q1': Q1,
                'Q3': Q3,
                'IQR': IQR,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound,
                'outlier_count': outliers.sum(),
                'outlier_percentage': (outliers.sum() / len(data)) * 100,
                'method': 'IQR',
                'multiplier': self.iqr_multiplier
            }
            return outliers, bounds_info
        
        return outliers
    
    def detect_outliers_sigma(self, data: Union[pd.Series, np.ndarray], 
                             sigma_multiplier: float = 2.0,
                             return_bounds: bool = False) -> Union[pd.Series, Tuple[pd.Series, Dict]]:
        """
        ä½¿ç”¨Ïƒè§„åˆ™æ£€æµ‹å¼‚å¸¸å€¼ (ä½œä¸ºå¯¹æ¯”)
        
        Args:
            data: è¾“å…¥æ•°æ®
            sigma_multiplier: Ïƒå€æ•°ï¼Œé»˜è®¤2.0
            return_bounds: æ˜¯å¦è¿”å›è¾¹ç•Œä¿¡æ¯
            
        Returns:
            å¼‚å¸¸å€¼æ£€æµ‹ç»“æœ
        """
        if isinstance(data, np.ndarray):
            data = pd.Series(data)
        
        # ç¡®ä¿ data æ˜¯ pd.Series ç±»å‹ï¼ˆç”¨äºIDEç±»å‹æ¨æ–­ï¼‰
        data: pd.Series = data
        
        # âœ… æ·»åŠ æ—¥å¿—è®°å½•
        logger.info(f"ğŸ” å¼€å§‹Ïƒè§„åˆ™å¼‚å¸¸æ£€æµ‹ï¼Œæ•°æ®ç‚¹æ•°: {len(data)}, Ïƒå€æ•°: {sigma_multiplier}")
            
        mean = data.mean()
        std = data.std()
        
        lower_bound = mean - sigma_multiplier * std
        upper_bound = mean + sigma_multiplier * std
        
        # âœ… æ·»åŠ è¾¹ç•Œä¿¡æ¯æ—¥å¿—
        logger.debug(f"ğŸ“Š Ïƒè§„åˆ™ç»Ÿè®¡: mean={mean:.2f}, std={std:.2f}")
        logger.debug(f"ğŸ¯ å¼‚å¸¸æ£€æµ‹è¾¹ç•Œ: [{lower_bound:.2f}, {upper_bound:.2f}]")
        
        outliers_mask = (data < lower_bound) | (data > upper_bound)
        outliers: pd.Series = pd.Series(outliers_mask, dtype=bool)
        
        # âœ… æ·»åŠ æ£€æµ‹ç»“æœæ—¥å¿—
        outlier_count = outliers.sum()
        outlier_percentage = (outlier_count / len(data)) * 100
        logger.info(f"âœ… Ïƒè§„åˆ™å¼‚å¸¸æ£€æµ‹å®Œæˆ: å‘ç° {outlier_count} ä¸ªå¼‚å¸¸ç‚¹ ({outlier_percentage:.1f}%)")
        
        if return_bounds:
            bounds_info = {
                'mean': mean,
                'std': std,
                'lower_bound': lower_bound,
                'upper_bound': upper_bound,
                'outlier_count': outliers.sum(),
                'outlier_percentage': (outliers.sum() / len(data)) * 100,
                'method': f'{sigma_multiplier}Ïƒ',
                'multiplier': sigma_multiplier
            }
            return outliers, bounds_info
        
        return outliers
    
    def compare_methods(self, data: Union[pd.Series, np.ndarray]) -> Dict:
        """
        æ¯”è¾ƒIQRå’Œ2Ïƒæ–¹æ³•çš„å¼‚å¸¸æ£€æµ‹ç»“æœ
        
        Args:
            data: è¾“å…¥æ•°æ®
            
        Returns:
            æ¯”è¾ƒç»“æœå­—å…¸
        """
        if isinstance(data, np.ndarray):
            data = pd.Series(data)
            
        # IQRæ–¹æ³•
        iqr_outliers, iqr_bounds = self.detect_outliers_iqr(data, return_bounds=True)
        
        # 2Ïƒæ–¹æ³•
        sigma_outliers, sigma_bounds = self.detect_outliers_sigma(data, return_bounds=True)
        
        # è®¡ç®—é‡å åº¦
        both_methods = iqr_outliers & sigma_outliers
        only_iqr = iqr_outliers & ~sigma_outliers
        only_sigma = sigma_outliers & ~iqr_outliers
        
        comparison = {
            'data_points': len(data),
            'iqr_method': iqr_bounds,
            'sigma_method': sigma_bounds,
            'overlap': {
                'both_methods_count': both_methods.sum(),
                'only_iqr_count': only_iqr.sum(),
                'only_sigma_count': only_sigma.sum(),
                'agreement_rate': (both_methods.sum() / max(iqr_outliers.sum(), sigma_outliers.sum())) * 100 if max(iqr_outliers.sum(), sigma_outliers.sum()) > 0 else 100
            },
            'recommendation': self._get_method_recommendation(iqr_bounds, sigma_bounds, data)
        }
        
        return comparison
    
    def _get_method_recommendation(self, iqr_bounds: Dict, sigma_bounds: Dict, data: pd.Series) -> str:
        """
        åŸºäºæ•°æ®ç‰¹å¾æ¨èæœ€é€‚åˆçš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•
        """
        # æ£€æŸ¥æ•°æ®åˆ†å¸ƒç‰¹å¾
        skewness = data.skew()
        kurtosis = data.kurtosis()
        
        # æ¨èé€»è¾‘
        if abs(skewness) > 1.0 or kurtosis > 3.0:
            return "IQRæ–¹æ³• - æ•°æ®åˆ†å¸ƒåæ–œæˆ–æœ‰é‡å°¾ï¼ŒIQRæ›´é²æ£’"
        elif iqr_bounds['outlier_count'] > sigma_bounds['outlier_count'] * 2:
            return "2Ïƒæ–¹æ³• - IQRå¯èƒ½è¿‡äºæ•æ„Ÿ"
        elif sigma_bounds['outlier_count'] > iqr_bounds['outlier_count'] * 2:
            return "IQRæ–¹æ³• - 2Ïƒå¯èƒ½è¿‡äºæ•æ„Ÿ"
        else:
            return "IQRæ–¹æ³• - é€šå¸¸æ›´é²æ£’ï¼Œæ¨èä½œä¸ºé»˜è®¤é€‰æ‹©"

    def analyze_performance_anomalies(self, df: pd.DataFrame, 
                                    metrics: List[str] = None) -> Dict:
        """
        åˆ†ææ€§èƒ½æŒ‡æ ‡ä¸­çš„å¼‚å¸¸å€¼
        
        Args:
            df: æ€§èƒ½æ•°æ®DataFrame
            metrics: è¦åˆ†æçš„æŒ‡æ ‡åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåˆ†ææ‰€æœ‰æ•°å€¼åˆ—
            
        Returns:
            å¼‚å¸¸åˆ†æç»“æœ
        """
        if metrics is None:
            # è‡ªåŠ¨é€‰æ‹©æ•°å€¼å‹åˆ—
            metrics = df.select_dtypes(include=[np.number]).columns.tolist()
            # æ’é™¤æ—¶é—´æˆ³ç­‰ä¸é€‚åˆå¼‚å¸¸æ£€æµ‹çš„åˆ—
            exclude_cols = ['timestamp', 'current_qps', 'test_duration']
            metrics = [col for col in metrics if col not in exclude_cols]
        
        results = {
            'analyzed_metrics': metrics,
            'anomaly_summary': {},
            'method_comparison': {},
            'recommendations': []
        }
        
        for metric in metrics:
            if metric not in df.columns:
                continue
                
            data = df[metric].dropna()
            if len(data) < 10:  # æ•°æ®ç‚¹å¤ªå°‘ï¼Œè·³è¿‡
                continue
                
            # æ¯”è¾ƒä¸¤ç§æ–¹æ³•
            comparison = self.compare_methods(data)
            results['method_comparison'][metric] = comparison
            
            # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸
            outliers, bounds = self.detect_outliers_iqr(data, return_bounds=True)
            
            results['anomaly_summary'][metric] = {
                'outlier_indices': data[outliers].index.tolist(),
                'outlier_values': data[outliers].tolist(),
                'bounds': bounds,
                'severity': self._classify_anomaly_severity(bounds['outlier_percentage'])
            }
        
        # ç”Ÿæˆæ€»ä½“å»ºè®®
        results['recommendations'] = self._generate_anomaly_recommendations(results)
        
        return results
    
    def _classify_anomaly_severity(self, outlier_percentage: float) -> str:
        """åˆ†ç±»å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if outlier_percentage < 1.0:
            return "è½»å¾®"
        elif outlier_percentage < 5.0:
            return "ä¸­ç­‰"
        elif outlier_percentage < 10.0:
            return "ä¸¥é‡"
        else:
            return "æä¸¥é‡"
    
    def _generate_anomaly_recommendations(self, results: Dict) -> List[str]:
        """ç”Ÿæˆå¼‚å¸¸æ£€æµ‹å»ºè®®"""
        recommendations = []
        
        high_anomaly_metrics = []
        for metric, summary in results['anomaly_summary'].items():
            if summary['bounds']['outlier_percentage'] > 5.0:
                high_anomaly_metrics.append(metric)
        
        if high_anomaly_metrics:
            recommendations.append(f"å‘ç°é«˜å¼‚å¸¸ç‡æŒ‡æ ‡: {', '.join(high_anomaly_metrics)}")
            recommendations.append("å»ºè®®æ£€æŸ¥è¿™äº›æŒ‡æ ‡å¯¹åº”çš„ç³»ç»Ÿç»„ä»¶")
        
        if len(results['anomaly_summary']) > 0:
            avg_anomaly_rate = np.mean([s['bounds']['outlier_percentage'] 
                                      for s in results['anomaly_summary'].values()])
            if avg_anomaly_rate > 3.0:
                recommendations.append("æ•´ä½“å¼‚å¸¸ç‡è¾ƒé«˜ï¼Œå»ºè®®è¿›è¡Œç³»ç»Ÿæ€§èƒ½è°ƒä¼˜")
        
        return recommendations


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    normal_data = np.random.normal(50, 10, 1000)
    # æ·»åŠ ä¸€äº›å¼‚å¸¸å€¼
    outliers = np.array([100, 120, 150, -10, -20])
    test_data = np.concatenate([normal_data, outliers])
    
    # åˆ›å»ºå¼‚å¸¸æ£€æµ‹å™¨
    detector = AnomalyDetector()
    
    # æ£€æµ‹å¼‚å¸¸
    outliers_detected, bounds = detector.detect_outliers_iqr(test_data, return_bounds=True)
    
    print("IQRå¼‚å¸¸æ£€æµ‹ç»“æœ:")
    print(f"æ£€æµ‹åˆ°å¼‚å¸¸å€¼: {outliers_detected.sum()} ä¸ª")
    print(f"å¼‚å¸¸ç‡: {bounds['outlier_percentage']:.2f}%")
    print(f"æ£€æµ‹è¾¹ç•Œ: [{bounds['lower_bound']:.2f}, {bounds['upper_bound']:.2f}]")
    
    # æ¯”è¾ƒä¸¤ç§æ–¹æ³•
    comparison = detector.compare_methods(test_data)
    print(f"\næ–¹æ³•æ¯”è¾ƒ:")
    print(f"IQRæ–¹æ³•æ£€æµ‹åˆ°: {comparison['iqr_method']['outlier_count']} ä¸ªå¼‚å¸¸")
    print(f"2Ïƒæ–¹æ³•æ£€æµ‹åˆ°: {comparison['sigma_method']['outlier_count']} ä¸ªå¼‚å¸¸")
    print(f"æ¨è: {comparison['recommendation']}")
